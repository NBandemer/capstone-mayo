{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ],
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run after every new session\n",
        "pip install transformers[torch]\n",
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "SJqJcZ4S64i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "csqlu1lfu2n-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a5a76a-1142-4058-c60b-8e996a236289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\")\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"sdoh_community_present\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i8-ZZN5mu286",
        "outputId": "abbe0f2d-28ce-4b6f-a786-5da998d9737c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1760' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1760/1760 20:47, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.518100</td>\n",
              "      <td>0.451791</td>\n",
              "      <td>0.805694</td>\n",
              "      <td>0.786858</td>\n",
              "      <td>0.836237</td>\n",
              "      <td>0.805694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.332100</td>\n",
              "      <td>0.321415</td>\n",
              "      <td>0.887544</td>\n",
              "      <td>0.883790</td>\n",
              "      <td>0.894376</td>\n",
              "      <td>0.887544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.260200</td>\n",
              "      <td>0.224677</td>\n",
              "      <td>0.928826</td>\n",
              "      <td>0.928766</td>\n",
              "      <td>0.928722</td>\n",
              "      <td>0.928826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.216900</td>\n",
              "      <td>0.217337</td>\n",
              "      <td>0.924555</td>\n",
              "      <td>0.924766</td>\n",
              "      <td>0.925170</td>\n",
              "      <td>0.924555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.183700</td>\n",
              "      <td>0.272942</td>\n",
              "      <td>0.888968</td>\n",
              "      <td>0.884484</td>\n",
              "      <td>0.899658</td>\n",
              "      <td>0.888968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.153300</td>\n",
              "      <td>0.255275</td>\n",
              "      <td>0.920285</td>\n",
              "      <td>0.918513</td>\n",
              "      <td>0.924326</td>\n",
              "      <td>0.920285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.121200</td>\n",
              "      <td>0.177923</td>\n",
              "      <td>0.937367</td>\n",
              "      <td>0.936680</td>\n",
              "      <td>0.938227</td>\n",
              "      <td>0.937367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.082900</td>\n",
              "      <td>0.218929</td>\n",
              "      <td>0.936655</td>\n",
              "      <td>0.935620</td>\n",
              "      <td>0.939131</td>\n",
              "      <td>0.936655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.061600</td>\n",
              "      <td>0.216296</td>\n",
              "      <td>0.941637</td>\n",
              "      <td>0.941120</td>\n",
              "      <td>0.942125</td>\n",
              "      <td>0.941637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.043300</td>\n",
              "      <td>0.257377</td>\n",
              "      <td>0.938790</td>\n",
              "      <td>0.938052</td>\n",
              "      <td>0.939970</td>\n",
              "      <td>0.938790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.348297</td>\n",
              "      <td>0.945196</td>\n",
              "      <td>0.944725</td>\n",
              "      <td>0.945701</td>\n",
              "      <td>0.945196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.019400</td>\n",
              "      <td>0.297102</td>\n",
              "      <td>0.950890</td>\n",
              "      <td>0.950900</td>\n",
              "      <td>0.950911</td>\n",
              "      <td>0.950890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.011700</td>\n",
              "      <td>0.293452</td>\n",
              "      <td>0.953025</td>\n",
              "      <td>0.952882</td>\n",
              "      <td>0.952944</td>\n",
              "      <td>0.953025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.331648</td>\n",
              "      <td>0.951601</td>\n",
              "      <td>0.951498</td>\n",
              "      <td>0.951498</td>\n",
              "      <td>0.951601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>0.368525</td>\n",
              "      <td>0.950890</td>\n",
              "      <td>0.950729</td>\n",
              "      <td>0.950804</td>\n",
              "      <td>0.950890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.004600</td>\n",
              "      <td>0.366766</td>\n",
              "      <td>0.954448</td>\n",
              "      <td>0.954351</td>\n",
              "      <td>0.954357</td>\n",
              "      <td>0.954448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.407532</td>\n",
              "      <td>0.947331</td>\n",
              "      <td>0.947023</td>\n",
              "      <td>0.947424</td>\n",
              "      <td>0.947331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.415367</td>\n",
              "      <td>0.948754</td>\n",
              "      <td>0.948479</td>\n",
              "      <td>0.948809</td>\n",
              "      <td>0.948754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>0.455065</td>\n",
              "      <td>0.943060</td>\n",
              "      <td>0.942497</td>\n",
              "      <td>0.943802</td>\n",
              "      <td>0.943060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.406168</td>\n",
              "      <td>0.948043</td>\n",
              "      <td>0.947751</td>\n",
              "      <td>0.948116</td>\n",
              "      <td>0.948043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.17792321741580963, 'eval_accuracy': 0.9373665480427046, 'eval_f1': 0.9366799102071873, 'eval_precision': 0.9382272268676727, 'eval_recall': 0.9373665480427046, 'eval_runtime': 4.8716, 'eval_samples_per_second': 288.409, 'eval_steps_per_second': 4.516, 'epoch': 20.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "    logging_strategy='epoch',  # characterize as epoch\n",
        "    num_train_epochs=20, # have high epoch\n",
        "    #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "    per_device_train_batch_size=64, #reduced batch sie\n",
        "    per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "    save_strategy= 'epoch',\n",
        "    warmup_steps=500,\n",
        "    weight_decay=1e-5,\n",
        "    logging_dir= tensor_logs,  # change to tensor logs\n",
        "    eval_steps=100,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    #accumulate gradients over 4 steps\n",
        "    #gradient_accumulation_steps = 4\n",
        "    load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "    greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # 3 is a balance between giving the model enough chance  to improve and stopping early enough to prevent overfitting and unnecessary computation\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "yxR5iKE9QHH0",
        "outputId": "d50e8574-b6f3-4da6-ecd4-c07817da3dd7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [110/110 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 0.08034949749708176, 'eval_accuracy': 0.9716725978647687, 'eval_f1': 0.9714837398225641, 'eval_precision': 0.9722325803849914, 'eval_recall': 0.9716725978647687, 'eval_runtime': 25.4116, 'eval_samples_per_second': 276.448, 'eval_steps_per_second': 4.329, 'epoch': 20.0}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyMC/IFOoCRP9t6fZt9/LB7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}