{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "\n",
        "# import necessary libraries for data manipulation, model evaluation, and plotting\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Cell 2\n",
        "# model training and evaluation setup\n",
        "import datetime\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history'] #focus on this column for history\n",
        "        df = pd.DataFrame(log_history) # Convert the list of dictionaries to a DataFrame\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        " # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # You must ensure that training_args and train_dataset are already defined\n",
        "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    #steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Eval Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "def compute_metrics(pred): #evaluation metrics function\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L47PywTgujGQ"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2X4TWlFLxmXU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import datetime\n",
        "import warnings\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bIl1HxVexDKa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csqlu1lfu2n-",
        "outputId": "be8ac3e9-9de6-40cf-ffb4-ea51eada0e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"sdoh_community_present\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iydwAI4q5rcP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history'] #focus on this column for history\n",
        "        df = pd.DataFrame(log_history) # Convert the list of dictionaries to a DataFrame\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-hGonT0DR0o"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates the metrics at the end of each epoch\n",
        "    \"\"\"\n",
        "    labels = eval_pred.label_ids\n",
        "    preds = eval_pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgADASNj5xU0"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "def plot_metric_from_tensor(log_dir, output_dir):\n",
        "\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # Access step and value directly from events\n",
        "    steps1 = [event.step for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    steps2 = [event.step for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(steps1, values1, label=\"Eval Loss\")\n",
        "    plt.plot(steps2, values2, label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nEfHDei51ks"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(\n",
        "    train_encodings,\n",
        "    y_train\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,\n",
        "    y_val\n",
        ")\n",
        "#val_dataset = DataLoader(val_encodings, y_val)\n",
        "#test_dataset = DataLoader(test_encodings, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cjTTCYjPKESc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80b6908-c577-42f9-a952-7b9326ce5991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
            "  Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tLvRlpBbKMlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838c28b3-8467-4196-8f21-55a120d05565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i8-ZZN5mu286",
        "outputId": "3dd395b5-ebbe-4531-e2c2-efe3d2ea943f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='574' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 574/1760 06:34 < 13:38, 1.45 it/s, Epoch 6.51/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.612600</td>\n",
              "      <td>1.208353</td>\n",
              "      <td>0.506762</td>\n",
              "      <td>0.460736</td>\n",
              "      <td>0.469155</td>\n",
              "      <td>0.506762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.089800</td>\n",
              "      <td>0.787770</td>\n",
              "      <td>0.717438</td>\n",
              "      <td>0.697613</td>\n",
              "      <td>0.723222</td>\n",
              "      <td>0.717438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.781600</td>\n",
              "      <td>0.755754</td>\n",
              "      <td>0.742349</td>\n",
              "      <td>0.725572</td>\n",
              "      <td>0.770600</td>\n",
              "      <td>0.742349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.650200</td>\n",
              "      <td>0.570566</td>\n",
              "      <td>0.812811</td>\n",
              "      <td>0.804965</td>\n",
              "      <td>0.806865</td>\n",
              "      <td>0.812811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.561000</td>\n",
              "      <td>0.578733</td>\n",
              "      <td>0.807829</td>\n",
              "      <td>0.797840</td>\n",
              "      <td>0.808583</td>\n",
              "      <td>0.807829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.474700</td>\n",
              "      <td>0.530575</td>\n",
              "      <td>0.819929</td>\n",
              "      <td>0.819366</td>\n",
              "      <td>0.824908</td>\n",
              "      <td>0.819929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1760' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1760/1760 20:26, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.612600</td>\n",
              "      <td>1.208353</td>\n",
              "      <td>0.506762</td>\n",
              "      <td>0.460736</td>\n",
              "      <td>0.469155</td>\n",
              "      <td>0.506762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.089800</td>\n",
              "      <td>0.787770</td>\n",
              "      <td>0.717438</td>\n",
              "      <td>0.697613</td>\n",
              "      <td>0.723222</td>\n",
              "      <td>0.717438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.781600</td>\n",
              "      <td>0.755754</td>\n",
              "      <td>0.742349</td>\n",
              "      <td>0.725572</td>\n",
              "      <td>0.770600</td>\n",
              "      <td>0.742349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.650200</td>\n",
              "      <td>0.570566</td>\n",
              "      <td>0.812811</td>\n",
              "      <td>0.804965</td>\n",
              "      <td>0.806865</td>\n",
              "      <td>0.812811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.561000</td>\n",
              "      <td>0.578733</td>\n",
              "      <td>0.807829</td>\n",
              "      <td>0.797840</td>\n",
              "      <td>0.808583</td>\n",
              "      <td>0.807829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.474700</td>\n",
              "      <td>0.530575</td>\n",
              "      <td>0.819929</td>\n",
              "      <td>0.819366</td>\n",
              "      <td>0.824908</td>\n",
              "      <td>0.819929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.409600</td>\n",
              "      <td>0.540294</td>\n",
              "      <td>0.836299</td>\n",
              "      <td>0.830504</td>\n",
              "      <td>0.830296</td>\n",
              "      <td>0.836299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.324300</td>\n",
              "      <td>0.616927</td>\n",
              "      <td>0.842705</td>\n",
              "      <td>0.834290</td>\n",
              "      <td>0.836904</td>\n",
              "      <td>0.842705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.595948</td>\n",
              "      <td>0.815658</td>\n",
              "      <td>0.824607</td>\n",
              "      <td>0.841251</td>\n",
              "      <td>0.815658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.191600</td>\n",
              "      <td>0.686083</td>\n",
              "      <td>0.832028</td>\n",
              "      <td>0.833937</td>\n",
              "      <td>0.838583</td>\n",
              "      <td>0.832028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.135100</td>\n",
              "      <td>0.751606</td>\n",
              "      <td>0.822776</td>\n",
              "      <td>0.825441</td>\n",
              "      <td>0.830380</td>\n",
              "      <td>0.822776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.125100</td>\n",
              "      <td>0.853009</td>\n",
              "      <td>0.824911</td>\n",
              "      <td>0.820643</td>\n",
              "      <td>0.825498</td>\n",
              "      <td>0.824911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.091600</td>\n",
              "      <td>0.823297</td>\n",
              "      <td>0.836299</td>\n",
              "      <td>0.833151</td>\n",
              "      <td>0.832374</td>\n",
              "      <td>0.836299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.060700</td>\n",
              "      <td>0.911337</td>\n",
              "      <td>0.835587</td>\n",
              "      <td>0.837392</td>\n",
              "      <td>0.846489</td>\n",
              "      <td>0.835587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.052300</td>\n",
              "      <td>0.948124</td>\n",
              "      <td>0.814235</td>\n",
              "      <td>0.819597</td>\n",
              "      <td>0.827695</td>\n",
              "      <td>0.814235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.039100</td>\n",
              "      <td>1.063290</td>\n",
              "      <td>0.829893</td>\n",
              "      <td>0.828591</td>\n",
              "      <td>0.831595</td>\n",
              "      <td>0.829893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>1.024538</td>\n",
              "      <td>0.827758</td>\n",
              "      <td>0.826626</td>\n",
              "      <td>0.827811</td>\n",
              "      <td>0.827758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>1.073175</td>\n",
              "      <td>0.839146</td>\n",
              "      <td>0.837908</td>\n",
              "      <td>0.838022</td>\n",
              "      <td>0.839146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>1.116366</td>\n",
              "      <td>0.833452</td>\n",
              "      <td>0.831926</td>\n",
              "      <td>0.832679</td>\n",
              "      <td>0.833452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>1.104967</td>\n",
              "      <td>0.832028</td>\n",
              "      <td>0.830893</td>\n",
              "      <td>0.830861</td>\n",
              "      <td>0.832028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.5305747389793396, 'eval_accuracy': 0.8199288256227758, 'eval_f1': 0.8193663854108167, 'eval_precision': 0.8249076908342831, 'eval_recall': 0.8199288256227758, 'eval_runtime': 4.8994, 'eval_samples_per_second': 286.771, 'eval_steps_per_second': 4.49, 'epoch': 20.0}\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "import datetime\n",
        "import os\n",
        "import torch\n",
        "from torch.optim import AdamW  # variant of Adam with weight decay\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "import json\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Define label_columns here\n",
        "label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        \"\"\" :rtype: object \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "    logging_strategy='epoch',  # characterize as epoch\n",
        "    num_train_epochs=20, # have high epoch\n",
        "    #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "    per_device_train_batch_size=64, #reduced batch sie\n",
        "    per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "    save_strategy= 'epoch',\n",
        "    warmup_steps=500,\n",
        "    weight_decay=1e-5,\n",
        "    logging_dir= tensor_logs,  # change to tensor logs\n",
        "    eval_steps=100,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    #accumulate gradients over 4 steps\n",
        "    #gradient_accumulation_steps = 4\n",
        "    load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "    greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # 3 is a balance between giving the model enough chance  to improve and stopping early enough to prevent overfitting and unnecessary computation\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Cell 4\n",
        "# Evaluation on Test Data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this also\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyOrgEJ2UKgKd3z+GtQmADQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}