{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ],
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "csqlu1lfu2n-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ffaff8-b172-4c05-b374-bcd697ac35be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\")\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"sdoh_community_present\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i8-ZZN5mu286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "786cc0e8-e12c-4a1d-db43-3a84ef74af32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [616/616 07:28, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.596000</td>\n",
              "      <td>0.525194</td>\n",
              "      <td>0.744484</td>\n",
              "      <td>0.698837</td>\n",
              "      <td>0.809569</td>\n",
              "      <td>0.744484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.383100</td>\n",
              "      <td>0.368281</td>\n",
              "      <td>0.852669</td>\n",
              "      <td>0.844059</td>\n",
              "      <td>0.869031</td>\n",
              "      <td>0.852669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>0.240845</td>\n",
              "      <td>0.913879</td>\n",
              "      <td>0.913094</td>\n",
              "      <td>0.913856</td>\n",
              "      <td>0.913879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.223700</td>\n",
              "      <td>0.195518</td>\n",
              "      <td>0.928826</td>\n",
              "      <td>0.928196</td>\n",
              "      <td>0.929061</td>\n",
              "      <td>0.928826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.186600</td>\n",
              "      <td>0.226781</td>\n",
              "      <td>0.921708</td>\n",
              "      <td>0.920544</td>\n",
              "      <td>0.923155</td>\n",
              "      <td>0.921708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>0.199147</td>\n",
              "      <td>0.925979</td>\n",
              "      <td>0.925246</td>\n",
              "      <td>0.926341</td>\n",
              "      <td>0.925979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.096200</td>\n",
              "      <td>0.209787</td>\n",
              "      <td>0.934520</td>\n",
              "      <td>0.933872</td>\n",
              "      <td>0.935072</td>\n",
              "      <td>0.934520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.19551753997802734, 'eval_accuracy': 0.9288256227758007, 'eval_f1': 0.9281955081701352, 'eval_precision': 0.9290612771979371, 'eval_recall': 0.9288256227758007, 'eval_runtime': 4.7566, 'eval_samples_per_second': 295.377, 'eval_steps_per_second': 4.625, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "    logging_strategy='epoch',  # characterize as epoch\n",
        "    num_train_epochs=7, # have high epoch\n",
        "    #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "    per_device_train_batch_size=64, #reduced batch sie\n",
        "    per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "    save_strategy= 'epoch',\n",
        "    warmup_steps=500,\n",
        "    weight_decay=1e-5,\n",
        "    logging_dir= tensor_logs,  # change to tensor logs\n",
        "    #eval_steps=100,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    #accumulate gradients over 4 steps\n",
        "    #gradient_accumulation_steps = 4\n",
        "    load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "    greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # 3 is a balance between giving the model enough chance  to improve and stopping early enough to prevent overfitting and unnecessary computation\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]"
      ],
      "metadata": {
        "id": "qvHjlczRfoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "2y3hG9frfp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['sdoh_community_absent', 'sdoh_community_present']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxR5iKE9QHH0",
        "outputId": "0bec511a-3b07-4d81-e446-b7481b28f46b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bc871785f905>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[ 4.1010003, -4.674293 ],\n",
            "       [ 0.6659358, -2.6060843],\n",
            "       [-3.53474  ,  1.4819527],\n",
            "       ...,\n",
            "       [-2.436789 ,  1.3270983],\n",
            "       [-2.1720557,  1.153169 ],\n",
            "       [ 0.7330762, -2.8865876]], dtype=float32), array([[[ 0.42700708, -0.18862489, -0.48639557, ...,  0.01541823,\n",
            "         -0.538374  , -0.3061447 ],\n",
            "        [-0.5477326 ,  0.08688699,  0.44624352, ...,  0.056337  ,\n",
            "          0.79815537, -0.12809859],\n",
            "        [ 0.39677367,  1.2513163 , -1.1322625 , ...,  1.1529073 ,\n",
            "          0.36044106, -0.7884846 ],\n",
            "        ...,\n",
            "        [ 0.7938337 ,  1.0020214 , -0.00569954, ...,  0.17524213,\n",
            "          0.613088  , -0.3931444 ],\n",
            "        [ 0.7902924 ,  1.0052366 , -0.01652941, ...,  0.19044717,\n",
            "          0.6297312 , -0.3970333 ],\n",
            "        [ 0.7872011 ,  0.998283  , -0.00939967, ...,  0.17383085,\n",
            "          0.61733955, -0.3937556 ]],\n",
            "\n",
            "       [[-0.73340195,  0.7174273 ,  0.89764297, ...,  0.90720713,\n",
            "          0.21869722, -1.74529   ],\n",
            "        [ 0.18493067,  0.4339019 ,  0.5773464 , ...,  0.60550386,\n",
            "         -1.3542238 , -1.0383308 ],\n",
            "        [ 0.19385768,  1.166257  ,  2.2585542 , ...,  0.38326457,\n",
            "          0.4091812 , -1.2304224 ],\n",
            "        ...,\n",
            "        [ 0.26785207,  0.9630479 ,  1.1561949 , ...,  0.36003378,\n",
            "         -0.24791081, -1.2809683 ],\n",
            "        [ 0.26937613,  0.96461296,  1.1534584 , ...,  0.35911283,\n",
            "         -0.24846524, -1.2822442 ],\n",
            "        [ 0.27132037,  0.9674155 ,  1.1543416 , ...,  0.35957357,\n",
            "         -0.24849392, -1.2810309 ]],\n",
            "\n",
            "       [[-0.12974921, -0.1544534 ,  1.9334943 , ...,  1.0516407 ,\n",
            "         -0.50551635,  0.4665411 ],\n",
            "        [ 0.02365742,  0.27077848,  1.3109602 , ...,  2.0156531 ,\n",
            "         -1.260538  , -0.14559902],\n",
            "        [ 0.7455404 , -0.86540353,  2.0812235 , ...,  0.67992216,\n",
            "         -0.78454787,  0.37065145],\n",
            "        ...,\n",
            "        [ 0.21550584, -0.52529716,  2.4824677 , ...,  1.1357719 ,\n",
            "         -1.0498061 , -0.06975241],\n",
            "        [ 0.20315339, -1.1286652 ,  1.4014946 , ...,  0.9187649 ,\n",
            "         -1.0929328 , -0.23054777],\n",
            "        [ 0.73261786, -0.06306023,  1.8412373 , ...,  1.0883391 ,\n",
            "         -0.6782972 , -0.5639989 ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.01640908, -0.17209847,  2.850958  , ...,  1.8574358 ,\n",
            "          0.69619125,  0.07245214],\n",
            "        [ 0.77742416, -0.2859568 ,  1.4941909 , ...,  2.09749   ,\n",
            "          0.24440074, -1.2612847 ],\n",
            "        [-0.23186651,  0.47643667,  2.0282805 , ...,  1.7756821 ,\n",
            "         -0.17095627,  0.10867428],\n",
            "        ...,\n",
            "        [ 0.49098802,  0.10614451,  2.3868942 , ...,  1.2232238 ,\n",
            "          0.13482985, -0.02414003],\n",
            "        [ 0.48836204,  0.10464737,  2.39043   , ...,  1.2220355 ,\n",
            "          0.13305825, -0.02660117],\n",
            "        [ 0.48869264,  0.10423046,  2.38991   , ...,  1.2205137 ,\n",
            "          0.13087146, -0.02660516]],\n",
            "\n",
            "       [[ 0.3794575 , -0.2620044 ,  2.5359986 , ...,  1.4422047 ,\n",
            "         -0.01161615,  0.42071   ],\n",
            "        [ 0.47726744, -0.24116053,  2.8106809 , ...,  1.2381684 ,\n",
            "         -0.08200175, -0.6221143 ],\n",
            "        [ 0.4489251 , -0.31547582,  1.9889153 , ...,  1.6309958 ,\n",
            "         -0.26584458,  0.14134386],\n",
            "        ...,\n",
            "        [ 0.9693323 ,  0.37444234,  1.9503282 , ...,  1.4066958 ,\n",
            "          0.20632166,  0.20276228],\n",
            "        [ 0.9704678 ,  0.37842274,  1.9476155 , ...,  1.4069028 ,\n",
            "          0.2045199 ,  0.20490909],\n",
            "        [ 0.97067523,  0.3775813 ,  1.9502085 , ...,  1.4070952 ,\n",
            "          0.19924216,  0.21036963]],\n",
            "\n",
            "       [[ 0.19623885, -0.18986799,  0.41917253, ...,  0.00609184,\n",
            "          0.6130608 , -1.0121987 ],\n",
            "        [ 0.37431967, -0.02451285, -0.03419872, ...,  0.1853234 ,\n",
            "         -0.5294206 , -1.0419526 ],\n",
            "        [ 0.1423279 ,  1.0766708 ,  0.23809299, ...,  0.7264873 ,\n",
            "          0.3582482 , -1.9108477 ],\n",
            "        ...,\n",
            "        [ 0.46598244,  0.15907954, -0.2795631 , ...,  1.1113796 ,\n",
            "         -0.57686543, -0.5812643 ],\n",
            "        [-2.1710637 ,  2.2131093 ,  0.14560588, ...,  0.94072413,\n",
            "         -0.08798948, -1.0030048 ],\n",
            "        [-0.6075377 , -0.23692745,  0.7047541 , ..., -0.66500854,\n",
            "         -0.80911565, -0.01814583]]], dtype=float32)), label_ids=array([0, 0, 1, ..., 1, 1, 1]), metrics={'test_loss': 0.15197040140628815, 'test_accuracy': 0.9423487544483986, 'test_f1': 0.9419128240142831, 'test_precision': 0.9426193097874771, 'test_recall': 0.9423487544483986, 'test_runtime': 25.7732, 'test_samples_per_second': 272.57, 'test_steps_per_second': 4.268})\n",
            "Test Results: {'eval_loss': 0.15197040140628815, 'eval_accuracy': 0.9423487544483986, 'eval_f1': 0.9419128240142831, 'eval_precision': 0.9426193097874771, 'eval_recall': 0.9423487544483986, 'eval_runtime': 24.8843, 'eval_samples_per_second': 282.307, 'eval_steps_per_second': 4.42, 'epoch': 7.0}\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            " sdoh_community_absent       0.95      0.89      0.92      2562\n",
            "sdoh_community_present       0.94      0.97      0.96      4463\n",
            "\n",
            "              accuracy                           0.94      7025\n",
            "             macro avg       0.94      0.93      0.94      7025\n",
            "          weighted avg       0.94      0.94      0.94      7025\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffqg7AwNCu8_",
        "outputId": "ef42750c-37dc-4e9e-81b9-8a436c9010c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision    Recall  F1 Score\n",
            "0  0.942349   0.938418  0.973112   0.95545\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyODbkNFAT5fi5m1IcCerRrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}