{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/checkpoint_epoch_{epoch}.pth'\n",
        "best_model_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/best_model.pth'\n",
        "\n",
        "\n",
        "# Saving the checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, loss, val_loss, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    if is_best:\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csqlu1lfu2n-",
        "outputId": "b45667ad-0259-4ea2-c79d-d733d7011af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['behavior_tobacco']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_tobacco\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: change label to float for sdoh_economics, sdoh_environment\n",
        "\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(float(self.labels[idx]))\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i8-ZZN5mu286",
        "outputId": "d7b56d7e-7027-4fe1-a940-ec0898871e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [616/616 07:14, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.759000</td>\n",
              "      <td>1.212177</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.016100</td>\n",
              "      <td>1.014782</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.818800</td>\n",
              "      <td>1.730356</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.648500</td>\n",
              "      <td>0.715661</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.571700</td>\n",
              "      <td>0.506478</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.468800</td>\n",
              "      <td>0.486541</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.337100</td>\n",
              "      <td>0.529821</td>\n",
              "      <td>0.183630</td>\n",
              "      <td>0.056977</td>\n",
              "      <td>0.033720</td>\n",
              "      <td>0.183630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.48654067516326904, 'eval_accuracy': 0.18362989323843418, 'eval_f1': 0.056977164708978977, 'eval_precision': 0.03371993769075873, 'eval_recall': 0.18362989323843418, 'eval_runtime': 4.7167, 'eval_samples_per_second': 297.877, 'eval_steps_per_second': 4.664, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "      output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "      logging_strategy='epoch',  # characterize as epoch\n",
        "      num_train_epochs=7, # have high epoch\n",
        "      #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "      per_device_train_batch_size=64, #reduced batch sie\n",
        "      per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "      save_strategy= 'epoch',\n",
        "      warmup_steps=500,\n",
        "      weight_decay=1e-5,\n",
        "      logging_dir= tensor_logs,  # change to tensor logs\n",
        "      #eval_steps=100,\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      #accumulate gradients over 4 steps\n",
        "      #gradient_accumulation_steps = 4\n",
        "      load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "      metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "      greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Save checkpoint after every epoch\n",
        "#save_checkpoint(model, optimizer, epoch, current_loss, current_val_loss, is_best=False)\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvHjlczRfoIP"
      },
      "outputs": [],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y3hG9frfp73"
      },
      "outputs": [],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxR5iKE9QHH0",
        "outputId": "f21123ed-321c-40f8-bf49-df8885edc121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[ 0.9004211 ],\n",
            "       [ 1.7476517 ],\n",
            "       [ 2.5079975 ],\n",
            "       ...,\n",
            "       [-0.28871664],\n",
            "       [ 1.620848  ],\n",
            "       [ 2.4681783 ]], dtype=float32), array([[[-0.8698914 ,  0.38341543,  0.24650288, ...,  0.7810866 ,\n",
            "          0.8721652 , -1.2161869 ],\n",
            "        [-0.42741212,  0.9046873 , -0.1859181 , ...,  1.1748141 ,\n",
            "          0.19828303, -1.6401913 ],\n",
            "        [-0.03754518,  0.3684572 , -0.68810487, ...,  0.1323823 ,\n",
            "          0.87850404, -1.2472682 ],\n",
            "        ...,\n",
            "        [-0.15611325,  0.4819714 , -0.51623607, ...,  0.8843163 ,\n",
            "          0.69531345, -1.4033415 ],\n",
            "        [-0.15510935,  0.47526678, -0.5147523 , ...,  0.8817247 ,\n",
            "          0.6990933 , -1.4027839 ],\n",
            "        [-0.15792423,  0.47242472, -0.5097334 , ...,  0.8854402 ,\n",
            "          0.6994617 , -1.4083941 ]],\n",
            "\n",
            "       [[-1.107784  ,  0.09766681, -0.739067  , ...,  1.977403  ,\n",
            "          0.85334295, -0.9473694 ],\n",
            "        [ 0.20493646,  1.0166056 , -0.35650828, ...,  1.6986121 ,\n",
            "          1.8834434 , -0.6712575 ],\n",
            "        [-0.30442742,  0.91997343, -1.2128035 , ...,  2.4795704 ,\n",
            "          2.158531  , -0.81348646],\n",
            "        ...,\n",
            "        [-0.51071113, -0.19033653, -1.0110415 , ...,  1.8684653 ,\n",
            "          2.428768  , -0.4836218 ],\n",
            "        [-0.5102663 , -0.18984315, -1.0121558 , ...,  1.868326  ,\n",
            "          2.4275908 , -0.4840265 ],\n",
            "        [-0.50930434, -0.18705885, -1.0116924 , ...,  1.8664103 ,\n",
            "          2.426478  , -0.48275098]],\n",
            "\n",
            "       [[-0.8016119 , -0.2611574 , -2.1360073 , ...,  1.4272765 ,\n",
            "          1.6262075 ,  0.15690099],\n",
            "        [ 0.08205897, -0.21725614, -1.8776524 , ...,  1.2336515 ,\n",
            "          0.6801167 , -1.6263248 ],\n",
            "        [-0.7980876 , -0.19720875, -2.428711  , ...,  1.3219491 ,\n",
            "          0.68633366, -1.0063018 ],\n",
            "        ...,\n",
            "        [-1.0936788 , -0.08562114, -2.0959148 , ...,  0.8390909 ,\n",
            "          1.8490853 , -1.4534206 ],\n",
            "        [-1.8797566 , -0.8613149 , -1.9561977 , ...,  0.76134104,\n",
            "          1.6802231 , -0.21813919],\n",
            "        [-0.5470187 , -0.75308704, -1.964562  , ...,  0.9523239 ,\n",
            "          2.2908206 , -0.7402452 ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.02560836,  0.12608242, -1.134475  , ...,  0.82686317,\n",
            "          0.56691355,  0.26419577],\n",
            "        [ 0.6898658 , -0.7532928 , -1.452031  , ..., -0.03303045,\n",
            "         -0.02629816,  0.8834433 ],\n",
            "        [ 1.5606316 , -0.8271422 , -1.5761179 , ...,  1.188428  ,\n",
            "         -1.4614116 , -1.0178547 ],\n",
            "        ...,\n",
            "        [ 1.0513223 , -1.0422087 , -1.4710796 , ...,  0.5806898 ,\n",
            "          1.0292292 ,  0.00749103],\n",
            "        [ 1.0510484 , -1.0415138 , -1.4703064 , ...,  0.5814729 ,\n",
            "          1.0316417 ,  0.00799161],\n",
            "        [ 1.0492976 , -1.0454848 , -1.4743072 , ...,  0.58230996,\n",
            "          1.0304115 ,  0.00908889]],\n",
            "\n",
            "       [[-0.88319814,  0.14493735, -1.8104558 , ...,  0.535643  ,\n",
            "          0.4766496 ,  0.13221626],\n",
            "        [-0.00404201, -0.7359819 , -2.352934  , ...,  0.992887  ,\n",
            "          1.2674702 ,  0.4260427 ],\n",
            "        [-0.40373716, -0.35410443, -1.475368  , ...,  1.1176354 ,\n",
            "          0.9129871 ,  0.5173015 ],\n",
            "        ...,\n",
            "        [-0.5041185 , -0.6762974 , -1.5256294 , ...,  0.99229074,\n",
            "          1.7292703 ,  0.17798279],\n",
            "        [-0.5049066 , -0.67600477, -1.5233375 , ...,  0.99323   ,\n",
            "          1.729945  ,  0.1806203 ],\n",
            "        [-0.5106407 , -0.67630416, -1.5229197 , ...,  0.9942086 ,\n",
            "          1.7296386 ,  0.18077457]],\n",
            "\n",
            "       [[-1.4159504 , -0.6728267 , -0.75591445, ...,  1.4158988 ,\n",
            "          1.6766807 , -1.5215687 ],\n",
            "        [-1.638672  ,  0.09556459, -2.1610487 , ...,  1.360035  ,\n",
            "          1.9347184 , -0.24315387],\n",
            "        [-1.610619  , -0.96288145, -1.1357589 , ...,  1.5206815 ,\n",
            "         -0.3772869 , -0.20553465],\n",
            "        ...,\n",
            "        [-1.4883993 , -0.6321856 , -1.1134686 , ...,  0.3385096 ,\n",
            "          0.9147049 , -1.0968281 ],\n",
            "        [-1.40379   , -0.02818921, -2.163957  , ...,  1.3874966 ,\n",
            "          1.4346355 ,  0.12491681],\n",
            "        [-2.2575788 , -0.66251373, -1.7484885 , ...,  0.7652658 ,\n",
            "          1.4037032 ,  0.16216639]]], dtype=float32)), label_ids=array([1., 2., 4., ..., 0., 2., 2.], dtype=float32), metrics={'test_loss': 0.3310316205024719, 'test_accuracy': 0.18377224199288256, 'test_f1': 0.057058673499954644, 'test_precision': 0.03377223692709059, 'test_recall': 0.18377224199288256, 'test_runtime': 24.2125, 'test_samples_per_second': 290.14, 'test_steps_per_second': 4.543})\n",
            "Test Results: {'eval_loss': 0.3310316205024719, 'eval_accuracy': 0.18377224199288256, 'eval_f1': 0.057058673499954644, 'eval_precision': 0.03377223692709059, 'eval_recall': 0.18377224199288256, 'eval_runtime': 25.0492, 'eval_samples_per_second': 280.448, 'eval_steps_per_second': 4.391, 'epoch': 7.0}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      1.00      0.31      1291\n",
            "           1       0.00      0.00      0.00      1006\n",
            "           2       0.00      0.00      0.00      2121\n",
            "           3       0.00      0.00      0.00      2252\n",
            "           4       0.00      0.00      0.00       355\n",
            "\n",
            "    accuracy                           0.18      7025\n",
            "   macro avg       0.04      0.20      0.06      7025\n",
            "weighted avg       0.03      0.18      0.06      7025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['0', '1', '2', '3', '4']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffqg7AwNCu8_",
        "outputId": "4d277680-52d4-4067-8817-441c8dac2995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision    Recall  F1 Score\n",
            "0  0.183772   0.033772  0.183772  0.057059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCFTWfcD1Tfb",
        "outputId": "3ed8ee4e-93c8-48a9-b7a4-479608d0c8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels: [1, 2, 4, 1, 3, 1, 2, 2, 2, 0, 2, 3, 3, 3, 2, 4, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 4, 2, 0, 2, 3, 2, 2, 3, 3, 2, 3, 2, 0, 2, 2, 4, 2, 1, 2, 2, 2, 3, 0, 3, 1, 2, 3, 3, 3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 1, 4, 2, 0, 0, 1, 1, 0, 3, 1, 1, 4, 3, 0, 2, 0, 0, 3, 1, 2, 2, 3, 3, 0, 2, 0, 2, 0, 2, 1, 3, 4, 0, 0, 2, 1, 0, 0, 0, 3, 0, 3, 3, 0, 2, 3, 0, 2, 3, 3, 2, 0, 1, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 4, 2, 2, 0, 2, 1, 3, 0, 1, 3, 2, 2, 2, 3, 3, 3, 4, 0, 1, 2, 0, 2, 2, 0, 3, 1, 3, 2, 0, 2, 4, 2, 2, 2, 0, 2, 2, 0, 1, 3, 3, 3, 3, 1, 0, 0, 3, 3, 2, 1, 4, 1, 4, 3, 1, 0, 3, 1, 0, 3, 3, 0, 0, 2, 0, 3, 3, 2, 3, 3, 0, 3, 4, 2, 2, 3, 2, 2, 2, 3, 4, 3, 0, 2, 1, 1, 3, 0, 3, 3, 3, 0, 2, 2, 0, 0, 2, 4, 2, 0, 3, 2, 2, 3, 3, 1, 1, 0, 3, 2, 2, 0, 0, 2, 2, 3, 2, 2, 3, 0, 2, 2, 2, 3, 4, 3, 2, 3, 3, 3, 3, 2, 4, 3, 4, 1, 0, 4, 2, 3, 3, 2, 0, 3, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 3, 3, 3, 1, 0, 3, 2, 1, 3, 2, 1, 3, 3, 0, 0, 1, 2, 3, 2, 3, 2, 3, 1, 3, 2, 4, 2, 0, 1, 3, 4, 4, 1, 0, 1, 2, 1, 2, 3, 2, 3, 2, 0, 0, 3, 0, 2, 3, 3, 3, 4, 3, 2, 4, 0, 0, 0, 2, 3, 1, 2, 2, 3, 0, 1, 2, 1, 2, 2, 3, 2, 4, 2, 2, 0, 3, 2, 3, 0, 1, 0, 2, 2, 2, 3, 3, 2, 2, 3, 1, 1, 1, 0, 3, 0, 1, 1, 3, 3, 2, 3, 2, 2, 2, 1, 4, 3, 3, 2, 3, 3, 3, 0, 0, 0, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 0, 0, 3, 3, 2, 2, 0, 3, 4, 3, 0, 3, 0, 2, 3, 3, 1, 2, 2, 3, 2, 3, 0, 3, 2, 1, 4, 3, 3, 1, 1, 3, 3, 3, 0, 3, 4, 0, 3, 3, 3, 3, 0, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 3, 3, 2, 2, 0, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 3, 3, 2, 2, 0, 3, 2, 3, 1, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 4, 2, 2, 3, 3, 3, 2, 2, 1, 1, 3, 3, 2, 0, 0, 3, 3, 4, 1, 3, 3, 3, 3, 4, 0, 0, 4, 3, 3, 0, 3, 2, 2, 3, 2, 3, 2, 1, 4, 3, 0, 1, 1, 1, 1, 2, 3, 2, 1, 0, 2, 3, 3, 3, 2, 3, 3, 2, 1, 3, 3, 3, 0, 2, 3, 1, 1, 3, 0, 4, 3, 3, 0, 3, 1, 4, 1, 3, 3, 2, 2, 2, 0, 3, 3, 1, 2, 3, 1, 0, 3, 2, 1, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 1, 3, 0, 3, 3, 2, 4, 3, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 3, 2, 0, 3, 2, 0, 2, 1, 2, 2, 2, 3, 1, 3, 2, 0, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 3, 1, 3, 3, 4, 3, 3, 2, 2, 2, 2, 3, 2, 2, 0, 1, 3, 3, 3, 2, 1, 4, 1, 1, 3, 3, 3, 0, 2, 0, 1, 0, 2, 2, 3, 3, 0, 3, 3, 0, 3, 3, 1, 2, 0, 3, 2, 0, 3, 2, 2, 3, 1, 0, 0, 3, 3, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 4, 2, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 3, 2, 2, 1, 1, 2, 3, 2, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 1, 4, 3, 2, 4, 2, 2, 1, 3, 2, 1, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, 0, 1, 0, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0, 3, 4, 0, 2, 2, 0, 2, 3, 3, 3, 3, 1, 2, 2, 3, 2, 3, 3, 0, 2, 2, 2, 0, 3, 4, 4, 0, 3, 2, 1, 2, 3, 2, 3, 2, 1, 1, 3, 2, 2, 3, 3, 3, 1, 2, 2, 3, 3, 2, 2, 1, 1, 4, 0, 3, 2, 0, 1, 1, 2, 3, 2, 0, 0, 0, 3, 3, 3, 0, 4, 2, 1, 0, 1, 0, 2, 1, 2, 1, 3, 2, 1, 2, 1, 0, 2, 3, 0, 1, 3, 2, 3, 4, 2, 2, 3, 1, 2, 4, 3, 2, 3, 3, 2, 1, 1, 2, 2, 3, 0, 0, 0, 2, 2, 2, 2, 3, 0, 1, 3, 2, 3, 3, 3, 2, 2, 3, 3, 1, 3, 3, 3, 4, 3, 3, 3, 2, 1, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 1, 0, 0, 3, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 3, 3, 1, 2, 2, 3, 3, 3, 3, 0, 2, 2, 2, 0, 3, 4, 2, 3, 3, 2, 3, 2, 0, 3, 2, 0, 0, 2, 2, 1, 3, 0, 2, 4, 0, 2, 0, 2, 3, 2, 3, 3, 2, 3, 1, 3, 2, 2, 3, 3, 0, 0, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 0, 0, 2, 3, 3, 4, 2, 0, 2, 2, 2, 2, 0, 3, 3, 3, 0, 0, 3, 3, 1, 4, 0, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2, 3, 3, 4, 1, 3, 3, 2, 3, 2, 3, 3, 1, 3, 4, 0, 2, 2, 3, 1, 2, 2, 2, 0, 3, 2, 3, 2, 2, 2, 1, 1, 3, 2, 0, 0, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 0, 3, 3, 4, 0, 0, 3, 0, 2, 3, 2, 2, 3, 3, 2, 1, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3, 3, 3, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2, 2, 2, 0, 3, 0, 4, 2, 1, 2, 2, 2, 2, 1, 4, 3, 3, 3, 1, 2, 0, 3, 2, 1, 1, 1, 2, 3, 2, 2, 3, 3, 3, 1, 2, 4, 2, 2, 3, 0, 3, 0, 4, 3, 3, 1, 2, 3, 3, 3, 1, 1, 1, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 2, 3, 1, 0, 1, 3, 3, 3, 2, 3, 2, 2, 3, 1, 0, 2, 0, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 1, 0, 0, 3, 2, 3, 3, 3, 3, 3, 4, 3, 2, 4, 3, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 0, 0, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 0, 3, 2, 3, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 4, 3, 1, 1, 1, 3, 2, 2, 0, 2, 0, 0, 3, 3, 0, 0, 2, 3, 3, 3, 3, 3, 3, 2, 2, 0, 3, 3, 1, 3, 3, 2, 3, 3, 3, 2, 3, 1, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3, 1, 1, 3, 0, 1, 3, 2, 4, 1, 1, 2, 2, 0, 3, 0, 3, 2, 1, 2, 0, 3, 0, 3, 1, 3, 2, 3, 3, 2, 0, 0, 0, 1, 2, 0, 3, 3, 2, 2, 4, 0, 3, 1, 1, 2, 3, 2, 3, 1, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 2, 0, 3, 3, 2, 1, 0, 1, 3, 2, 2, 4, 4, 3, 3, 2, 0, 3, 2, 2, 3, 2, 4, 0, 3, 0, 1, 2, 3, 3, 2, 2, 2, 2, 0, 2, 2, 0, 3, 3, 2, 2, 2, 2, 4, 2, 1, 0, 3, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 1, 3, 0, 3, 2, 3, 0, 3, 0, 1, 1, 3, 2, 2, 0, 2, 1, 3, 3, 2, 0, 2, 2, 3, 3, 0, 2, 2, 0, 1, 1, 2, 0, 2, 2, 2, 1, 1, 3, 3, 2, 2, 2, 3, 2, 0, 2, 3, 2, 1, 2, 0, 3, 1, 2, 3, 1, 0, 2, 2, 0, 2, 2, 3, 1, 3, 2, 1, 3, 3, 3, 1, 2, 2, 4, 2, 3, 0, 2, 0, 1, 3, 0, 2, 3, 1, 3, 3, 0, 2, 2, 0, 3, 2, 3, 1, 2, 3, 3, 3, 0, 2, 2, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 2, 2, 2, 0, 3, 0, 4, 3, 1, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 1, 0, 1, 0, 3, 0, 3, 1, 0, 4, 2, 0, 1, 1, 3, 1, 3, 0, 1, 1, 3, 2, 3, 0, 3, 3, 3, 0, 3, 3, 2, 2, 3, 3, 2, 0, 2, 2, 0, 2, 2, 3, 3, 3, 3, 2, 4, 2, 2, 0, 0, 0, 0, 2, 1, 3, 4, 4, 4, 2, 2, 3, 1, 2, 0, 2, 1, 0, 2, 2, 2, 4, 0, 2, 4, 3, 3, 2, 3, 2, 1, 3, 2, 2, 2, 2, 3, 2, 0, 3, 2, 3, 2, 2, 1, 2, 2, 0, 0, 1, 3, 3, 3, 4, 0, 0, 1, 0, 1, 4, 2, 3, 0, 1, 3, 2, 2, 3, 3, 0, 2, 0, 1, 3, 3, 4, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 1, 0, 3, 2, 2, 0, 2, 2, 1, 3, 1, 1, 3, 3, 2, 3, 3, 3, 0, 0, 3, 2, 0, 1, 0, 2, 4, 2, 0, 3, 2, 2, 3, 2, 3, 2, 0, 0, 0, 1, 3, 2, 0, 2, 4, 2, 1, 2, 2, 1, 1, 2, 2, 3, 4, 2, 4, 4, 4, 1, 0, 0, 3, 3, 4, 3, 2, 3, 1, 1, 0, 0, 2, 3, 0, 3, 1, 0, 3, 3, 3, 0, 3, 2, 3, 2, 3, 2, 3, 1, 3, 3, 2, 1, 3, 1, 3, 3, 2, 4, 4, 3, 1, 3, 2, 2, 1, 3, 0, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 1, 0, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 1, 2, 2, 3, 2, 1, 3, 0, 1, 0, 2, 3, 3, 1, 2, 3, 2, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 3, 1, 1, 2, 3, 3, 3, 0, 4, 3, 2, 2, 1, 1, 2, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 0, 3, 2, 2, 2, 3, 2, 2, 0, 2, 3, 2, 4, 2, 3, 2, 2, 3, 1, 1, 1, 2, 2, 0, 0, 0, 1, 2, 3, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 0, 2, 2, 3, 2, 2, 3, 1, 1, 4, 3, 0, 0, 2, 1, 0, 1, 4, 2, 0, 0, 2, 3, 3, 2, 1, 0, 3, 0, 3, 2, 2, 1, 1, 2, 1, 2, 3, 3, 2, 2, 3, 0, 2, 3, 4, 4, 0, 3, 2, 2, 4, 3, 0, 0, 3, 2, 1, 4, 1, 1, 2, 3, 3, 0, 4, 2, 2, 2, 0, 2, 3, 2, 0, 3, 3, 2, 3, 0, 3, 3, 1, 3, 0, 3, 1, 2, 2, 3, 2, 2, 2, 3, 0, 2, 3, 4, 1, 4, 2, 2, 2, 2, 2, 4, 0, 0, 2, 2, 2, 3, 1, 0, 0, 3, 3, 0, 3, 2, 3, 0, 1, 3, 3, 2, 0, 3, 2, 3, 3, 3, 1, 0, 4, 3, 4, 0, 3, 3, 2, 2, 2, 0, 2, 2, 2, 0, 0, 3, 0, 3, 3, 0, 3, 3, 3, 1, 1, 0, 2, 2, 2, 3, 0, 1, 0, 4, 0, 4, 0, 0, 1, 0, 4, 2, 3, 0, 2, 2, 3, 3, 2, 2, 3, 3, 3, 0, 2, 3, 2, 3, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 2, 3, 0, 2, 0, 4, 0, 3, 0, 3, 3, 3, 3, 1, 1, 0, 1, 0, 2, 2, 2, 1, 3, 2, 3, 2, 3, 1, 3, 0, 0, 2, 4, 0, 2, 2, 0, 4, 2, 1, 0, 2, 0, 3, 2, 2, 2, 3, 3, 3, 2, 1, 1, 3, 3, 3, 1, 1, 3, 2, 2, 0, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 1, 2, 2, 2, 3, 2, 2, 2, 0, 1, 2, 3, 0, 2, 2, 1, 3, 0, 0, 0, 0, 1, 2, 0, 2, 3, 3, 0, 3, 3, 0, 0, 2, 3, 0, 2, 1, 1, 3, 3, 2, 2, 1, 3, 0, 2, 2, 2, 3, 0, 3, 3, 3, 2, 3, 0, 3, 2, 0, 0, 3, 1, 2, 0, 3, 0, 3, 0, 3, 3, 2, 0, 3, 3, 3, 1, 0, 0, 3, 0, 3, 2, 0, 0, 0, 2, 2, 3, 3, 2, 2, 3, 3, 1, 3, 3, 3, 3, 2, 0, 4, 0, 2, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 2, 0, 3, 4, 0, 1, 0, 0, 0, 3, 0, 2, 3, 0, 0, 2, 2, 2, 3, 2, 1, 3, 0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 1, 3, 0, 3, 0, 2, 3, 3, 3, 1, 2, 4, 3, 1, 3, 2, 0, 2, 1, 3, 0, 4, 0, 2, 1, 3, 0, 1, 0, 3, 2, 3, 0, 2, 1, 3, 3, 1, 2, 0, 0, 0, 2, 3, 0, 1, 2, 1, 2, 0, 3, 3, 3, 1, 3, 1, 2, 2, 2, 2, 2, 0, 4, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3, 4, 2, 0, 3, 1, 2, 2, 3, 1, 2, 3, 3, 2, 3, 3, 0, 2, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 1, 4, 2, 4, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 2, 2, 2, 2, 0, 4, 2, 0, 0, 3, 0, 0, 1, 0, 0, 2, 3, 4, 0, 4, 3, 1, 0, 2, 4, 2, 3, 3, 3, 2, 0, 2, 1, 1, 3, 3, 3, 1, 1, 1, 2, 3, 3, 3, 2, 0, 2, 2, 0, 0, 1, 1, 0, 0, 3, 0, 3, 2, 2, 3, 3, 2, 2, 3, 1, 1, 2, 2, 2, 2, 1, 2, 3, 3, 0, 1, 1, 2, 1, 2, 4, 2, 1, 4, 1, 1, 1, 0, 3, 1, 4, 0, 2, 1, 2, 0, 3, 3, 0, 1, 1, 0, 4, 4, 2, 1, 2, 0, 3, 3, 3, 0, 3, 2, 0, 2, 3, 3, 3, 0, 1, 0, 3, 0, 3, 2, 0, 2, 2, 2, 1, 3, 3, 0, 4, 0, 0, 2, 3, 1, 2, 1, 0, 0, 2, 1, 2, 3, 3, 3, 0, 3, 2, 0, 0, 2, 4, 3, 3, 2, 2, 3, 1, 0, 0, 1, 1, 4, 3, 3, 0, 2, 2, 2, 4, 3, 4, 3, 0, 2, 0, 3, 0, 2, 3, 3, 0, 0, 1, 3, 0, 1, 0, 0, 0, 2, 1, 3, 0, 2, 0, 3, 2, 3, 3, 3, 2, 0, 3, 2, 1, 1, 0, 4, 0, 4, 1, 3, 3, 2, 1, 2, 0, 0, 2, 2, 4, 1, 3, 1, 1, 3, 3, 0, 3, 2, 3, 3, 3, 3, 3, 2, 1, 3, 3, 1, 3, 1, 0, 0, 3, 3, 0, 3, 4, 3, 0, 2, 0, 0, 0, 1, 1, 3, 2, 2, 0, 3, 3, 3, 2, 3, 3, 3, 1, 1, 1, 2, 2, 3, 1, 1, 3, 2, 1, 3, 2, 0, 0, 2, 0, 0, 3, 3, 0, 1, 0, 2, 2, 1, 0, 3, 0, 0, 0, 3, 1, 2, 2, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 3, 0, 3, 1, 2, 3, 4, 3, 3, 0, 3, 3, 0, 3, 0, 3, 2, 0, 3, 0, 0, 1, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 3, 3, 0, 1, 3, 2, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 3, 0, 0, 0, 1, 1, 3, 1, 0, 3, 3, 1, 4, 2, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 3, 3, 2, 1, 0, 1, 4, 1, 1, 2, 3, 1, 2, 4, 0, 1, 2, 3, 0, 2, 3, 1, 3, 3, 3, 2, 2, 2, 3, 1, 0, 3, 3, 2, 0, 4, 3, 0, 0, 2, 1, 4, 2, 1, 1, 2, 1, 0, 2, 2, 3, 3, 3, 2, 1, 2, 0, 3, 0, 1, 3, 1, 2, 2, 2, 2, 3, 2, 1, 3, 2, 3, 2, 2, 2, 0, 0, 1, 2, 0, 2, 3, 3, 2, 0, 3, 0, 3, 1, 2, 1, 3, 0, 0, 0, 3, 1, 2, 0, 0, 0, 3, 3, 2, 1, 3, 2, 4, 2, 3, 4, 2, 1, 2, 3, 0, 3, 2, 2, 3, 3, 1, 1, 3, 3, 3, 1, 2, 4, 3, 0, 1, 0, 2, 2, 0, 4, 0, 3, 1, 3, 0, 2, 1, 3, 0, 3, 0, 0, 1, 1, 3, 0, 3, 1, 3, 0, 0, 0, 2, 1, 0, 2, 1, 2, 3, 0, 0, 0, 3, 2, 2, 2, 3, 2, 3, 3, 0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 3, 2, 1, 3, 0, 2, 1, 3, 1, 3, 0, 1, 1, 2, 2, 3, 0, 0, 3, 3, 1, 3, 0, 0, 0, 2, 0, 3, 0, 0, 3, 2, 1, 2, 3, 2, 2, 3, 0, 3, 3, 3, 3, 3, 2, 0, 3, 2, 3, 0, 3, 1, 1, 0, 0, 4, 0, 2, 1, 3, 3, 3, 1, 3, 3, 3, 2, 3, 0, 2, 2, 2, 1, 2, 1, 1, 0, 0, 0, 0, 3, 3, 2, 0, 3, 0, 1, 4, 3, 1, 1, 4, 1, 2, 1, 1, 1, 3, 2, 3, 3, 0, 0, 3, 2, 1, 0, 1, 4, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 3, 3, 0, 1, 0, 2, 2, 3, 2, 3, 1, 0, 0, 2, 2, 3, 1, 1, 2, 2, 3, 0, 3, 1, 4, 3, 3, 3, 3, 2, 2, 3, 0, 2, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 0, 3, 1, 3, 0, 3, 2, 1, 1, 0, 2, 2, 2, 3, 0, 2, 0, 0, 0, 0, 3, 2, 4, 2, 2, 3, 0, 2, 2, 3, 0, 2, 2, 2, 3, 0, 3, 2, 0, 3, 0, 1, 1, 1, 2, 1, 1, 2, 0, 2, 2, 2, 2, 3, 2, 2, 2, 0, 1, 2, 3, 2, 2, 2, 3, 3, 2, 2, 0, 1, 3, 3, 2, 2, 0, 1, 1, 2, 4, 2, 2, 2, 2, 3, 3, 0, 0, 3, 4, 4, 3, 2, 0, 3, 1, 2, 2, 3, 3, 1, 2, 2, 3, 2, 3, 2, 2, 0, 1, 2, 2, 3, 2, 0, 3, 0, 0, 3, 0, 3, 0, 1, 2, 2, 0, 3, 3, 4, 2, 3, 2, 2, 0, 3, 1, 4, 4, 2, 4, 3, 2, 3, 2, 0, 3, 0, 3, 2, 1, 2, 3, 0, 1, 3, 3, 0, 4, 3, 1, 3, 3, 4, 3, 3, 1, 1, 3, 1, 1, 1, 3, 4, 2, 2, 2, 1, 0, 0, 2, 2, 4, 3, 3, 2, 0, 2, 3, 2, 3, 0, 2, 2, 3, 2, 2, 3, 3, 1, 0, 3, 2, 1, 1, 0, 0, 2, 3, 2, 3, 3, 0, 3, 2, 0, 3, 3, 0, 3, 2, 1, 2, 2, 0, 4, 3, 4, 2, 0, 3, 1, 3, 2, 2, 4, 3, 2, 3, 1, 1, 2, 2, 2, 1, 1, 3, 3, 1, 2, 3, 1, 3, 2, 2, 1, 3, 2, 3, 0, 3, 3, 4, 2, 2, 3, 1, 3, 3, 2, 3, 3, 0, 2, 1, 4, 4, 0, 3, 3, 1, 1, 2, 0, 2, 3, 2, 0, 1, 2, 0, 2, 3, 3, 3, 3, 3, 2, 2, 1, 3, 1, 2, 3, 0, 0, 3, 3, 3, 3, 2, 3, 3, 2, 2, 1, 3, 2, 1, 3, 2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 3, 2, 3, 3, 0, 0, 1, 2, 3, 4, 1, 3, 4, 2, 2, 3, 3, 2, 3, 0, 3, 4, 2, 2, 0, 1, 3, 3, 2, 3, 2, 3, 0, 3, 1, 1, 0, 0, 2, 3, 3, 4, 2, 3, 2, 2, 3, 4, 3, 0, 1, 3, 3, 3, 3, 2, 3, 1, 3, 0, 2, 2, 3, 3, 2, 2, 4, 2, 3, 2, 2, 1, 2, 3, 3, 2, 3, 1, 3, 2, 0, 2, 1, 3, 3, 3, 0, 1, 1, 2, 1, 3, 3, 3, 3, 2, 0, 0, 3, 0, 0, 2, 2, 3, 3, 3, 2, 2, 0, 0, 3, 1, 2, 2, 4, 2, 0, 3, 2, 1, 2, 2, 0, 1, 0, 2, 2, 2, 0, 0, 0, 3, 4, 2, 2, 2, 0, 4, 1, 3, 2, 1, 3, 3, 0, 2, 2, 1, 2, 2, 3, 1, 0, 2, 0, 1, 1, 2, 0, 3, 0, 2, 3, 2, 3, 2, 3, 3, 2, 0, 3, 1, 2, 3, 2, 3, 3, 3, 2, 3, 4, 2, 3, 2, 3, 0, 0, 0, 0, 1, 4, 2, 3, 3, 3, 0, 4, 2, 3, 0, 1, 2, 3, 2, 3, 2, 3, 3, 3, 1, 2, 3, 3, 2, 3, 3, 3, 1, 0, 0, 2, 3, 3, 0, 0, 0, 0, 2, 3, 1, 1, 3, 3, 2, 2, 2, 0, 2, 3, 0, 3, 0, 3, 3, 2, 3, 0, 3, 0, 4, 3, 1, 0, 3, 2, 0, 3, 1, 2, 0, 2, 0, 1, 2, 0, 1, 2, 1, 3, 2, 1, 0, 0, 1, 2, 2, 3, 0, 1, 3, 1, 0, 0, 2, 2, 0, 0, 3, 2, 3, 2, 3, 2, 2, 3, 3, 0, 3, 0, 4, 3, 1, 3, 2, 1, 2, 2, 2, 3, 4, 0, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 4, 2, 2, 2, 3, 3, 0, 4, 3, 4, 3, 3, 1, 0, 3, 3, 0, 1, 2, 2, 0, 3, 0, 0, 4, 2, 2, 0, 0, 3, 2, 3, 0, 2, 3, 2, 2, 0, 3, 2, 2, 0, 2, 3, 3, 0, 0, 2, 2, 3, 3, 2, 1, 0, 0, 4, 3, 4, 2, 3, 2, 0, 0, 3, 2, 3, 0, 2, 2, 0, 3, 3, 2, 2, 0, 2, 2, 2, 3, 3, 0, 0, 2, 4, 2, 3, 2, 3, 3, 1, 3, 3, 2, 0, 2, 1, 1, 3, 3, 3, 2, 2, 0, 3, 2, 0, 3, 2, 3, 2, 2, 0, 3, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 3, 2, 0, 2, 0, 1, 4, 2, 0, 3, 1, 2, 3, 2, 2, 0, 2, 0, 4, 3, 2, 3, 3, 0, 0, 1, 2, 2, 0, 0, 1, 1, 4, 2, 2, 2, 2, 0, 2, 2, 1, 1, 3, 3, 1, 3, 2, 2, 3, 3, 3, 2, 3, 0, 4, 3, 0, 2, 3, 0, 3, 0, 2, 1, 1, 2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 0, 0, 3, 2, 2, 2, 1, 1, 0, 0, 2, 2, 1, 3, 2, 2, 0, 3, 2, 3, 2, 2, 1, 2, 3, 0, 2, 2, 2, 2, 3, 3, 2, 0, 2, 1, 2, 2, 2, 2, 4, 3, 3, 3, 2, 0, 2, 4, 0, 1, 1, 3, 3, 2, 3, 3, 3, 3, 3, 2, 0, 2, 3, 3, 2, 0, 0, 0, 0, 2, 0, 1, 3, 3, 3, 2, 2, 1, 2, 1, 4, 1, 1, 3, 3, 2, 2, 2, 0, 1, 3, 1, 1, 3, 3, 2, 2, 2, 3, 2, 2, 4, 0, 2, 0, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 0, 1, 1, 3, 1, 0, 3, 3, 1, 2, 0, 1, 3, 2, 4, 2, 2, 1, 1, 1, 0, 2, 0, 3, 3, 3, 2, 0, 3, 3, 0, 3, 0, 4, 3, 3, 2, 1, 1, 2, 2, 0, 1, 3, 3, 3, 0, 3, 3, 3, 2, 2, 1, 0, 2, 0, 3, 3, 1, 1, 3, 3, 3, 3, 0, 3, 2, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 4, 3, 3, 2, 2, 2, 3, 0, 1, 1, 2, 0, 0, 3, 2, 3, 2, 0, 0, 2, 2, 2, 2, 1, 3, 3, 0, 3, 2, 2, 2, 2, 3, 1, 2, 3, 2, 2, 0, 2, 0, 3, 2, 2, 2, 2, 3, 0, 4, 1, 2, 3, 1, 2, 3, 3, 0, 0, 3, 2, 3, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 3, 2, 2, 2, 2, 3, 4, 3, 3, 0, 3, 0, 3, 3, 2, 2, 2, 2, 2, 3, 0, 2, 0, 2, 1, 2, 0, 0, 1, 1, 1, 3, 3, 3, 3, 0, 3, 4, 3, 1, 4, 2, 2, 0, 2, 1, 4, 1, 1, 0, 3, 3, 3, 1, 1, 3, 3, 3, 2, 1, 3, 3, 0, 2, 2, 1, 3, 1, 1, 2, 3, 0, 1, 0, 4, 0, 2, 0, 1, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 1, 1, 1, 3, 0, 1, 2, 2, 1, 3, 2, 2, 3, 2, 0, 3, 0, 2, 2, 0, 2, 2, 3, 2, 2, 3, 3, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 3, 2, 0, 2, 3, 2, 4, 2, 0, 2, 1, 1, 0, 0, 0, 3, 0, 2, 2, 3, 1, 3, 1, 1, 0, 1, 0, 3, 1, 2, 2, 0, 1, 0, 0, 0, 2, 3, 3, 3, 3, 3, 1, 0, 0, 3, 1, 2, 3, 3, 0, 4, 3, 0, 1, 1, 3, 0, 3, 2, 1, 0, 1, 1, 3, 3, 1, 0, 3, 0, 1, 3, 0, 3, 0, 3, 1, 3, 3, 2, 0, 1, 0, 4, 4, 3, 1, 1, 2, 2, 0, 0, 0, 4, 4, 0, 0, 2, 1, 2, 1, 3, 1, 2, 2, 0, 2, 2, 2, 4, 2, 3, 0, 3, 3, 2, 2, 3, 1, 3, 3, 0, 0, 0, 3, 3, 3, 2, 2, 3, 3, 0, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 1, 2, 3, 1, 4, 2, 2, 2, 0, 1, 1, 2, 1, 3, 3, 3, 2, 4, 0, 0, 1, 1, 4, 3, 2, 0, 3, 2, 1, 0, 2, 2, 2, 3, 0, 2, 3, 2, 3, 3, 1, 0, 4, 0, 3, 3, 2, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 0, 4, 3, 4, 1, 3, 2, 1, 3, 3, 1, 4, 0, 1, 3, 0, 1, 4, 3, 1, 3, 2, 4, 3, 3, 3, 3, 2, 1, 1, 0, 3, 0, 3, 4, 3, 2, 0, 3, 0, 0, 0, 3, 2, 2, 2, 0, 3, 3, 2, 2, 3, 2, 3, 1, 1, 3, 3, 2, 2, 3, 3, 3, 4, 4, 1, 3, 0, 0, 2, 2, 2, 3, 0, 2, 3, 4, 2, 0, 3, 3, 3, 3, 2, 2, 2, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 3, 1, 2, 2, 2, 4, 3, 1, 3, 2, 2, 2, 1, 3, 2, 0, 2, 2, 3, 3, 4, 1, 2, 0, 1, 3, 0, 2, 0, 0, 1, 0, 3, 2, 3, 1, 3, 1, 1, 1, 2, 2, 2, 0, 1, 3, 2, 1, 4, 3, 3, 3, 1, 0, 2, 3, 1, 3, 1, 2, 3, 1, 0, 0, 3, 3, 2, 1, 1, 1, 3, 0, 3, 3, 0, 0, 0, 2, 4, 3, 0, 2, 2, 1, 0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 0, 0, 2, 4, 4, 2, 0, 1, 3, 2, 0, 3, 2, 2, 2, 2, 0, 2, 3, 0, 0, 0, 2, 2, 1, 2, 3, 0, 0, 1, 3, 0, 4, 0, 0, 3, 1, 3, 3, 0, 2, 1, 1, 0, 2, 0, 1, 2, 3, 3, 2, 3, 4, 1, 0, 1, 2, 3, 3, 0, 3, 0, 3, 4, 0, 1, 0, 3, 3, 4, 4, 0, 3, 4, 3, 3, 3, 3, 0, 3, 3, 3, 0, 2, 1, 0, 0, 3, 1, 2, 2, 0, 4, 3, 3, 1, 1, 2, 3, 3, 1, 0, 3, 3, 1, 2, 0, 3, 2, 2, 2, 1, 2, 1, 3, 1, 3, 2, 0, 2, 3, 0, 0, 2, 2, 1, 2, 3, 3, 0, 3, 1, 2, 2, 0, 1, 2, 3, 3, 2, 3, 1, 1, 1, 0, 1, 3, 3, 3, 1, 3, 1, 2, 2, 1, 2, 3, 2, 1, 3, 2, 2, 4, 0, 3, 0, 2, 3, 3, 0, 4, 2, 2, 3, 2, 2, 3, 4, 4, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 1, 2, 1, 4, 4, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 0, 3, 2, 3, 1, 1, 1, 0, 0, 2, 2, 1, 2, 0, 2, 3, 0, 2, 0, 2, 2, 3, 2, 1, 1, 4, 2, 0, 2, 4, 3, 3, 2, 2, 0, 0, 2, 2, 3, 3, 3, 1, 2, 3, 4, 3, 0, 0, 2, 3, 0, 3, 3, 3, 2, 1, 1, 2, 0, 3, 3, 3, 3, 2, 2, 2, 1, 2, 0, 3, 1, 0, 3, 3, 0, 0, 3, 3, 2, 2, 0, 2, 4, 4, 1, 2, 2, 0, 2, 1, 2, 1, 4, 2, 3, 3, 1, 3, 0, 0, 0, 3, 0, 2, 2, 2, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 1, 1, 1, 1, 3, 0, 2, 0, 3, 0, 3, 3, 1, 2, 2, 3, 2, 2, 2, 1, 2, 1, 0, 0, 3, 2, 0, 2, 2, 1, 1, 2, 0, 3, 0, 4, 1, 1, 1, 3, 2, 2, 3, 2, 3, 2, 3, 0, 0, 2, 0, 0, 3, 3, 2, 2, 3, 1, 2, 3, 0, 0, 4, 3, 3, 0, 3, 1, 1, 3, 2, 2, 2, 2, 1, 3, 2, 3, 3, 0, 2, 1, 2, 0, 0, 1, 0, 3, 1, 1, 3, 2, 0, 0, 3, 0, 2, 2, 0, 0, 3, 2, 2, 2, 2, 2, 0, 2, 0, 2, 3, 0, 3, 3, 2, 3, 3, 3, 1, 3, 2, 0, 2, 3, 3, 4, 2, 2, 2, 2, 1, 1, 2, 0, 1, 3, 3, 1, 2, 2, 2, 2, 3, 3, 0, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 1, 2, 2, 3, 2, 0, 3, 3, 3, 3, 4, 1, 3, 4, 3, 0, 2, 2, 1, 0, 2, 1, 2, 0, 2, 3, 0, 2, 0, 3, 4, 3, 3, 1, 2, 0, 2, 2, 3, 0, 0, 3, 3, 1, 3, 3, 4, 4, 2, 0, 0, 3, 2, 2, 3, 3, 4, 0, 0, 3, 3, 0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 1, 1, 2, 3, 2, 2, 3, 3, 0, 3, 3, 4, 1, 3, 3, 2, 3, 0, 1, 3, 1, 0, 3, 2, 2, 2, 2, 2, 3, 3, 2, 2, 0, 1, 1, 0, 4, 0, 2, 3, 0, 3, 0, 3, 3, 4, 1, 2, 3, 3, 2, 3, 0, 2, 0, 3, 4, 2, 2, 2, 3, 1, 1, 4, 1, 1, 1, 0, 2, 3, 0, 2, 2, 2, 0, 3, 4, 2, 0, 2, 1, 0, 2, 1, 1, 2, 0, 4, 2, 1, 0, 0, 1, 2, 2, 3, 3, 1, 3, 2, 0, 0, 2, 0, 1, 3, 3, 0, 3, 3, 3, 2, 0, 2, 2, 0, 4, 0, 3, 3, 3, 1, 3, 3, 1, 3, 3, 2, 1, 0, 3, 2, 1, 2, 3, 2, 2, 3, 2, 2, 1, 4, 0, 2, 3, 3, 3, 3, 3, 1, 0, 2, 4, 1, 1, 1, 2, 0, 1, 4, 1, 2, 2, 2, 2, 4, 3, 0, 2, 3, 3, 3, 2, 2, 4, 0, 3, 2, 2, 1, 4, 0, 2, 1, 4, 3, 1, 3, 1, 0, 0, 0, 3, 2, 3, 3, 3, 3, 2, 2, 0, 1, 0, 3, 3, 2, 1, 3, 0, 2, 1, 3, 3, 2, 3, 0, 0, 2, 1, 3, 2, 0, 3, 2, 3, 3, 1, 0, 1, 2, 1, 0, 3, 1, 2, 3, 4, 1, 2, 3, 0, 2, 0, 0, 3, 1, 3, 0, 3, 3, 0, 0, 0, 4, 1, 1, 3, 3, 3, 0, 0, 2, 2, 0, 2, 3, 3, 2, 0, 2, 2, 2, 2, 1, 3, 2, 3, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 3, 2, 3, 1, 3, 4, 3, 0, 1, 2, 0, 2, 2, 1, 0, 2, 3, 2, 3, 3, 2, 1, 3, 2, 0, 2, 1, 3, 2, 1, 2, 0, 2, 1, 3, 2, 3, 4, 2, 3, 2, 2, 0, 3, 2, 3, 2, 0, 3, 3, 3, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 3, 4, 0, 3, 4, 3, 2, 3, 1, 1, 3, 1, 2, 2, 3, 3, 2, 1, 1, 2, 4, 3, 2, 2, 3, 2, 0, 2, 2, 3, 2, 1, 2, 2, 3, 3, 2, 2, 2, 2, 3, 0, 2, 3, 2, 3, 1, 1, 3, 2, 3, 3, 2, 2, 2, 4, 2, 3, 2, 4, 2, 0, 2, 4, 3, 1, 3, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 0, 0, 3, 3, 2, 3, 2, 1, 0, 0, 2, 3, 1, 0, 2, 0, 3, 3, 2, 0, 3, 1, 0, 0, 3, 3, 2, 2, 3, 3, 2, 1, 1, 3, 2, 3, 3, 3, 3, 2, 2, 3, 2, 4, 2, 4, 2, 1, 3, 3, 2, 2, 3, 0, 3, 1, 2, 3, 0, 2, 0, 1, 1, 2, 3, 2, 4, 1, 2, 1, 3, 2, 4, 3, 2, 2, 3, 3, 2, 3, 3, 3, 0, 2, 3, 1, 0, 2, 3, 3, 0, 3, 1, 1, 3, 3, 3, 1, 3, 3, 2, 2, 2, 1, 3, 3, 0, 2, 0, 3, 2, 3, 3, 0, 0, 3, 1, 3, 2, 3, 2, 3, 2, 3, 0, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 4, 0, 2, 2, 1, 2, 0, 1, 3, 1, 0, 3, 2, 2, 2, 2, 0, 3, 0, 3, 3, 2, 1, 2, 3, 0, 4, 3, 1, 3, 3, 3, 4, 0, 1, 2, 3, 2, 3, 1, 3, 0, 3, 3, 1, 3, 3, 3, 0, 3, 3, 2, 2, 3, 0, 3, 1, 0, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 0, 2, 1, 3, 2, 2, 0, 3, 3, 1, 2, 2, 2, 3, 3, 0, 3, 2, 2, 4, 3, 3, 2, 3, 1, 2, 0, 2, 0, 2, 1, 1, 1, 3, 0, 0, 2, 1, 1, 2, 3, 3, 3, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 1, 2, 2, 0, 3, 2, 3, 4, 1, 0, 0, 2, 2, 0, 2, 3, 3, 4, 3, 2, 1, 3, 1, 3, 2, 3, 3, 3, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 3, 2, 2, 1, 2, 2, 3, 0, 4, 3, 3, 2, 2, 3, 3, 2, 1, 0, 1, 3, 2, 0, 2, 2, 2, 0, 3, 3, 3, 2, 2, 0, 1, 1, 1, 1, 3, 3, 1, 1, 2, 3, 2, 2, 2, 1, 2, 2, 0, 3, 4, 1, 0, 2, 0, 2, 3, 3, 0, 2, 0, 1, 2, 2, 2, 2, 0, 3, 2, 2, 1, 3, 1, 4, 2, 3, 3, 3, 2, 1, 2, 0, 3, 1, 1, 3, 3, 1, 3, 1, 2, 0, 3, 1, 2, 1, 3, 3, 1, 0, 2, 3, 3, 3, 2, 1, 1, 3, 3, 1, 2, 0, 0, 0, 2, 0, 0, 4, 3, 0, 2, 0, 0, 1, 2, 3, 3, 3, 0, 2, 1, 2, 2, 4, 1, 2, 3, 0, 2, 3, 3, 1, 1, 3, 0, 1, 3, 2, 2, 0, 4, 3, 4, 0, 4, 0, 2, 1, 4, 3, 2, 3, 2, 0, 4, 2, 3, 2, 3, 3, 3, 0, 2, 2, 1, 0, 3, 3, 3, 3, 2, 2, 2, 3, 4, 3, 0, 3, 4, 3, 3, 1, 3, 3, 2, 2, 2, 3, 0, 0, 2, 3, 0, 2, 2, 1, 0, 2, 2, 3, 0, 2, 1, 3, 3, 0, 3, 1, 1, 2, 2, 0, 3, 0, 2, 3, 3, 3, 2, 2, 2, 0, 4, 2, 4, 3, 0, 2, 0, 3, 3, 0, 3, 3, 1, 3, 3, 2, 2, 3, 0, 0, 3, 1, 4, 2, 3, 3, 2, 1, 3, 3, 1, 0, 3, 1, 0, 1, 0, 3, 0, 0, 3, 2, 3, 3, 3, 2, 3, 3, 3, 4, 4, 2, 2, 2, 4, 3, 0, 3, 1, 1, 1, 3, 2, 2, 3, 3, 0, 0, 3, 0, 0, 1, 4, 1, 2, 2, 4, 2, 0, 0, 3, 2, 3, 3, 3, 1, 2, 0, 1, 1, 0, 0, 3, 3, 0, 0, 1, 0, 2, 2, 3, 1, 0, 3, 1, 3, 2, 3, 3, 0, 2, 2, 2, 2, 0, 1, 2, 2, 1, 1, 1, 2, 3, 2, 0, 2, 0, 3, 3, 3, 2, 0, 2, 3, 4, 2, 3, 0, 1, 0, 0, 2, 3, 4, 2, 3, 0, 2, 3, 3, 3, 1, 0, 3, 3, 3, 4, 3, 3, 3, 3, 2, 4, 2, 3, 0, 2, 1, 3, 1, 2, 2, 3, 3, 3, 2, 2, 0, 2, 4, 1, 1, 3, 4, 2, 3, 1, 3, 3, 1, 2, 2, 3, 1, 2, 1, 2, 2, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 2, 3, 0, 2, 2, 0, 1, 4, 2, 2, 3, 2, 2, 2, 0, 2, 3, 0, 1, 0, 3, 3, 2, 4, 2, 1, 1, 2, 0, 1, 2, 0, 1, 0, 0, 3, 3, 2, 1, 0, 4, 0, 2, 3, 2, 3, 4, 4, 1, 0, 2, 1, 0, 2, 2, 2, 0, 3, 1, 4, 2, 3, 3, 3, 1, 3, 3, 2, 2, 2, 2, 3, 4, 3, 3, 0, 0, 3, 4, 2, 1, 3, 0, 3, 0, 2, 2, 3, 3, 0, 3, 3, 4, 2, 1, 1, 3, 3, 4, 3, 3, 3, 0, 3, 3, 4, 3, 1, 2, 2, 2, 0, 3, 3, 2, 0, 3, 1, 4, 3, 0, 1, 2, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 1, 3, 3, 3, 3, 2, 1, 2, 3, 0, 0, 2, 4, 3, 2, 3, 0, 2, 2, 2, 0, 2, 0, 3, 2, 3, 0, 3, 3, 0, 3, 0, 0, 2, 0, 3, 2, 1, 3, 2, 4, 3, 4, 4, 1, 3, 2, 2, 0, 3, 3, 1, 2, 0, 3, 2, 2, 2, 0, 3, 2, 3, 3, 2, 4, 1, 0, 3, 2, 3, 2, 0, 3, 1, 2, 2, 0, 0, 1, 1, 4, 1, 1, 2, 2, 1, 2, 4, 0, 0, 3, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 2, 0, 4, 3, 2, 4, 3, 2, 3, 3, 3, 2, 1, 3, 0, 3, 2, 1, 2, 3, 2, 3, 3, 3, 2, 3, 2, 0, 3, 2, 4, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 4, 3, 2, 0, 3, 2, 3, 2, 0, 4, 1, 0, 0, 2, 2, 2, 3, 3, 1, 1, 3, 2, 1, 4, 1, 2, 3, 2, 0, 0, 2, 0, 3, 0, 2, 4, 4, 2, 2, 2, 3, 0, 3, 3, 2, 3, 4, 3, 0, 4, 3, 0, 3, 0, 2, 2]\n",
            "Predicted Labels: [0 0 0 ... 0 0 0]\n",
            "Unique Predicted Labels: [0]\n",
            "Test Dataset Labels: [0 1 2 3 4]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"predicted_labels = results.predictions[0].argmax(axis=1)\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "true_labels = np.array(test_dataset.labels).flatten()\"\"\"\n",
        "\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "print(\"Unique Predicted Labels:\", np.unique(predicted_labels))\n",
        "print(\"Test Dataset Labels:\", np.unique(test_dataset.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nbm1CKoj0UKX",
        "outputId": "64dcafc2-f95e-446b-b767-8515c653ff90"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-676cbab762d7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate AUROC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUROC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         return _multiclass_roc_auc_score(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \"\"\"\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         raise ValueError(\n\u001b[1;32m    640\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#predicted_probs = torch.nn.functional.softmax(torch.tensor(predicted_labels), dim=-1).numpy()\n",
        "\n",
        "# Calculate AUROC\n",
        "auroc = roc_auc_score(true_labels, predicted_labels, multi_class='ovr')\n",
        "print(\"AUROC:\", auroc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyPdmMFOIWW26N74KQnvxjcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}