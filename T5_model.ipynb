{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rStwlHrXSZ4J0G3L9CeN7wplUcplt_oq",
      "authorship_tag": "ABX9TyNnZtKSWqrgCXoUoC58MWHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG5CqGQmBqRb"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ],
      "metadata": {
        "id": "06Tol0fmDCHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/checkpoint_epoch_{epoch}.pth'\n",
        "best_model_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/best_model.pth'\n",
        "\n",
        "\n",
        "# Saving the checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, loss, val_loss, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    if is_best:\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ],
      "metadata": {
        "id": "9WgPciFiDVGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label_columns here\n",
        "label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\n",
        "\n",
        "sbdh_substance = {\n",
        "    0: 'None',\n",
        "    1: 'Present',\n",
        "    2: 'Past',\n",
        "    3: 'Never',\n",
        "    4: 'Unsure'\n",
        "}\n",
        "\n",
        "sbdh_econ_env = {\n",
        "    0: 'None',\n",
        "    1: 'True',\n",
        "    2: 'False',\n",
        "}\n",
        "\n",
        "sbdh_community_ed = {\n",
        "    0: 'False',\n",
        "    1: 'True',\n",
        "}\n",
        "\n",
        "dataset['sdoh_community_present'] = dataset.sdoh_community_present.map(sbdh_community_ed)\n",
        "\n",
        "num_labels = len(sbdh_community_ed)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NproI6UhDYMe",
        "outputId": "33ed28bb-757f-4ff2-f9a6-cbddd4306698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ],
      "metadata": {
        "id": "-5MzK5JUDa5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"sdoh_community_present\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ],
      "metadata": {
        "id": "JbV0EkAgDa7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ],
      "metadata": {
        "id": "gOLRb3L_Da-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: change label to float for sdoh_economics, sdoh_environment\n",
        "\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "\n",
        "            # item['labels'] = torch.tensor(float(self.labels[idx]))\n",
        "            item['labels'] = self.labels[idx]\n",
        "\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "owFtkulLDbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ],
      "metadata": {
        "id": "xJMA7k23DbD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ],
      "metadata": {
        "id": "ZQrcuigaDbGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\n",
        "#label_columns = ['behavior_alcohol']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_drug\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=3)\n",
        "\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "      output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "      logging_strategy='epoch',  # characterize as epoch\n",
        "      num_train_epochs=20, # have high epoch\n",
        "      #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "      per_device_train_batch_size=64, #reduced batch size\n",
        "      per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "      save_strategy= 'epoch',\n",
        "      warmup_steps=500,\n",
        "      weight_decay=0.02,\n",
        "      logging_dir= tensor_logs,  # change to tensor logs\n",
        "      #eval_steps=100,\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      #accumulate gradients over 4 steps\n",
        "      #gradient_accumulation_steps = 4\n",
        "      load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "      metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "      greater_is_better=False,  # Set to False because a lower loss is better\n",
        "      learning_rate=5e-6,\n",
        "      lr_scheduler_type='linear',\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        "      #callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Save checkpoint after every epoch\n",
        "#save_checkpoint(model, optimizer, epoch, current_loss, current_val_loss, is_best=False)\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EPLvBH8qDlTm",
        "outputId": "15d1c4cb-8c6e-4909-e559-bd762297e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1760' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1760/1760 20:50, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.724900</td>\n",
              "      <td>0.611772</td>\n",
              "      <td>0.668327</td>\n",
              "      <td>0.596037</td>\n",
              "      <td>0.674467</td>\n",
              "      <td>0.668327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.585800</td>\n",
              "      <td>0.469987</td>\n",
              "      <td>0.757295</td>\n",
              "      <td>0.729272</td>\n",
              "      <td>0.780813</td>\n",
              "      <td>0.757295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.455300</td>\n",
              "      <td>0.416253</td>\n",
              "      <td>0.809253</td>\n",
              "      <td>0.794472</td>\n",
              "      <td>0.827942</td>\n",
              "      <td>0.809253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.366400</td>\n",
              "      <td>0.344892</td>\n",
              "      <td>0.874733</td>\n",
              "      <td>0.871449</td>\n",
              "      <td>0.877559</td>\n",
              "      <td>0.874733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.311600</td>\n",
              "      <td>0.297195</td>\n",
              "      <td>0.895374</td>\n",
              "      <td>0.893476</td>\n",
              "      <td>0.896733</td>\n",
              "      <td>0.895374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.396289</td>\n",
              "      <td>0.866904</td>\n",
              "      <td>0.859992</td>\n",
              "      <td>0.881577</td>\n",
              "      <td>0.866904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.254600</td>\n",
              "      <td>0.277825</td>\n",
              "      <td>0.902491</td>\n",
              "      <td>0.902630</td>\n",
              "      <td>0.902817</td>\n",
              "      <td>0.902491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.226900</td>\n",
              "      <td>0.254106</td>\n",
              "      <td>0.911032</td>\n",
              "      <td>0.910313</td>\n",
              "      <td>0.910829</td>\n",
              "      <td>0.911032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.208200</td>\n",
              "      <td>0.255457</td>\n",
              "      <td>0.909609</td>\n",
              "      <td>0.909474</td>\n",
              "      <td>0.909387</td>\n",
              "      <td>0.909609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.190900</td>\n",
              "      <td>0.256236</td>\n",
              "      <td>0.913879</td>\n",
              "      <td>0.913312</td>\n",
              "      <td>0.913592</td>\n",
              "      <td>0.913879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.185500</td>\n",
              "      <td>0.261778</td>\n",
              "      <td>0.915302</td>\n",
              "      <td>0.914618</td>\n",
              "      <td>0.915176</td>\n",
              "      <td>0.915302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.267335</td>\n",
              "      <td>0.916014</td>\n",
              "      <td>0.915183</td>\n",
              "      <td>0.916155</td>\n",
              "      <td>0.916014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.258814</td>\n",
              "      <td>0.911744</td>\n",
              "      <td>0.911707</td>\n",
              "      <td>0.911674</td>\n",
              "      <td>0.911744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.150900</td>\n",
              "      <td>0.297625</td>\n",
              "      <td>0.911744</td>\n",
              "      <td>0.910007</td>\n",
              "      <td>0.914349</td>\n",
              "      <td>0.911744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.143700</td>\n",
              "      <td>0.264040</td>\n",
              "      <td>0.921708</td>\n",
              "      <td>0.920892</td>\n",
              "      <td>0.922073</td>\n",
              "      <td>0.921708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.139000</td>\n",
              "      <td>0.262423</td>\n",
              "      <td>0.917438</td>\n",
              "      <td>0.916749</td>\n",
              "      <td>0.917381</td>\n",
              "      <td>0.917438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.129300</td>\n",
              "      <td>0.270332</td>\n",
              "      <td>0.919573</td>\n",
              "      <td>0.919310</td>\n",
              "      <td>0.919273</td>\n",
              "      <td>0.919573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.136400</td>\n",
              "      <td>0.272011</td>\n",
              "      <td>0.918149</td>\n",
              "      <td>0.917611</td>\n",
              "      <td>0.917924</td>\n",
              "      <td>0.918149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.128000</td>\n",
              "      <td>0.272008</td>\n",
              "      <td>0.918149</td>\n",
              "      <td>0.917570</td>\n",
              "      <td>0.917966</td>\n",
              "      <td>0.918149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.123300</td>\n",
              "      <td>0.274532</td>\n",
              "      <td>0.918149</td>\n",
              "      <td>0.917570</td>\n",
              "      <td>0.917966</td>\n",
              "      <td>0.918149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.2541063725948334, 'eval_accuracy': 0.9110320284697508, 'eval_f1': 0.9103127636376075, 'eval_precision': 0.9108294338696495, 'eval_recall': 0.9110320284697508, 'eval_runtime': 4.7393, 'eval_samples_per_second': 296.458, 'eval_steps_per_second': 4.642, 'epoch': 20.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install transformers[torch]"
      ],
      "metadata": {
        "id": "RpNv0t_YDlWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install accelerate -U"
      ],
      "metadata": {
        "id": "itmPRdU0DlYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/20240315_041945/checkpoint-704\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['0', '1']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f6c4-27qGjMF",
        "outputId": "a0ad99dd-5993-4153-8d2c-708ea0e836c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-fa0b3b671f5d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[ 3.839839  , -4.3977637 ],\n",
            "       [ 2.0809374 , -2.0957348 ],\n",
            "       [-3.2345712 ,  3.7993314 ],\n",
            "       ...,\n",
            "       [-3.5753    ,  4.3370967 ],\n",
            "       [-3.360735  ,  4.2148614 ],\n",
            "       [ 0.24131553, -0.41713858]], dtype=float32), array([[[-2.40248263e-01, -1.81958961e+00,  1.24431539e+00, ...,\n",
            "          7.69307315e-01, -1.50773278e-03,  3.53687018e-01],\n",
            "        [-1.77006817e+00, -1.97040543e-01,  7.73607552e-01, ...,\n",
            "          3.12140495e-01,  1.22404361e+00, -1.97641999e-01],\n",
            "        [-1.53535157e-01, -8.06585774e-02,  1.15058236e-02, ...,\n",
            "          3.06435645e-01, -7.82480836e-01, -6.17570849e-03],\n",
            "        ...,\n",
            "        [-1.46141088e+00,  2.55656153e-01,  5.65618813e-01, ...,\n",
            "         -2.88824499e-01,  8.25519621e-01, -7.22157359e-01],\n",
            "        [-1.46138597e+00,  2.47528523e-01,  5.80571949e-01, ...,\n",
            "         -2.89777070e-01,  8.16525102e-01, -7.37143338e-01],\n",
            "        [-1.45096815e+00,  2.50930816e-01,  5.79260886e-01, ...,\n",
            "         -2.90130824e-01,  8.29640925e-01, -7.33545721e-01]],\n",
            "\n",
            "       [[-1.04444695e+00, -1.00069928e+00,  7.48708725e-01, ...,\n",
            "          1.53056347e+00, -2.76127368e-01,  1.22919893e+00],\n",
            "        [-1.53644538e+00,  8.32684457e-01, -8.74391794e-01, ...,\n",
            "          2.84961176e+00, -6.94006026e-01,  3.69147003e-01],\n",
            "        [-5.38073123e-01,  3.12475979e-01,  3.85070473e-01, ...,\n",
            "          1.94065845e+00,  5.38484454e-01, -1.13064954e-02],\n",
            "        ...,\n",
            "        [-1.52006507e+00,  7.43976116e-01,  7.81966984e-01, ...,\n",
            "          1.25213897e+00,  8.72961164e-01, -1.03934073e+00],\n",
            "        [-1.51336586e+00,  7.42087662e-01,  7.89563000e-01, ...,\n",
            "          1.25609696e+00,  8.75849605e-01, -1.03971541e+00],\n",
            "        [-1.51320505e+00,  7.43931234e-01,  7.88615227e-01, ...,\n",
            "          1.25670838e+00,  8.72946858e-01, -1.03995574e+00]],\n",
            "\n",
            "       [[ 9.89308596e-01,  1.36998698e-01,  1.42899543e-01, ...,\n",
            "          9.36076939e-01, -1.36775720e+00,  1.03517640e+00],\n",
            "        [-9.97547284e-02, -3.11091870e-01,  1.19820070e+00, ...,\n",
            "          1.59512889e+00,  3.68850052e-01,  7.74997890e-01],\n",
            "        [-3.43849123e-01, -1.38633871e+00,  1.49248064e+00, ...,\n",
            "          2.29363728e+00, -1.44197464e+00,  1.69461608e+00],\n",
            "        ...,\n",
            "        [-9.26012874e-01, -1.48019993e+00,  5.46755314e-01, ...,\n",
            "          1.25581646e+00,  2.06277892e-01,  1.49642944e-01],\n",
            "        [ 5.07609919e-02, -7.34460056e-01,  4.78319466e-01, ...,\n",
            "          1.00556284e-01, -2.27108812e+00,  5.66352189e-01],\n",
            "        [-1.43606794e+00, -4.04624075e-01,  1.42816913e+00, ...,\n",
            "          1.01803946e+00,  1.02256119e+00, -4.10992391e-02]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[-5.55827133e-02, -2.94344932e-01,  1.95410085e+00, ...,\n",
            "          1.01147044e+00, -6.77186787e-01,  1.72403610e+00],\n",
            "        [ 4.54601735e-01, -1.37430501e+00,  2.51560926e+00, ...,\n",
            "          1.76826167e+00, -6.78438604e-01, -3.54824215e-01],\n",
            "        [ 2.71824032e-01, -3.59941930e-01,  1.30077994e+00, ...,\n",
            "          1.57375646e+00,  3.47782761e-01,  8.67600083e-01],\n",
            "        ...,\n",
            "        [-1.74713171e+00,  1.93962216e-01,  1.34249973e+00, ...,\n",
            "          9.92384136e-01,  1.14443791e+00, -3.84627491e-01],\n",
            "        [-1.74897802e+00,  1.96452871e-01,  1.34396446e+00, ...,\n",
            "          9.96710122e-01,  1.15155101e+00, -3.79158437e-01],\n",
            "        [-1.75293469e+00,  1.93487421e-01,  1.34027803e+00, ...,\n",
            "          9.90874410e-01,  1.15217316e+00, -3.81671637e-01]],\n",
            "\n",
            "       [[-4.03860301e-01,  3.91871244e-01,  2.97310710e+00, ...,\n",
            "          2.06998277e+00, -3.03989172e-01, -5.08116603e-01],\n",
            "        [-5.32016978e-02, -9.56630290e-01,  6.11137390e-01, ...,\n",
            "          2.43045568e+00,  6.32799506e-01, -7.92905092e-01],\n",
            "        [-4.15584892e-01, -3.86766016e-01,  1.02224374e+00, ...,\n",
            "          2.08330417e+00, -2.45988056e-01, -1.04585938e-01],\n",
            "        ...,\n",
            "        [-2.01908922e+00,  1.15013504e+00,  8.48012805e-01, ...,\n",
            "          9.99801159e-01,  1.75057995e+00, -1.09305167e+00],\n",
            "        [-2.01993060e+00,  1.15231061e+00,  8.49248469e-01, ...,\n",
            "          1.00051749e+00,  1.75019622e+00, -1.09309185e+00],\n",
            "        [-2.01785398e+00,  1.15192127e+00,  8.51851702e-01, ...,\n",
            "          9.99944389e-01,  1.74835408e+00, -1.09154510e+00]],\n",
            "\n",
            "       [[-1.01418841e+00, -8.08268905e-01, -3.98420244e-01, ...,\n",
            "          2.01754355e+00, -8.92617047e-01,  4.43245113e-01],\n",
            "        [-3.35147053e-01, -1.72958657e-01,  1.25806034e+00, ...,\n",
            "          1.31229413e+00, -1.80515635e+00,  6.03737414e-01],\n",
            "        [-1.49841690e+00, -1.65441048e+00,  6.95123792e-01, ...,\n",
            "          1.01968670e+00, -3.94322813e-01,  9.07942355e-01],\n",
            "        ...,\n",
            "        [ 5.28126061e-01, -1.67786670e+00,  5.32115519e-01, ...,\n",
            "          1.66989708e+00, -7.16312349e-01, -9.00108144e-02],\n",
            "        [-3.00878823e-01,  3.48504335e-02,  1.74983799e+00, ...,\n",
            "          1.69357157e+00,  9.83519018e-01, -6.36833489e-01],\n",
            "        [-4.45361972e-01, -6.02908313e-01, -5.24742901e-01, ...,\n",
            "          4.35209572e-01, -2.06495667e+00, -9.12774727e-02]]],\n",
            "      dtype=float32)), label_ids=array([0, 0, 1, ..., 1, 1, 1]), metrics={'test_loss': 0.1922892928123474, 'test_accuracy': 0.9336654804270462, 'test_f1': 0.9332589256926748, 'test_precision': 0.9336158393664893, 'test_recall': 0.9336654804270462, 'test_runtime': 22.5299, 'test_samples_per_second': 311.809, 'test_steps_per_second': 4.882})\n",
            "Test Results: {'eval_loss': 0.1922892928123474, 'eval_accuracy': 0.9336654804270462, 'eval_f1': 0.9332589256926748, 'eval_precision': 0.9336158393664893, 'eval_recall': 0.9336654804270462, 'eval_runtime': 23.9428, 'eval_samples_per_second': 293.407, 'eval_steps_per_second': 4.594, 'epoch': 20.0}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.91      2562\n",
            "           1       0.93      0.96      0.95      4463\n",
            "\n",
            "    accuracy                           0.93      7025\n",
            "   macro avg       0.93      0.92      0.93      7025\n",
            "weighted avg       0.93      0.93      0.93      7025\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU7gSjQtGjQj",
        "outputId": "6bdd08da-221e-4b15-d770-9df184830008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision    Recall  F1 Score\n",
            "0  0.933665   0.933616  0.933665  0.933259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"predicted_labels = results.predictions[0].argmax(axis=1)\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "true_labels = np.array(test_dataset.labels).flatten()\"\"\"\n",
        "\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "print(\"Unique Predicted Labels:\", np.unique(predicted_labels))\n",
        "print(\"Test Dataset Labels:\", np.unique(test_dataset.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RAlzsy0GjV6",
        "outputId": "220c7fe8-a50d-4e9c-c337-4e85b69eb262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels: [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
            "Predicted Labels: [0 0 1 ... 1 1 0]\n",
            "Unique Predicted Labels: [0 1]\n",
            "Test Dataset Labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "logits = results.predictions[0]\n",
        "probabilities = torch.softmax(torch.from_numpy(logits), dim=-1).numpy()\n",
        "\n",
        "# Extract probabilities for the positive class\n",
        "prob = probabilities[:, 1]\n",
        "\n",
        "# Calculate AUROC\n",
        "auroc = roc_auc_score(true_labels, prob)\n",
        "\n",
        "print(f\"AUROC: {auroc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL14caXeG7sl",
        "outputId": "8636bb07-8b93-44ef-c7f3-ba9963550857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC: 0.9763784210289722\n"
          ]
        }
      ]
    }
  ]
}