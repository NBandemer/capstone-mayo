{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ],
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/checkpoint_epoch_{epoch}.pth'\n",
        "best_model_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/best_model.pth'\n",
        "\n",
        "\n",
        "# Saving the checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, loss, val_loss, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    if is_best:\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "csqlu1lfu2n-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc3c051-45f7-4457-acae-854908c8baac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_environment']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"sdoh_environment\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: change label to float for sdoh_economics, sdoh_environment\n",
        "\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(float(self.labels[idx]))\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i8-ZZN5mu286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dce2882-480d-4174-b8cd-ad50c606472d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [616/616 07:09, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.307300</td>\n",
              "      <td>0.140760</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>0.184303</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.109800</td>\n",
              "      <td>0.099629</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.087700</td>\n",
              "      <td>0.059491</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.063700</td>\n",
              "      <td>0.045229</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.044200</td>\n",
              "      <td>0.049323</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.036100</td>\n",
              "      <td>0.036742</td>\n",
              "      <td>0.370819</td>\n",
              "      <td>0.200619</td>\n",
              "      <td>0.137506</td>\n",
              "      <td>0.370819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.03674153611063957, 'eval_accuracy': 0.3708185053380783, 'eval_f1': 0.2006193575089707, 'eval_precision': 0.13750636390116638, 'eval_recall': 0.3708185053380783, 'eval_runtime': 4.6918, 'eval_samples_per_second': 299.458, 'eval_steps_per_second': 4.689, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "      output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "      logging_strategy='epoch',  # characterize as epoch\n",
        "      num_train_epochs=7, # have high epoch\n",
        "      #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "      per_device_train_batch_size=64, #reduced batch sie\n",
        "      per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "      save_strategy= 'epoch',\n",
        "      warmup_steps=500,\n",
        "      weight_decay=1e-5,\n",
        "      logging_dir= tensor_logs,  # change to tensor logs\n",
        "      #eval_steps=100,\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      #accumulate gradients over 4 steps\n",
        "      #gradient_accumulation_steps = 4\n",
        "      load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "      metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "      greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Save checkpoint after every epoch\n",
        "#save_checkpoint(model, optimizer, epoch, current_loss, current_val_loss, is_best=False)\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]"
      ],
      "metadata": {
        "id": "qvHjlczRfoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "2y3hG9frfp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['0', '1', '2']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ],
      "metadata": {
        "id": "yxR5iKE9QHH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df648ee1-6921-48a0-be95-348cee29957c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-15-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[-0.01427577],\n",
            "       [-0.07066951],\n",
            "       [ 0.9734494 ],\n",
            "       ...,\n",
            "       [ 2.1795232 ],\n",
            "       [-0.01989568],\n",
            "       [ 0.00417323]], dtype=float32), array([[[ 0.06329268,  0.42046323,  0.37138128, ..., -0.16738361,\n",
            "         -0.6861401 , -0.03792708],\n",
            "        [ 0.4300932 , -0.16742565, -0.2198467 , ...,  0.20202267,\n",
            "          0.9660715 , -0.27279773],\n",
            "        [ 0.26046112,  0.3902138 , -0.84677774, ..., -0.47999442,\n",
            "         -0.41443664,  0.30263457],\n",
            "        ...,\n",
            "        [-0.26864722, -0.06286313, -0.3989526 , ...,  0.7947545 ,\n",
            "         -0.3465603 , -0.39573827],\n",
            "        [-0.27762794, -0.06374443, -0.38828674, ...,  0.7966482 ,\n",
            "         -0.3405156 , -0.38919613],\n",
            "        [-0.26586986, -0.06379791, -0.3984193 , ...,  0.79219896,\n",
            "         -0.33098987, -0.38307774]],\n",
            "\n",
            "       [[-0.28050452, -0.05871927, -0.15129568, ...,  0.32435253,\n",
            "          0.01285291, -0.4830367 ],\n",
            "        [-0.48361912,  0.23074707, -0.16694954, ..., -0.62660515,\n",
            "          0.27733907, -0.4081871 ],\n",
            "        [-0.7272895 ,  0.00717209, -0.6532742 , ..., -0.46841756,\n",
            "         -0.3103957 , -0.18408266],\n",
            "        ...,\n",
            "        [-1.1580426 , -0.505681  , -0.31448847, ...,  0.92043537,\n",
            "         -0.25106525, -1.3675514 ],\n",
            "        [-1.1614869 , -0.50888216, -0.30613944, ...,  0.91841936,\n",
            "         -0.2521109 , -1.3620929 ],\n",
            "        [-1.1596917 , -0.51485246, -0.30421746, ...,  0.9168364 ,\n",
            "         -0.2505811 , -1.3628918 ]],\n",
            "\n",
            "       [[-0.98912543,  0.14930038,  0.2712535 , ...,  0.9769166 ,\n",
            "         -0.6873391 ,  0.7050262 ],\n",
            "        [-0.1958142 , -0.48647726,  0.1257318 , ...,  1.0413815 ,\n",
            "         -0.63581246,  0.21705712],\n",
            "        [-1.0191774 ,  0.5865425 ,  0.15374218, ...,  0.865769  ,\n",
            "         -0.11166382,  0.11387008],\n",
            "        ...,\n",
            "        [-0.3064366 , -0.2386852 ,  0.2423652 , ...,  1.1290715 ,\n",
            "         -1.3642192 ,  0.04496092],\n",
            "        [-0.2574443 ,  0.5416782 , -0.49219656, ...,  0.39998466,\n",
            "         -0.8873778 ,  0.6137098 ],\n",
            "        [-0.662272  , -0.24458207,  0.05387108, ...,  1.9119825 ,\n",
            "         -0.9559073 , -0.2876298 ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[-0.7395096 ,  0.6484068 ,  0.6847233 , ..., -0.08889076,\n",
            "         -0.11500696,  1.2891423 ],\n",
            "        [-1.1582463 ,  0.66937226,  0.72212076, ..., -0.65428007,\n",
            "          0.3677848 , -0.2344958 ],\n",
            "        [-1.3939866 ,  0.09544141,  0.87696147, ...,  0.4992977 ,\n",
            "         -0.03349054,  0.7014289 ],\n",
            "        ...,\n",
            "        [-1.3598726 ,  0.21586685,  0.63721883, ...,  1.3177923 ,\n",
            "          0.11462964,  0.4377589 ],\n",
            "        [-1.3548582 ,  0.21586138,  0.64021504, ...,  1.3167418 ,\n",
            "          0.1152763 ,  0.43599117],\n",
            "        [-1.3578697 ,  0.21588622,  0.6418322 , ...,  1.3176388 ,\n",
            "          0.11324779,  0.4360694 ]],\n",
            "\n",
            "       [[ 0.51811004, -0.59662575,  0.8218664 , ..., -0.6944091 ,\n",
            "         -1.1767274 , -0.7150915 ],\n",
            "        [ 0.29759973,  0.10092693,  0.04462999, ..., -0.9114083 ,\n",
            "         -0.8363418 , -1.1998261 ],\n",
            "        [ 0.34928963, -0.02484979, -0.02403128, ..., -0.8080746 ,\n",
            "         -0.9675945 , -0.90117055],\n",
            "        ...,\n",
            "        [-0.6519835 , -0.7121263 , -0.1070893 , ...,  0.60607576,\n",
            "          0.01286001, -0.94711125],\n",
            "        [-0.65407526, -0.71304166, -0.10547056, ...,  0.6046971 ,\n",
            "          0.0120415 , -0.9491659 ],\n",
            "        [-0.6513921 , -0.7120505 , -0.10421178, ...,  0.60448104,\n",
            "          0.00984153, -0.95135975]],\n",
            "\n",
            "       [[-0.5783948 ,  0.26905513,  0.7326024 , ...,  0.25887686,\n",
            "          0.2554947 , -1.2482567 ],\n",
            "        [ 0.14181784,  0.58341867, -0.5317592 , ..., -0.2762223 ,\n",
            "          0.548339  , -1.153815  ],\n",
            "        [-0.51735973,  0.32494822, -0.13576804, ...,  0.38515836,\n",
            "          0.34293407, -0.32544342],\n",
            "        ...,\n",
            "        [ 0.21418238, -0.04285957, -1.1176876 , ...,  0.21737999,\n",
            "          0.07748833, -0.7378541 ],\n",
            "        [ 0.02385961,  1.4589787 , -0.00277924, ...,  0.3328039 ,\n",
            "          0.2190569 , -0.5882986 ],\n",
            "        [-0.52666795,  0.63510877, -0.49360612, ..., -0.05574165,\n",
            "         -0.7190328 , -0.25352323]]], dtype=float32)), label_ids=array([0., 0., 1., ..., 2., 0., 1.], dtype=float32), metrics={'test_loss': 0.02486487850546837, 'test_accuracy': 0.3708185053380783, 'test_f1': 0.2006193575089707, 'test_precision': 0.1375063639011664, 'test_recall': 0.3708185053380783, 'test_runtime': 24.8619, 'test_samples_per_second': 282.56, 'test_steps_per_second': 4.424})\n",
            "Test Results: {'eval_loss': 0.02486487850546837, 'eval_accuracy': 0.3708185053380783, 'eval_f1': 0.2006193575089707, 'eval_precision': 0.1375063639011664, 'eval_recall': 0.3708185053380783, 'eval_runtime': 24.6184, 'eval_samples_per_second': 285.356, 'eval_steps_per_second': 4.468, 'epoch': 7.0}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      1.00      0.54      2605\n",
            "           1       0.00      0.00      0.00      4357\n",
            "           2       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.37      7025\n",
            "   macro avg       0.12      0.33      0.18      7025\n",
            "weighted avg       0.14      0.37      0.20      7025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ],
      "metadata": {
        "id": "ffqg7AwNCu8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b8d1cf-7712-4c2a-8d69-8935c78df183"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision    Recall  F1 Score\n",
            "0  0.370819   0.137506  0.370819  0.200619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"predicted_labels = results.predictions[0].argmax(axis=1)\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "true_labels = np.array(test_dataset.labels).flatten()\"\"\"\n",
        "\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "print(\"Unique Predicted Labels:\", np.unique(predicted_labels))\n",
        "print(\"Test Dataset Labels:\", np.unique(test_dataset.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCFTWfcD1Tfb",
        "outputId": "09c22836-c340-483d-d06c-20b80757d951"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels: [0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1]\n",
            "Predicted Labels: [0 0 0 ... 0 0 0]\n",
            "Unique Predicted Labels: [0]\n",
            "Test Dataset Labels: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#predicted_probs = torch.nn.functional.softmax(torch.tensor(predicted_labels), dim=-1).numpy()\n",
        "\n",
        "# Calculate AUROC\n",
        "auroc = roc_auc_score(true_labels, predicted_labels, multi_class='ovr')\n",
        "print(\"AUROC:\", auroc)"
      ],
      "metadata": {
        "id": "nbm1CKoj0UKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyPkgpV7u2svDMTKo8pHhEv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}