{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/checkpoint_epoch_{epoch}.pth'\n",
        "best_model_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/best_model.pth'\n",
        "\n",
        "\n",
        "# Saving the checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, loss, val_loss, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    if is_best:\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csqlu1lfu2n-",
        "outputId": "3f76fbaa-3178-4d7a-f18c-47068c96a58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['behavior_drug']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_drug\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: change label to float for sdoh_economics, sdoh_environment\n",
        "\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(float(self.labels[idx]))\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i8-ZZN5mu286",
        "outputId": "8eb0f897-44d3-4ebb-a71f-1b556eb9a3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [616/616 07:22, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.279100</td>\n",
              "      <td>1.826783</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.248800</td>\n",
              "      <td>1.347324</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.822300</td>\n",
              "      <td>0.664478</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.549257</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.523600</td>\n",
              "      <td>0.616378</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.471500</td>\n",
              "      <td>0.456049</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.349700</td>\n",
              "      <td>0.390877</td>\n",
              "      <td>0.614947</td>\n",
              "      <td>0.468324</td>\n",
              "      <td>0.378159</td>\n",
              "      <td>0.614947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDo0lEQVR4nOzdd3hU1b7G8e9Mek8gHULvLYQqIB0F5CDYQEQRD3ZQORwbR8Uu1nMtKGDFhmJDPRYUQxeUGnqvCaTQUkmfuX9MGAihpEyyM8n7eZ553Nmz9p7fAPdcXtbav2WyWq1WREREREREpELMRhcgIiIiIiJSEyhciYiIiIiIOIDClYiIiIiIiAMoXImIiIiIiDiAwpWIiIiIiIgDKFyJiIiIiIg4gMKViIiIiIiIAyhciYiIiIiIOIDClYiIiIiIiAMoXImIiFTAnDlzMJlMHDhwwOhSRETEYApXIiLiNLZu3crNN99MvXr18PDwIDIykrFjx7J161ajSxMREVG4EhER5/Ddd9/RqVMnYmNjue2223jnnXeYMGECixcvplOnTsyfP9/oEkVEpJZzNboAERGRS9m7dy+33HILTZo0YdmyZYSEhNjfe+CBB+jduze33HILmzZtokmTJlVSU1ZWFj4+PlXyWSIi4hw0cyUiItXeK6+8wqlTp3j33XeLBSuA4OBgZs+eTVZWFi+//DLffPMNJpOJpUuXlrjP7NmzMZlMbNmyxX5ux44dXH/99dSpUwdPT0+6dOnCjz/+WOy6089VLV26lHvvvZfQ0FDq169/wXp/+OEHhg0bRmRkJB4eHjRt2pRnn32WwsLCYuP69etHu3btWLduHT179sTLy4vGjRsza9as8vwyiYiIwRSuRESk2vvf//5Ho0aN6N2793nf79OnD40aNeLnn39m2LBh+Pr68tVXX5UYN2/ePNq2bUu7du0A2zNcl112Gdu3b+fRRx/ltddew8fHh5EjR553meG9997Ltm3bmDZtGo8++ugF650zZw6+vr5MmTKFN954g86dO1/wmpMnT3LVVVfRuXNnXn75ZerXr88999zDhx9+WNpfHhERqSZMVqvVanQRIiIiF5KWlkZgYCAjRozg+++/v+C4ESNG8OOPP5Kens5dd91FbGwsR44cwcXFBYCkpCTq1avHU089xRNPPAHAoEGDSElJYc2aNXh4eABgtVq5/PLLOXr0KLt27QJsYem2227j8ssvZ8mSJfZ7nv3e/v37adSoEQDZ2dl4eXkVq+/uu+/m008/5cSJE/bP6tevH0uXLuW1115jypQpAOTl5dG9e3eOHDlCQkICbm5uFf9FFBGRKqGZKxERqdYyMjIA8PPzu+i40++np6czevRoUlJSWLJkif39b775BovFwujRowE4ceIEixYtYtSoUWRkZHDs2DGOHTvG8ePHGTx4MLt37+bw4cPFPuOOO+4oFqwu5OxgdfrevXv35tSpU+zYsaPYWFdXV+666y77z+7u7tx1112kpKSwbt26S36WiIhUHwpXIiJSrZ0OTadD1oWcHcKGDBlCQEAA8+bNs78/b948OnbsSIsWLQDYs2cPVquVJ554gpCQkGKvJ598EoCUlJRin9G4ceNS1bx161auueYaAgIC8Pf3JyQkhJtvvhmwzcSdLTIyskRjjNM1au8sERHnom6BIiJSrQUEBBAREcGmTZsuOm7Tpk3Uq1cPf39/APtzU++88w7Jycn8+eefvPDCC/bxFosFgAcffJDBgwef957NmjUr9vO5S/3OJzU1lb59++Lv788zzzxD06ZN8fT0ZP369TzyyCP2zxURkZpH4UpERKq9f/zjH7z33nusWLGCyy+/vMT7y5cv58CBA8WW140ePZqPP/6Y2NhYtm/fjtVqtS8JBOwt293c3Bg0aJDDal2yZAnHjx/nu+++o0+fPvbz+/fvP+/4I0eOlGjrfvpZr9PPcImIiHPQskAREan2HnroIby8vLjrrrs4fvx4sfdOnDjB3Xffjbe3Nw899JD9/KBBg6hTpw7z5s1j3rx5dOvWrdiyvtDQUPr168fs2bNJTEws8ZlHjx4tV62nn8k6u19UXl4e77zzznnHFxQUMHv27GJjZ8+eTUhICJ07dy5XDSIiYgzNXImISLXXvHlzPv74Y8aOHUv79u2ZMGECjRs35sCBA3zwwQccO3aML774gqZNm9qvcXNz49prr+XLL78kKyuLV199tcR93377bS6//HLat2/PHXfcQZMmTUhOTmbVqlUkJCSwcePGMtfas2dPgoKCuPXWW7n//vsxmUx8+umnXKg5b2RkJC+99BIHDhygRYsWzJs3j7i4ON599111ChQRcTKauRIREadwww03sG7dOvr168cHH3zA3XffzXvvvUffvn1Zt24d1157bYlrRo8eTWZmJgCjRo0q8X6bNm1Yu3Ytw4YNY86cOUycOJFZs2ZhNpuZNm1aueqsW7cuP/30ExERETz++OO8+uqrXHHFFbz88svnHR8UFMQvv/zC2rVreeihh4iPj2fGjBnccccd5fp8ERExjva5EhERMUi/fv04duwYW7ZsMboUERFxAM1ciYiIiIiIOIDClYiIiIiIiAMoXImIiIiIiDiAnrkSERERERFxAM1ciYiIiIiIOIDClYiIiIiIiANoE+HzsFgsHDlyBD8/P0wmk9HliIiIiIiIQaxWKxkZGURGRmI2X3xuSuHqPI4cOUJUVJTRZYiIiIiISDURHx9P/fr1LzpG4eo8/Pz8ANsvoL+/v8HViIiIiIiIUdLT04mKirJnhItRuDqP00sB/f39Fa5ERERERKRUjwupoYWIiIiIiIgDKFyJiIiIiIg4gMKViIiIiIiIA+iZKxERERFxCoWFheTn5xtdhtQwLi4uuLq6OmQLJoUrEREREan2MjMzSUhIwGq1Gl2K1EDe3t5ERETg7u5eofsoXImIiIhItVZYWEhCQgLe3t6EhIQ4ZIZBBGwbBOfl5XH06FH2799P8+bNL7lR8MUoXImIiIhItZafn4/VaiUkJAQvLy+jy5EaxsvLCzc3Nw4ePEheXh6enp7lvpcaWoiIiIiIU9CMlVSWisxWFbuPQ+4iIiIiIiJSyylciYiIiIiIOIDClYiIiIhINdWvXz8mT55s/7lRo0a8/vrrF73GZDLx/fffV/izHXWf2kThSkRERETEwYYPH86QIUPO+97y5csxmUxs2rSpzPdds2YNd955Z0XLK+app56iY8eOJc4nJiYydOhQh37WuebMmUNgYGClfkZVUrgSEREREXGwCRMmsHDhQhISEkq899FHH9GlSxc6dOhQ5vuGhITg7e3tiBIvKTw8HA8Pjyr5rJpC4UpEREREnIrVauVUXoEhr9JuYvyPf/yDkJAQ5syZU+x8ZmYmX3/9NRMmTOD48eOMGTOGevXq4e3tTfv27fniiy8uet9zlwXu3r2bPn364OnpSZs2bVi4cGGJax555BFatGiBt7c3TZo04YknniA/Px+wzRw9/fTTbNy4EZPJhMlkstd87rLAzZs3M2DAALy8vKhbty533nknmZmZ9vfHjx/PyJEjefXVV4mIiKBu3bpMnDjR/lnlcejQIUaMGIGvry/+/v6MGjWK5ORk+/sbN26kf//++Pn54e/vT+fOnVm7di0ABw8eZPjw4QQFBeHj40Pbtm355Zdfyl1LaWifKxERERFxKtn5hbSZ9pshn73tmcF4u1/6r9Curq6MGzeOOXPm8Nhjj9nbyH/99dcUFhYyZswYMjMz6dy5M4888gj+/v78/PPP3HLLLTRt2pRu3bpd8jMsFgvXXnstYWFh/P3336SlpRV7Pus0Pz8/5syZQ2RkJJs3b+aOO+7Az8+Phx9+mNGjR7NlyxYWLFjAH3/8AUBAQECJe2RlZTF48GB69OjBmjVrSElJ4fbbb2fSpEnFAuTixYuJiIhg8eLF7Nmzh9GjR9OxY0fuuOOOS36f832/08Fq6dKlFBQUMHHiREaPHs2SJUsAGDt2LDExMcycORMXFxfi4uJwc3MDYOLEieTl5bFs2TJ8fHzYtm0bvr6+Za6jLBSuREREREQqwT//+U9eeeUVli5dSr9+/QDbksDrrruOgIAAAgICePDBB+3j77vvPn777Te++uqrUoWrP/74gx07dvDbb78RGRkJwAsvvFDiOanHH3/cftyoUSMefPBBvvzySx5++GG8vLzw9fXF1dWV8PDwC37W3LlzycnJ4ZNPPsHHxweAGTNmMHz4cF566SXCwsIACAoKYsaMGbi4uNCqVSuGDRtGbGxsucJVbGwsmzdvZv/+/URFRQHwySef0LZtW9asWUPXrl05dOgQDz30EK1atQKgefPm9usPHTrEddddR/v27QFo0qRJmWsoK4Wr6i49ETbOhcungDbOExEREcHLzYVtzww27LNLq1WrVvTs2ZMPP/yQfv36sWfPHpYvX84zzzwDQGFhIS+88AJfffUVhw8fJi8vj9zc3FI/U7V9+3aioqLswQqgR48eJcbNmzePN998k71795KZmUlBQQH+/v6l/h6nPys6OtoerAB69eqFxWJh586d9nDVtm1bXFzO/BpFRESwefPmMn3W2Z8ZFRVlD1YAbdq0ITAwkO3bt9O1a1emTJnC7bffzqeffsqgQYO44YYbaNq0KQD3338/99xzD7///juDBg3iuuuuK9dzbmWhZ66qs/wcmHU5xD4DO342uhoRERGRasFkMuHt7mrIy1TGf+yeMGEC3377LRkZGXz00Uc0bdqUvn37AvDKK6/wxhtv8Mgjj7B48WLi4uIYPHgweXl5Dvu1WrVqFWPHjuWqq67ip59+YsOGDTz22GMO/YyznV6Sd5rJZMJisVTKZ4Gt0+HWrVsZNmwYixYtok2bNsyfPx+A22+/nX379nHLLbewefNmunTpwltvvVVptYDCVfXm5gmdx9uOFz0HlkJDyxERERGRshk1ahRms5m5c+fyySef8M9//tMe0P78809GjBjBzTffTHR0NE2aNGHXrl2lvnfr1q2Jj48nMTHRfu6vv/4qNmblypU0bNiQxx57jC5dutC8eXMOHjxYbIy7uzuFhRf/e2br1q3ZuHEjWVlZ9nN//vknZrOZli1blrrmsjj9/eLj4+3ntm3bRmpqKm3atLGfa9GiBf/617/4/fffufbaa/noo4/s70VFRXH33Xfz3Xff8e9//5v33nuvUmo9TeGquut5H3gGwNHtsPkbo6sRERERkTLw9fVl9OjRTJ06lcTERMaPH29/r3nz5ixcuJCVK1eyfft27rrrrmKd8C5l0KBBtGjRgltvvZWNGzeyfPlyHnvssWJjmjdvzqFDh/jyyy/Zu3cvb775pn1m57RGjRqxf/9+4uLiOHbsGLm5uSU+a+zYsXh6enLrrbeyZcsWFi9ezH333cctt9xiXxJYXoWFhcTFxRV7bd++nUGDBtG+fXvGjh3L+vXrWb16NePGjaNv37506dKF7OxsJk2axJIlSzh48CB//vkna9asoXXr1gBMnjyZ3377jf3797N+/XoWL15sf6+yGBqupk+fTteuXfHz8yM0NJSRI0eyc+fOi17z3nvv0bt3b4KCgggKCmLQoEGsXr262Jjx48fbW0mefl1oE7dqzysQek22HS95AQoqZwpXRERERCrHhAkTOHnyJIMHDy72fNTjjz9Op06dGDx4MP369SM8PJyRI0eW+r5ms5n58+eTnZ1Nt27duP3223n++eeLjbn66qv517/+xaRJk+jYsSMrV67kiSeeKDbmuuuuY8iQIfTv35+QkJDztoP39vbmt99+48SJE3Tt2pXrr7+egQMHMmPGjLL9YpxHZmYmMTExxV7Dhw/HZDLxww8/EBQURJ8+fRg0aBBNmjRh3rx5ALi4uHD8+HHGjRtHixYtGDVqFEOHDuXpp58GbKFt4sSJtG7dmiFDhtCiRQveeeedCtd7MSZraZv1V4IhQ4Zw44030rVrVwoKCvjPf/7Dli1b2LZtW7GH5c42duxYevXqRc+ePfH09OSll15i/vz5bN26lXr16gG2cJWcnFxsStDDw4OgoKBS1ZWenk5AQABpaWllftivUuRlwRsdISsFhv0Xuk4wuiIRERGRKpOTk8P+/ftp3Lgxnp6eRpcjNdDF/oyVJRsY2i1wwYIFxX6eM2cOoaGhrFu3jj59+pz3ms8//7zYz++//z7ffvstsbGxjBs3zn7ew8Pjou0knYq7D/R5CH59CJa+DB1vAjcvo6sSEREREZGzVKtnrtLS0gCoU6dOqa85deoU+fn5Ja5ZsmQJoaGhtGzZknvuuYfjx49f8B65ubmkp6cXe1U7nW+FgAaQmQSrK/dBPBERERERKbtqE64sFguTJ0+mV69etGvXrtTXPfLII0RGRjJo0CD7uSFDhvDJJ58QGxvLSy+9xNKlSxk6dOgFu6BMnz7dvpFbQEBAsV761YarB/R71Ha84r+QUw0DoIiIiIhILWboM1dnu+eee/j1119ZsWIF9evXL9U1L774Ii+//DJLliy56IZg+/bto2nTpvzxxx8MHDiwxPu5ubnFuqKkp6cTFRVVfZ65Oq2wAGb2gGO7oO+j0H+q0RWJiIiIVDo9cyWVzVHPXFWLmatJkybx008/sXjx4lIHq1dffZUXX3yR33///ZI7LTdp0oTg4GD27Nlz3vc9PDzw9/cv9qqWXFyhf1F7zVUzIOvCSx1FRERERKRqGRqurFYrkyZNYv78+SxatIjGjRuX6rqXX36ZZ599lgULFtClS5dLjk9ISOD48eNERERUtGTjtb4aIqIhL9O2PFBERERERKoFQ8PVxIkT+eyzz5g7dy5+fn4kJSWRlJREdna2fcy4ceOYOvXM8reXXnqJJ554gg8//JBGjRrZr8nMzARsffIfeugh/vrrLw4cOEBsbCwjRoygWbNmDB48uMq/o8OZzTBgmu149XuQdtjYekREREREBDA4XM2cOZO0tDT69etHRESE/XV6YzCAQ4cOkZiYWOyavLw8rr/++mLXvPrqq4BtM7FNmzZx9dVX06JFCyZMmEDnzp1Zvnw5Hh4eVf4dK0WzgdCgJxTmwrKXja5GREREREQweJ+r0vTSWLJkSbGfDxw4cNHxXl5e/PbbbxWoygmYTDDwCfhoKKz/FHreD3WbGl2ViIiIiEitVi0aWkg5NOwJza4AayEsmW50NSIiIiJSBRo1asTrr79udBlyAQpXzmzA47b/bv4GkrYYW4uIiIiI2JlMpou+nnrqqXLdd82aNdx5550Vqq1fv35Mnjy5QveQ8zN0WaBUUGRHaDMStn0Pi5+HMV8YXJCIiIiIAMV6BsybN49p06axc+dO+zlfX1/7sdVqpbCwEFfXS//VPCQkxLGFikNp5srZ9X8MTGbY+QvErzG6GhEREZHKZ7VCXpYxr1L0DAAIDw+3vwICAjCZTPafd+zYgZ+fH7/++iudO3fGw8ODFStWsHfvXkaMGEFYWBi+vr507dqVP/74o9h9z10WaDKZeP/997nmmmvw9vamefPm/PjjjxX65f32229p27YtHh4eNGrUiNdee63Y+++88w7NmzfH09OTsLAwrr/+evt733zzDe3bt8fLy4u6desyaNAgsrKyKlSPM9HMlbMLaQHRN0HcZ7DoGbj1f0ZXJCIiIlK58k/BC5HGfPZ/joC7j0Nu9eijj/Lqq6/SpEkTgoKCiI+P56qrruL555/Hw8ODTz75hOHDh7Nz504aNGhwwfs8/fTTvPzyy7zyyiu89dZbjB07loMHD1KnTp0y17Ru3TpGjRrFU089xejRo1m5ciX33nsvdevWZfz48axdu5b777+fTz/9lJ49e3LixAmWL18O2GbrxowZw8svv8w111xDRkYGy5cvL1UTu5pC4aom6PcIbJoH+5fBviXQpJ/RFYmIiIjIJTzzzDNcccUV9p/r1KlDdHS0/ednn32W+fPn8+OPPzJp0qQL3mf8+PGMGTMGgBdeeIE333yT1atXM2TIkDLX9N///peBAwfyxBNPANCiRQu2bdvGK6+8wvjx4zl06BA+Pj784x//wM/Pj4YNGxITEwPYwlVBQQHXXnstDRs2BKB9+/ZlrsGZKVzVBIENoMs/YfVsiH0GGve1tWsXERERqYncvG0zSEZ9toN06dKl2M+ZmZk89dRT/Pzzz/agkp2dzaFDhy56nw4dOtiPfXx88Pf3JyUlpVw1bd++nREjRhQ716tXL15//XUKCwu54ooraNiwIU2aNGHIkCEMGTLEviQxOjqagQMH0r59ewYPHsyVV17J9ddfT1BQULlqcUZ65qqm6POg7f/YD6+zPX8lIiIiUlOZTLaleUa8HPgP2D4+xZcXPvjgg8yfP58XXniB5cuXExcXR/v27cnLy7vofdzc3M755TFhsVgcVufZ/Pz8WL9+PV988QURERFMmzaN6OhoUlNTcXFxYeHChfz666+0adOGt956i5YtW7J///5KqaU6UriqKXxD4bJ7bMeLngNLobH1iIiIiEiZ/Pnnn4wfP55rrrmG9u3bEx4ezoEDB6q0htatW/Pnn3+WqKtFixa4uLgA4OrqyqBBg3j55ZfZtGkTBw4cYNGiRYAt2PXq1Yunn36aDRs24O7uzvz586v0OxhJywJrkp73wZr3IWUbbPkWOowyuiIRERERKaXmzZvz3XffMXz4cEwmE0888USlzUAdPXqUuLi4YuciIiL497//TdeuXXn22WcZPXo0q1atYsaMGbzzzjsA/PTTT+zbt48+ffoQFBTEL7/8gsVioWXLlvz999/ExsZy5ZVXEhoayt9//83Ro0dp3bp1pXyH6kgzVzWJVxD0esB2vPh5KMw3th4RERERKbX//ve/BAUF0bNnT4YPH87gwYPp1KlTpXzW3LlziYmJKfZ677336NSpE1999RVffvkl7dq1Y9q0aTzzzDOMHz8egMDAQL777jsGDBhA69atmTVrFl988QVt27bF39+fZcuWcdVVV9GiRQsef/xxXnvtNYYOHVop36E6MllrU2/EUkpPTycgIIC0tDT8/f2NLqds8rLgjWjIOgr/+D9bowsRERERJ5aTk8P+/ftp3Lgxnp6eRpcjNdDF/oyVJRto5qqmcfeBPg/Zjpe+DPnZxtYjIiIiIlJLKFzVRJ3HQ0AUZCTansESEREREZFKp3BVE7l6QL9HbcfL/ws56cbWIyIiIiJSCyhc1VQdboS6zSH7BPz1jtHViIiIiIjUeApXNZWLKwx4zHa8cgZkHTe2HhEREZEKUh82qSyO+rOlcFWTtR4B4R0gLwP+/D+jqxEREREpl9Ob1+bl5RlcidRUp06dAsDNza1C99EmwjWZ2QwDp8Hn18Pq9+Cye8E/0uiqRERERMrE1dUVb29vjh49ipubG2az5gfEMaxWK6dOnSIlJYXAwEB7kC8vhauartkgaNADDq2CZa/Y9r4SERERcSImk4mIiAj279/PwYMHjS5HaqDAwEDCw8MrfB9tInweTr2J8PkcXAkfDQWzK0xaA3WaGF2RiIiISJlZLBYtDRSHc3Nzu+iMVVmygWauaoOGPW0zWHv+gCUvwrXvGl2RiIiISJmZzWY8PT2NLkPkgrRgtbYY8Ljtv5u+guRtxtYiIiIiIlIDKVzVFpEx0GYEYIXFzxtdjYiIiIhIjaNwVZv0fwxMZtjxEySsM7oaEREREZEaReGqNglpCdFjbMeLnjG2FhERERGRGkbhqrbp+wiY3WDfEti31OhqRERERERqDIWr2iaoIXS5zXa86FlQJ34REREREYdQuKqNej8Irl6QsAZ2LTC6GhERERGRGkHhqjbyC4PL7rYdxz4LFoux9YiIiIiI1AAKV7VVz/vBIwBStsKWb42uRkRERETE6Slc1VbedaDXfbbjxc9DYb6x9YiIiIiIODmFq9qs+z3gHQwn98OGz4yuRkRERETEqSlc1WYevtDnQdvx0pchP9vYekREREREnJjCVW3X+Tbwrw8ZR2DNB0ZXIyIiIiLitBSuajs3T+j3iO14+WuQk25sPSIiIiIiTkrhSiD6JqjbDLJPwF8zja5GRERERMQpKVwJuLhC/8dsxyvfglMnjK1HRERERMQJKVyJTZuREN4e8jJgxf8ZXY2IiIiIiNNRuBIbsxkGTLMdr34X0hONrUdERERExMkoXMkZza+AqMugIAeWvWJ0NSIiIiIiTkXhSs4wmWBg0ezV+o/hxH5j6xERERERcSIKV1Jco17QdCBYCmDJi0ZXIyIiIiLiNBSupKSBT9j+u2kepGw3thYRERERESdhaLiaPn06Xbt2xc/Pj9DQUEaOHMnOnTsved3XX39Nq1at8PT0pH379vzyyy/F3rdarUybNo2IiAi8vLwYNGgQu3fvrqyvUfNExkDrqwErLHrO6GpERERERJyCoeFq6dKlTJw4kb/++ouFCxeSn5/PlVdeSVZW1gWvWblyJWPGjGHChAls2LCBkSNHMnLkSLZs2WIf8/LLL/Pmm28ya9Ys/v77b3x8fBg8eDA5OTlV8bVqhv6PgckMO36Cw+uMrkZEREREpNozWa1Wq9FFnHb06FFCQ0NZunQpffr0Oe+Y0aNHk5WVxU8//WQ/d9lll9GxY0dmzZqF1WolMjKSf//73zz44IMApKWlERYWxpw5c7jxxhtL3DM3N5fc3Fz7z+np6URFRZGWloa/v7+Dv6UTmX8PbJwLTfrDuO+NrkZEREREpMqlp6cTEBBQqmxQrZ65SktLA6BOnToXHLNq1SoGDRpU7NzgwYNZtWoVAPv37ycpKanYmICAALp3724fc67p06cTEBBgf0VFRVX0q9QM/R4BsxvsWwz7lxldjYiIiIhItVZtwpXFYmHy5Mn06tWLdu3aXXBcUlISYWFhxc6FhYWRlJRkf//0uQuNOdfUqVNJS0uzv+Lj4yvyVWqOoEbQebztOPZZqD6TnCIiIiIi1U61CVcTJ05ky5YtfPnll1X+2R4eHvj7+xd7SZE+D4KrFySshl2/GV2NiIiIiEi1VS3C1aRJk/jpp59YvHgx9evXv+jY8PBwkpOTi51LTk4mPDzc/v7pcxcaI2XgFw7d77IdL3oWLBZj6xERERERqaYMDVdWq5VJkyYxf/58Fi1aROPGjS95TY8ePYiNjS12buHChfTo0QOAxo0bEx4eXmxMeno6f//9t32MlFGvB8DDH5K3wNbvjK5GRERERKRaMjRcTZw4kc8++4y5c+fi5+dHUlISSUlJZGdn28eMGzeOqVOn2n9+4IEHWLBgAa+99ho7duzgqaeeYu3atUyaNAkAk8nE5MmTee655/jxxx/ZvHkz48aNIzIykpEjR1b1V6wZvOtAz/ttx4ufh8J8Y+sREREREamGDA1XM2fOJC0tjX79+hEREWF/zZs3zz7m0KFDJCYm2n/u2bMnc+fO5d133yU6OppvvvmG77//vlgTjIcffpj77ruPO++8k65du5KZmcmCBQvw9PSs0u9Xo1x2N3gHw4l9EDfX6GpERERERKqdarXPVXVRll72tcqqd+C3qeBfD+5bD24KqyIiIiJSszntPldSzXX5py1YpR+GtR8aXY2IiIiISLWicCWl5+YJfR+xHS9/DXIzjK1HRERERKQaUbiSsul4E9RpCqeOwV+zjK5GRERERKTaULiSsnFxg/7/sR2vfBNOnTC2HhERERGRakLhSsqu7bUQ1g5y0+HPN4yuRkRERESkWlC4krIzm2HAE7bjv2dDRpKx9YiIiIiIVAMKV1I+LQZD/W5QkA3LXjW6GhERERERwylcSfmYTDBwmu143Rw4ecDIakREREREDKdwJeXXuDc06Q+WfFjyotHViIiIiIgYSuFKKmZg0bNXG7+ElO3G1iIiIiIiYiCFK6mYep2h9XDACoufN7oaERERERHDKFxJxfV/HDDB9v/B4XVGVyMiIiIiYgiFK6m40FYQfaPteNFzxtYiIiIiImIQhStxjH6PgtkN9i6C/cuNrkZEREREpMopXIljBDWCzrfajhc9C1aroeWIiIiIiFQ1hStxnD4PgasXxP8Nu383uhoRERERkSqlcCWO4xcO3e+0Hcc+CxaLsfWIiIiIiFQhhStxrF6TwcMfkjfDtvlGVyMiIiIiUmUUrsSxvOtAz/tsx4ueh8ICY+sREREREakiClfieJfdA9514cRe2DjX6GpERERERKqEwpU4nocf9P637XjJS5CfY2w9IiIiIiJVQOFKKkeXCeBfD9ITYN1HRlcjIiIiIlLpFK6kcrh5Qt+HbcfLXoXcTGPrERERERGpZApXUnk6joU6TeDUMfh7ptHViIiIiIhUKoUrqTwubtD/Mdvxn2/BqRPG1iMiIiIiUokUrqRytb0WQttCbhqsfNPoakREREREKo3ClVQusxkGPmE7/msWZCQbW4+IiIiISCVRuJLK12II1O8KBdmw/FWjqxERERERqRQKV9WcxWLlRFae0WVUjMkEA6fZjtd+BCcPGluPiIiIiEglULiq5l7+bSfD3lzOruQMo0upmMZ9oEk/sOTD0peMrkZERERExOEUrqqxrNwC/tieTGJaDtfPXMlf+44bXVLFDCiavdr4BRzdaWwtIiIiIiIOpnBVjfl4uPLN3T3o0jCI9JwCxn2wmp82HTG6rPKr3xla/QOsFlj8vNHViIiIiIg4lMJVNRfo7c5nt3dnSNtw8got3PfFBj5Ysd/ossqv/2OACbb9AEc2GF2NiIiIiIjDKFw5AU83F94e24lbezTEaoVnf9rG8z9vw2KxGl1a2YW1gQ6jbMeLnjO2FhERERERB1K4chIuZhNPXd2WR4e2AuC95ft5YF4cuQWFBldWDv0eBbMr7PkDDvxpdDUiIiIiIg6hcOVETCYTd/dtyuujO+LmYuJ/G49w64erScvON7q0sqnTBDqNsx0vehasTjgDJyIiIiJyDoUrJzQyph4fje+Gr4crf+07wahZq0hMyza6rLLp8xC4esKhVbYZLBERERERJ6dw5aQubx7MvLsuI9TPg53JGVz7zkrn2gvLPxK63WE7jn0GLBZj6xERERERqSCFKyfWNjKA7+7tSdMQH+fcC6vXv8DdD5I2wfYfjK5GRERERKRCFK6cXP0gb769p6dz7oXlUxd63mc7XvQ8FBYYW4+IiIiISAUoXNUATr0XVo97wbsuHN8NG78wuhoRERERkXJTuKohnHYvLA8/uHyK7XjJi1CQa2w9IiIiIiLlpHBVgzjtXlhdJ4BfJKQnwNqPjK5GRERERKRcDA1Xy5YtY/jw4URGRmIymfj+++8vOn78+PGYTKYSr7Zt29rHPPXUUyXeb9WqVSV/k+rDKffCcvOCvg/bjpe/CrmZxtYjIiIiIlIOhoarrKwsoqOjefvtt0s1/o033iAxMdH+io+Pp06dOtxwww3FxrVt27bYuBUrVlRG+dWa0+2FFXMzBDWGrKPw9yyjqxERERERKTNDw9XQoUN57rnnuOaaa0o1PiAggPDwcPtr7dq1nDx5kttuu63YOFdX12LjgoODK6P8as+p9sJycYP+j9mO/3wTsk8aW4+IiIiISBk59TNXH3zwAYMGDaJhw4bFzu/evZvIyEiaNGnC2LFjOXTo0EXvk5ubS3p6erFXTeFUe2G1uw5C20Jumi1giYiIiIg4EacNV0eOHOHXX3/l9ttvL3a+e/fuzJkzhwULFjBz5kz2799P7969yci48IzN9OnTCQgIsL+ioqIqu/wq5TR7YZnNMOBx2/HfsyAj2dh6RERERETKwGnD1ccff0xgYCAjR44sdn7o0KHccMMNdOjQgcGDB/PLL7+QmprKV199dcF7TZ06lbS0NPsrPj6+kquvek6zF1bLoVCvC+SfguWvGV2NiIiIiEipOWW4slqtfPjhh9xyyy24u7tfdGxgYCAtWrRgz549Fxzj4eGBv79/sVdN5BR7YZlMMHCa7Xjth5B68SWdIiIiIiLVhVOGq6VLl7Jnzx4mTJhwybGZmZns3buXiIiIKqis+nOKvbCa9IXGfcGSD0teMroaEREREZFSMTRcZWZmEhcXR1xcHAD79+8nLi7O3oBi6tSpjBs3rsR1H3zwAd27d6ddu3Yl3nvwwQdZunQpBw4cYOXKlVxzzTW4uLgwZsyYSv0uzsQp9sI6PXu1cS4c3WVsLSIiIiIipWBouFq7di0xMTHExMQAMGXKFGJiYpg2zfYX68TExBKd/tLS0vj2228vOGuVkJDAmDFjaNmyJaNGjaJu3br89ddfhISEVO6XcULVei+s+l2g5TCwWmDx80ZXIyIiIiJySSar1VqNHripHtLT0wkICCAtLa3GPn91tq1H0rjtozWkZOQSEeDJx//sRoswP6PLguStMLMXYIU7l0JkR6MrEhEREZFapizZwCmfuRLHqrZ7YYW1hfY32I4XPWdsLSIiIiIil6BwJUA13gur36NgdoU9C+HgSqOrERERERG5IIUrsauWe2HVbQoxt9iOY58BrWIVERERkWpK4UqKqZZ7YfV9GFw84NAq2BNrXB0iIiIiIhehcCUlVLu9sPwjodsdtuPYp8FiMaYOEREREZGLULiS86p2e2FdPgXcfSFpE2z/0ZgaREREREQuQuFKLqra7IXlUxd6TLIdL34eCguqvgYRERERkYtQuJJLurx5MPPuuoxQPw92Jmdw7Tsr2ZWcUfWF9JgIXkFwbBdsmlf1ny8iIiIichEKV1Iq1WIvLE9/2/JAgCUvQkFu1X6+iIiIiMhFKFxJqVWLvbC63QF+EZB2CNZ9XLWfLSIiIiJyEQpXUiaG74Xl5gV9HrIdL3sF8rKq7rNFRERERC5C4UrKzPC9sGJugaBGkJUCf8+ums8UEREREbkEhSspF0P3wnJ1h37/sR3/+Tpkp1b+Z4qIiIiIXILClZSboXthtb8eQttAThqsfKvyP09ERERE5BIUrqTCDNkLy+wCAx63Hf81EzJTKvfzREREREQuQeFKHMKQvbBaXgX1OkN+Fiz/b+V+loiIiIjIJShcicNU+V5YJhMMnGY7XvsBpMZX3meJiIiIiFyCwpU4VJXvhdWkHzTuA4V5sPSlyvscEREREZFLULgSh6vyvbAGFM1exX0Ox3ZX3ueIiIiIiFyEwpVUiirdCyuqq+35K6sFFj/v+PuLiIiIiJSCwpVUmirdC6v/Y4AJts6HxI2Ov7+IiIiIyCUoXEmlqrK9sMLb2fa+Alj0nGPvLSIiIiJSCgpXUiWqZC+sflPB5AK7f4eDqxx7bxERERGRS1C4kipzvr2wdiY5cC+suk2h0y2249hnwFoJz3eJiIiIiFyAwpVUqRJ7Yc1y8F5YfR4GFw84tBL2xjruviIiIiIil6BwJVXu7L2wMhy9F1ZAPeh2h+1Ys1ciIiIiUoUUrsQQ5+6FNWnuBt5fvs8xN7/8X+Dua+sauP1Hx9xTREREROQSFK7EMGfvhQXw3M/bee4nB+yF5RMMPSbajhc9B5ZKaP0uIiIiInIOhSsx1Ll7Yb2/Yj/3f7mh4nth9ZgIXkFwbBdsmueASkVERERELk7hSgx37l5YP21KrPheWJ4BtuWBAIunQ0GuY4oVEREREbkAhSupNhy+F1bXO8A3HNIOwfpPHFeoiIiIiMh5KFxJteLQvbDcvaHvQ7bjpS9DXpbjChUREREROYfClVQ7Dt0LK2YcBDaErBRY/a5jCxUREREROYvClVRLDtsLy9Ud+v/HdrzidchOdWSZIiIiIiJ2CldSbTlsL6z2N0BIK8hJhVUzHF6niIiIiAgoXEk155C9sMwuMOBx2/GqdyDzaCVUKiIiIiK1ncKVVHsO2Qur1T8gMgbys2DFfyupUhERERGpzRSuxClUeC8skwkGTrMdr3kfUuMrr1gRERERqZUUrsSpVGgvrCb9oVFvKMyDZS9XbqEiIiIiUusoXInTKfdeWCYTDHjCdrzhczi2p3ILFREREZFaReFKnFK598Jq0B1aDAFrISx5ofILFREREZFaQ+FKnFa598I63Tlwy7eQtLlyixQRERGRWkPhSpxaufbCCm8P7a63HS96rvKLFBEREZFawdBwtWzZMoYPH05kZCQmk4nvv//+ouOXLFmCyWQq8UpKSio27u2336ZRo0Z4enrSvXt3Vq9eXYnfQoxWrr2w+v8HTC6wawEc+ruKKhURERGRmszQcJWVlUV0dDRvv/12ma7buXMniYmJ9ldoaKj9vXnz5jFlyhSefPJJ1q9fT3R0NIMHDyYlJcXR5Us1Uua9sOo2hZibbcexz4C1DJsSi4iIiIich8lqrR5/qzSZTMyfP5+RI0decMySJUvo378/J0+eJDAw8LxjunfvTteuXZkxYwYAFouFqKgo7rvvPh599NFS1ZKenk5AQABpaWn4+/uX9auIwb7fcJiHvtlIfqGVy5rUYfYtXQjwcis5MC0B3uwEhblwy3xoOqDqixURERGRaq0s2cApn7nq2LEjERERXHHFFfz555/283l5eaxbt45BgwbZz5nNZgYNGsSqVasueL/c3FzS09OLvcR5lXovrID60PV227Fmr0RERESkgpwqXEVERDBr1iy+/fZbvv32W6KioujXrx/r168H4NixYxQWFhIWFlbsurCwsBLPZZ1t+vTpBAQE2F9RUVGV+j2k8pV6L6zeU8DdF45sgB0/VX2hIiIiIlJjOFW4atmyJXfddRedO3emZ8+efPjhh/Ts2ZP/+7//q9B9p06dSlpamv0VHx/voIrFSKXaC8snGC6713a86DmwXOAZLRERERGRS3CqcHU+3bp1Y8+ePQAEBwfj4uJCcnJysTHJycmEh4df8B4eHh74+/sXe0nNUKq9sHpOAs9AOLoDNn9tSJ0iIiIi4vycPlzFxcUREREBgLu7O507dyY2Ntb+vsViITY2lh49ehhVohjskntheQbA5f+yHS9+AQryjClURERERJyaoeEqMzOTuLg44uLiANi/fz9xcXEcOnQIsC3XGzdunH3866+/zg8//MCePXvYsmULkydPZtGiRUycONE+ZsqUKbz33nt8/PHHbN++nXvuuYesrCxuu+22Kv1uUr2c3gtrfM9GwHn2wup2J/iGQepBWP+xcYWKiIiIiNNyNfLD165dS//+/e0/T5kyBYBbb72VOXPmkJiYaA9aYOsG+O9//5vDhw/j7e1Nhw4d+OOPP4rdY/To0Rw9epRp06aRlJREx44dWbBgQYkmF1L7uJhNPDm8DREBnkz/dQfvr9hPUnoOr42KxsPdG/o8BL88CMtegY5jwd3b6JJFRERExIlUm32uqhPtc1Xz/RB3mAe/PmcvLDcrzOgMqYdg0NNw+WSjyxQRERERg9X4fa5EKmpEx3rMue2cvbCyCqHff2wDVvwf5KQZW6SIiIiIOBWFK6m1ejUL5qu7ehTfCyt0KAS3hJxUWDnD6BJFRERExIkoXEmt1ibSn+/u7UmzUF/bXljv/s3Otg/Y3lz1NmQeNbZAEREREXEaCldS69UP8uabu3vQtZFtL6zhfwSRGtgW8rNsywNFREREREpB4UoE215Yn07oztB24eQVWrkvZbjtjTXvQ1qCscWJiIiIiFNQuBIp4unmwoybbHthLbe05y9LayjMxbr0ZaNLExEREREnoHAlcpbTe2FNHdqaV/JHAWBZ/yl5KbsMrkxEREREqjuFK5FzmEwm7urblHGjR7PYEoMLFtZ89BBp2flGlyYiIiIi1ZjClcgFjOhYj6B/PANAr+wlPPr2XBLTsg2uSkRERESqK4UrkYvo2K0PaU1szS2uTZtj2wsrKcPgqkRERESkOlK4ErmEgKuewmpy4QqX9USkb+L6WSv5a99xo8sSERERkWpG4UrkUoKbYep4EwDP+H1HRk4+4z5YzU+bjhhcmIiIiIhUJwpXIqXR9xFwcadd3ib+1eQIeYUWJs3dwPvL9xldmYiIiIhUEwpXIqURGAVdJgBwP18wvkdDAJ77eTvP/bQNi8VqZHUiIiIiUg0oXImUVu8p4OaD6ch6nmyxn6lDWwHw/or93P/lBnILCg0uUERERESMpHAlUlq+oXDZPQCYFj3PXb0b8caNHXFzMfHTpkRu/XC19sISERERqcUUrkTKoud94BkIR7fD5m8Y0bEec27rhq+HK3/tO8GoWau0F5aIiIhILaVwJVIWXoFw+WTb8ZIXoCCPXs2C+equHoT6ebAzOUN7YYmIiIjUUgpXImXV7U7wDYOTB2DDpwC0ifTnu3t70izUl8S0HO2FJSIiIlILKVyJlJW7D/R5yHa89GXIty0DrB/kzTd396BroyAycgoY98Fq/rdRe2GJiIiI1BYKVyLl0elWCGwAmUmw+j376UBvdz6d0J2h7cLJK7Rw3xfaC0tERESktlC4EikPV3foN9V2vOK/kJNuf8vTzYUZN3VifM9GgG0vrGe1F5aIiIhIjVeucBUfH09CQoL959WrVzN58mTeffddhxUmUu11GA3BLSH7JKx6u9hbLmYTTw5vY98L64MV+7lPe2GJiIiI1GjlClc33XQTixcvBiApKYkrrriC1atX89hjj/HMM884tECRasvsAgMesx2vmgFZxRtYmEwm7urb1L4X1s+bEhn3gfbCEhEREampyhWutmzZQrdu3QD46quvaNeuHStXruTzzz9nzpw5jqxPpHprfTVEdIS8TNvywPM4ey+sv/ef4IZZKzmSqr2wRERERGqacoWr/Px8PDw8APjjjz+4+uqrAWjVqhWJiYmOq06kujOZYOATtuPV70Ha4fMOO3svrF3JmVz7zkp2JWsvLBEREZGapFzhqm3btsyaNYvly5ezcOFChgwZAsCRI0eoW7euQwsUqfaaDoSGvaAwF5a9csFhZ++FlZSew/gPV3M8M7cKCxURERGRylSucPXSSy8xe/Zs+vXrx5gxY4iOjgbgxx9/tC8XFKk1TCYYUDR7teFTOL73gkNP74XVJNiHI2k53PfFBgoKLVVUqIiIiIhUJpPVai1Xf+jCwkLS09MJCgqynztw4ADe3t6EhoY6rEAjpKenExAQQFpaGv7+/kaXI87i8xtg9+/QfhRc995Fh+5KzmDk239yKq+Qu/o0YepVrauoSBEREREpi7Jkg3LNXGVnZ5Obm2sPVgcPHuT1119n586dTh+sRMptwOO2/27+GpK3XnRoizA/Xr3BNuM7e9k+ftp0pLKrExEREZFKVq5wNWLECD755BMAUlNT6d69O6+99hojR45k5syZDi1QxGlEREPbawArLHruksOvah/BXX2bAPDwN5vYmaQGFyIiIiLOrFzhav369fTu3RuAb775hrCwMA4ePMgnn3zCm2++6dACRZxK/8fAZIadv0D8mksOf+jKlvRqVpdTeYXc/dk67YElIiIi4sTKFa5OnTqFn58fAL///jvXXnstZrOZyy67jIMHDzq0QBGnEtwcOt5kO1506Q21XV3MvDWmE/UCvdh/LIt/fxWHxVKuxyBFRERExGDlClfNmjXj+++/Jz4+nt9++40rr7wSgJSUFDWAEOn7CLi4w/5lsG/JJYfX8XFn1s2dcXc188f2FN5atKfyaxQRERERhytXuJo2bRoPPvggjRo1olu3bvTo0QOwzWLFxMQ4tEARpxPYALr803Yc+wyUoiFn+/oBPD+yHQCvx+5i0Y7kyqxQRERERCpBuVuxJyUlkZiYSHR0NGazLaOtXr0af39/WrVq5dAiq5pasUuFZabAG9GQfwpunAuthpXqsse/38xnfx3C39OVHyddTqNgn0ouVEREREQuptJbsQOEh4cTExPDkSNHSEhIAKBbt25OH6xEHMI3FC67x3a86DmwFJbqsmn/aEtMg0DScwq4+7N1nMorqMQiRURERMSRyhWuLBYLzzzzDAEBATRs2JCGDRsSGBjIs88+i8VicXSNIs6p533gGQAp22DLt6W6xN3VzKybOxPs68GOpAwe/XYz5ZxcFhEREZEqVq5w9dhjjzFjxgxefPFFNmzYwIYNG3jhhRd46623eOKJJxxdo4hz8gqCXg/Yjhc/D4Wla7Me5u/JO2M74Wo28ePGI3ywYn8lFikiIiIijlKuZ64iIyOZNWsWV199dbHzP/zwA/feey+HDx92WIFG0DNX4jB5WbZnr7KOwj/+70yji1KY8+d+nvrfNlzMJj6b0J0eTetWYqEiIiIicj6V/szViRMnzvtsVatWrThx4kR5bilSM7n7QJ+HbMdLX4b87FJfemvPRlwTU49Ci5VJc9eTmFb6a0VERESk6pUrXEVHRzNjxowS52fMmEGHDh0qXJRIjdJ5PAREQUYirHm/1JeZTCZeuKY9bSL8OZ6Vx92frSe3oHSNMURERESk6pVrWeDSpUsZNmwYDRo0sO9xtWrVKuLj4/nll1/o3bu3wwutSloWKA634TP4YSJ41YEHNoJn6f9cxZ84xT/eWkFadj5jukUx/Vr9A4aIiIhIVan0ZYF9+/Zl165dXHPNNaSmppKamsq1117L1q1b+fTTT8tVtEiN1uFGqNscsk/AX++U6dKoOt68OSYGkwm+WB3PF6sPVVKRIiIiIlIR5d7nKjIykueff55vv/2Wb7/9lueee46TJ0/ywQcflPoey5YtY/jw4URGRmIymfj+++8vOv67777jiiuuICQkBH9/f3r06MFvv/1WbMxTTz2FyWQq9tLeW2I4F1cY8JjteOUMyDpepsv7tgjhwStbAvDkD1uJi091cIEiIiIiUlHlDleOkJWVRXR0NG+//Xapxi9btowrrriCX375hXXr1tG/f3+GDx/Ohg0bio1r27YtiYmJ9teKFSsqo3yRsmk9AsI7QF4G/Pl/Zb78nr5NubJNGHmFFu75bB3HMnMroUgRERERKS9XIz986NChDB06tNTjX3/99WI/v/DCC/zwww/873//IyYmxn7e1dWV8PBwR5Up4hhmMwx8Ej6/Dla/B5fdC/6RZbjcxGujohnx9p/sO5rFpLnr+WxCd1xdDP03EhEREREp4tR/K7NYLGRkZFCnTp1i53fv3k1kZCRNmjRh7NixHDp08WdUcnNzSU9PL/YSqRTNBkKDnlCQAz/eB7kZZbrcz9ONd2/pjI+7C3/tO8GLv+6opEJFREREpKzKNHN17bXXXvT91NTUitRSZq+++iqZmZmMGjXKfq579+7MmTOHli1bkpiYyNNPP03v3r3ZsmULfn5+573P9OnTefrpp6uqbKnNTCa48ln4aCjs+QPeGwg3fg7BzUt9i2ahfrw2Kpq7P1vP+yv20yEqkKujSz8DJiIiIiKVo0yt2G+77bZSjfvoo4/KXojJxPz58xk5cmSpxs+dO5c77riDH374gUGDBl1wXGpqKg0bNuS///0vEyZMOO+Y3NxccnPPPL+Snp5OVFSUWrFL5YlfA1+Ng4wj4O4H18yC1v8o0y1eWrCDmUv24uXmwvyJPWkVrj+rIiIiIo5WllbsZZq5Kk9oqgxffvklt99+O19//fVFgxVAYGAgLVq0YM+ePRcc4+HhgYeHh6PLFLmwqK5w11L4ejwc/BPmjYXeD0L//4DZpVS3ePDKlmw5nMby3ce469N1/DjpcgK83Cq3bhERERG5IKd75uqLL77gtttu44svvmDYsGGXHJ+ZmcnevXuJiIiogupEysA3FMb9YGtsAbD8VZg7Ck6dKNXlLmYTb94YQ71ALw4eP8XkLzdgsZR5T3ARERERcRBDw1VmZiZxcXHExcUBsH//fuLi4uwNKKZOncq4cePs4+fOncu4ceN47bXX6N69O0lJSSQlJZGWlmYf8+CDD7J06VIOHDjAypUrueaaa3BxcWHMmDFV+t1ESsXFDYZMh2vfA1evouew+kPS5lJdHuTjzuxbOuPhambxzqO8Ebu7kgsWERERkQsxNFytXbuWmJgYexv1KVOmEBMTw7Rp0wBITEws1unv3XffpaCggIkTJxIREWF/PfDAA/YxCQkJjBkzhpYtWzJq1Cjq1q3LX3/9RUhISNV+OZGy6DAKbl8IgQ3h5AF4/wrY9HWpLm1XL4Dnr2kPwBuxu4ndnlyJhYqIiIjIhZSpoUVtUZaH1kQc6tQJ+PZ22Btr+7n7Pbbugi6XfpZq2g9b+GTVQfw8Xflx0uU0Dvap5GJFREREar6yZAOne+ZKpEbzrgNjv7Y1twD4eyZ8MgIyUy556ePD2tClYRAZOQXc9elasnILKrlYERERETmbwpVIdWN2gYFPwOjPbW3aD/4Js/vY2rdfhLurmXfGdiLEz4NdyZk8/O0mNDEtIiIiUnUUrkSqq9b/gDsXQ3BLyEiEOVfB2otvhxDq78nMsZ1wNZv4eVMi7y/fX0XFioiIiIjClUh1Ftwc7oiF1ldDYR78NBl+vA/ycy54SZdGdZg2vA0A03/dzso9x6qoWBEREZHaTeFKpLrz8INRn8DAJ8FkhvWfwEdDIS3hgpfccllDrutUH4sVJn2xgSOp2VVYsIiIiEjtpHAl4gxMJug9BcZ+A15BcGQ9zO4L+5dfYLiJ569pR9tIf05k5XH3Z+vIyS+s4qJFREREaheFKxFn0mwg3LkUwjvAqWO2ToIrZ8B5Gld4urkw6+bOBHq7sSkhjWk/bFGDCxEREZFKpHAl4myCGsKE36HDjWAthN8fg28nQF5WiaFRdbx5a0wMZhN8tTaBL1bHG1CwiIiISO2gcCXijNy84JpZMPQVMLvClm/h/UFwfG+Job2bh/Dg4JYAPPnjFtYfOlnV1YqIiIjUCgpXIs7KZILud8KtP4FvGKRsg3f7w67fSgy9p29ThrYLJ7/Qyr2fredoRq4BBYuIiIjUbApXIs6uYQ/bc1hR3SE3DeaOhiUvgcViH2IymXjlhmiahviQlJ7DxLnryS+0XOSmIiIiIlJWClciNYF/hG0Gq+vtgBWWvABf3gQ5afYhvh6uzL6lC74erqzef4Lpv+wwrl4RERGRGkjhSqSmcHWHYa/BiHfAxQN2/WpbJpiy3T6kWagvr42KBuDDP/fzQ9xho6oVERERqXEUrkRqmpixMOE3CIiCE3vhvYGwdb797cFtw5nUvxkAj3y7iW1H0o2qVERERKRGUbgSqYkiY+DOJdC4L+Rnwdfj4fcnoLAAgH9d0YI+LULIybdw12drST2VZ2i5IiIiIjWBwpVITeUTDDd/B70esP288k347FrIOo6L2cSbN3Ykqo4X8SeyeeDLOAot2mBYREREpCIUrkRqMhdXuOIZuGEOuPnA/qXwbl84soFAb3dm3dwZTzczS3cd5Y0/dhldrYiIiIhTU7gSqQ3aXgN3xEKdppAWDx8Mhg2f0zYygOnXtgfgzUV7WLgt2eBCRURERJyXwpVIbRHaGu5YBC2GQmEu/HAv/DSFa9qHMr5nIwCmzItj79FMY+sUERERcVIKVyK1iVcg3DgX+j8GmGDtBzBnGI/1CaRbozpk5BZw96fryMwtMLpSEREREaejcCVS25jN0PdhuOkr8AyAhNW4vd+f2X3zCPXzYHdKJg9/sxGrVQ0uRERERMpC4UqktmpxJdyxGELbQmYyQV9fyzedtuDmAr9sTuLdZfuMrlBERETEqShcidRmdZvC7Quh3XVgKaDB30/yW8O5eJLLSwt2sGL3MaMrFBEREXEaClcitZ27D1z3AQx+AUwuNDnyE7GBLxBJCvd9sZ6Ek6eMrlBERETEKShciQiYTNBjIoz7HryDqZezm188n6Bdzjru/mwdOfmFRlcoIiIiUu0pXInIGY37wF1LIbIT/tYM5ri/TO+kz3h8/mY1uBARERG5BIUrESkuoD7c9it0GocLFh5x+5KBmx9k3p/bja5MREREpFpTuBKRktw84eq3YPgbFJrcGOqyhq4Lr2PLxjVGVyYiIiJSbSlciciFdR6P+Z+/cNI1mKamIzSaP5zU9d8ZXZWIiIhItaRwJSIXZYrqhvu9y9nk0hZfsgn88TYK/3gGLGpyISIiInI2hSsRuSSfOpH43vEzn1qvAsBlxWswdxScOmFwZSIiIiLVh8KViJRKk/Agwke/zv15E8m2usOeP+DdfpC02ejSRERERKoFhSsRKbUr2oTRqN+tXJv3NPHWUEg9CO9fAZu+Mro0EREREcMpXIlImTwwqAVhLbrwj9zn+MscAwXZ8N0d8OujUJhvdHkiIiIihlG4EpEycTGbeGN0DAF1Qrnp1L/5wX+s7Y2/Z8InIyAzxdgCRURERAyicCUiZRbg7cbsWzrj7ubKAynDmN/yZXD3g4N/wuw+EK/9sERERKT2UbgSkXJpHeHPS9d1AOBfG+uzvP9XENwSMhLho6Gw9kOwWg2uUkRERKTqKFyJSLmN6FiPf/ZqDMA9CzLYO/JHaH01WPLhp3/Bj/dBfo7BVYqIiIhUDYUrEamQqVe1onvjOmTmFnDnvB1kjvgQBj0FJjNs+NQ2i5WWYHSZIiIiIpVO4UpEKsTNxcyMmzoR7u/J3qNZPPj1Jqy9JsPN34JXEBxZD7P7wv5lRpcqIiIiUqkUrkSkwkL8PJh5cyfcXcws2JrEzKV7oekAuHMphHeAU8fgk5GwcoaewxIREZEaS+FKRBwipkEQT13dFoBXf9vJsl1HIaghTPgdOtwI1kL4/TH45p+Ql2VwtSIiIiKOp3AlIg4zplsUo7tEYbHC/V9uIP7EKXDzgmtmwVWvgtkVtn4H7w+C43uNLldERETEoQwNV8uWLWP48OFERkZiMpn4/vvvL3nNkiVL6NSpEx4eHjRr1ow5c+aUGPP222/TqFEjPD096d69O6tXr3Z88SJSgslk4ukRbYmuH0DqqXzu/mwdOfmFYDJBtztg/M/gGwYp2+Dd/rDrN6NLFhEREXEYQ8NVVlYW0dHRvP3226Uav3//foYNG0b//v2Ji4tj8uTJ3H777fz225m/oM2bN48pU6bw5JNPsn79eqKjoxk8eDApKSmV9TVE5Cyebi7MvLkzdX3c2Xoknf/M34z19HNWDS6zPYcV1R1y02DuaFjyElgsxhYtIiIi4gAmq7V6PF1uMpmYP38+I0eOvOCYRx55hJ9//pktW7bYz914442kpqayYMECALp3707Xrl2ZMWMGABaLhaioKO677z4effTRUtWSnp5OQEAAaWlp+Pv7l/9LidRiK/ce4+b3/8ZihWdGtGVcj0Zn3izIg9+mwpr3bT+3GALXzAavQCNKFREREbmgsmQDp3rmatWqVQwaNKjYucGDB7Nq1SoA8vLyWLduXbExZrOZQYMG2cecT25uLunp6cVeIlIxPZsGM3VoawCe+d821h44ceZNV3cY9hqMeAdcPGDXAnhvACRvM6haERERkYpzqnCVlJREWFhYsXNhYWGkp6eTnZ3NsWPHKCwsPO+YpKSkC953+vTpBAQE2F9RUVGVUr9IbXN778b8o0MEBRYr93y+npT0nOIDYsbChN8gIApO7LU1utjynTHFioiIiFSQU4WryjJ16lTS0tLsr/j4eKNLEqkRTCYTL1/fgZZhfhzNyOWez9eTV3DO81WRMbbnsBr3hfws+OY2+P0JKCwwpmgRERGRcnKqcBUeHk5ycnKxc8nJyfj7++Pl5UVwcDAuLi7nHRMeHn7B+3p4eODv71/sJSKO4e3uyqxbOuPn6cq6gyd57ufzLP3zqQs3fwe9Jtt+XvkmfHYNZB2r0lpFREREKsKpwlWPHj2IjY0tdm7hwoX06NEDAHd3dzp37lxsjMViITY21j5GRKpe42AfXh/dEYBPVh3km3UJJQe5uMIVT8MNH4ObD+xfBu/2g8Prq7RWERERkfIyNFxlZmYSFxdHXFwcYGu1HhcXx6FDhwDbcr1x48bZx999993s27ePhx9+mB07dvDOO+/w1Vdf8a9//cs+ZsqUKbz33nt8/PHHbN++nXvuuYesrCxuu+22Kv1uIlLcwNZhPDCwOQCPzd/MlsNp5x/YdiTcEQt1mkJaPHw4BDZ8VnWFioiIiJSToeFq7dq1xMTEEBMTA9iCUUxMDNOmTQMgMTHRHrQAGjduzM8//8zChQuJjo7mtdde4/3332fw4MH2MaNHj+bVV19l2rRpdOzYkbi4OBYsWFCiyYWIVL0HBjZnYKtQcgss3PXpOk5m5Z1/YGhruHMxtLwKCnPhh4nw0xRbC3cRERGRaqra7HNVnWifK5HKk5adz9UzVnDw+Cl6Nw9mzm3dcDGbzj/YYoHlr8Hi5wEr1O8Goz4B/4gqrVlERERqrxq7z5WIOL8ALzdm39IZLzcXlu8+xqu/77zwYLMZ+j4EN30FngGQsBpm94GDK6uuYBEREZFSUrgSkSrXKtyfl67vAMDMJXv5dXPixS9ocSXcsRhC20JWCnw8HP6eDZp4FxERkWpE4UpEDHF1dCS3X94YgAe/3sielIyLX1C3Kdy+ENpdB5YC+PVhmH835J2qgmpFRERELk3hSkQM8+jQVlzWpA5ZeYXc+ek6MnLyL36Buw9c9wEMfgFMLrDpS/jwSjh5oErqFREREbkYhSsRMYyri5kZN3UiIsCTfUezmPLVRiyWSyz1M5mgx0QY9wN4B0PSZtt+WHtiL36diIiISCVTuBIRQwX7ejDz5s64u5hZuC2ZmUv3lu7Cxr3hrmVQrzNkn4TPrrN1FtRzWCIiImIQhSsRMVzHqECeGdEWgFd/38nSXUdLd2FAPRj/C3QaB1gh9hmYdzPkXuL5LREREZFKoHAlItXCjd0aMKZbA6xWuP+LDRw6XspGFW6ecPVbMPwNcHGHHT/BewPg6K7KLVhERETkHApXIlJtPHV1G6KjAknLzueuz9aRnVdY+os7j4fbfgW/SDi2yxawtv9UabWKiIiInEvhSkSqDQ9XF2bd3Im6Pu5sT0xn6nebsJblGar6XeCupdDwcsjLgHljbUsFLWUIaSIiIiLlpHAlItVKRIAXM27qhIvZxPdxR/h45YGy3cA3FMZ9D5fda/t5+Wvw+Q1w6oSjSxUREREpRuFKRKqdHk3rMnVoKwCe+3k7q/eXMRi5uMGQ6XDt++DqBXtjbe3akzY7vlgRERGRIgpXIlItTbi8MVdHR1JgsXLv5+tJSssp+0063AC3/wFBjSD1ILx/BWz6yuG1ioiIiIDClYhUUyaTiReva0+rcD+OZeZyz+fryC0ox7NT4e3gziXQ7AooyIbv7oBfH4XCfIfXLCIiIrWbwpWIVFve7q7MvqUz/p6ubDiUyrM/bSvfjbyC4KZ50Och289/z4SPr4aMZMcVKyIiIrWewpWIVGsN6/rwxo0xmEzw2V+H+GptfPluZHaBAY/DjXPB3Q8OrYR3+0L8ascWLCIiIrWWwpWIVHv9W4Xyr0EtAHj8+y1sSkgt/81aDYM7F0NwS8hIhI+ugrUfQllavouIiIich8KViDiFSf2bMah1KHkFFu7+dB3HM3PLf7Pg5nBHLLS+Giz58NO/4Mf7IL8cTTNEREREiihciYhTMJtN/Hd0RxoH+3AkLYf7v9xAQaGl/Df08INRn8Cgp8Fkhg2fwkdDILWcyw5FRESk1lO4EhGn4e/pxuxbOuPt7sKfe47zyu87K3ZDkwkunww3f2trenFkg+05rP3LHFKviIiI1C4KVyLiVFqE+fHK9dEAzF66j583JVb8pk0HwJ1LIbwDnDoOn4yAlW/pOSwREREpE4UrEXE6wzpEcFefJgA89M1GdiVnVPymQQ1hwu8QPQasFvj9cfjmn5CXVfF7i4iISK2gcCUiTumhwS3p2bQup/IKuevTdaTnOGBTYDcvGDkTrnoVzK6w9Tt4fxAc31vxe4uIiEiNp3AlIk7J1cXMW2NiiAzwZP+xLKbM24jF4oBlfCYTdLsDxv8MvmGQsg3e7Q+7fqv4vUVERKRGU7gSEadV19eDWbd0xt3VzB/bk3l78R7H3bzBZbbnsKK6Q24azB0FS14ESwU6FIqIiEiNpnAlIk6tQ/1AnhvZDoD//rGLxTtTHHdz/wi49Sfoeoft5yXT4csxkJ3quM8QERGRGkPhSkSc3qguUYzt3gCrFR74YgMHjzuwCYWrOwx71fYslqsn7FoA7w2A5G2O+wwRERGpERSuRKRGmDa8DTENAknPKeCuT9dxKq/AsR/Q8Sb4528Q0ABO7LU1utjynWM/Q0RERJyawpWI1Ageri7MHNuZYF8PdiRlMPW7zVgdvU9VZEe4cwk06Qf5WfDNbbaW7YUODnIiIiLilBSuRKTGCA/w5J2xnXA1m/gh7ggf/nnA8R/iUxfGfgu9Jtt+XvkWfHYNZB1z/GeJiIiIU1G4EpEapVvjOjw2rDUAL/yynb/2HXf8h7i4whVPww0fg5sP7F8Gs/vC4XWO/ywRERFxGgpXIlLjjO/ZiJEdIym0WJk0dz2JadmV80FtR8Idi6BuM0hPsDW6+Phq2PQ15FfSZ4qIiEi1pXAlIjWOyWRi+rUdaB3hz7HMPO75bD25BYWV82GhrWwBq+21gAn2L4XvbofXWsLP/4YjG8DRz36JiIhItWSyOvyJb+eXnp5OQEAAaWlp+Pv7G12OiJTToeOnGD5jBWnZ+dzUvQEvXNO+cj8w9RDEzYUNn0PaoTPnw9pBzC3QYRR416ncGkRERMShypINFK7OQ+FKpOZYsjOF2+aswWqFl65rz+iuDSr/Qy0W2wzWhs9g+/+gMNd23sUdWg2DmJuhSX8wu1R+LSIiIlIhClcVpHAlUrPMWLSbV3/fhbuLma/u7kHHqMCq+/BTJ2DLt7DhU0jceOa8f33b3lkdb4I6jauuHhERESkThasKUrgSqVksFit3fbaOhduSiQjw5H/3XU6wr0fVF5K4yTabtWke5KSeOd+4j23ZYOvh4OZV9XWJiIjIBSlcVZDClUjNk56Tz8gZf7LvWBY9mtTl0wndcHUxqKdPfg7s/NkWtPYuBor+Z9gjANpfb1s2GBkDJpMx9YmIiIidwlUFKVyJ1Ey7kzMY+fafZOUVckfvxjw2rI3RJUFqvK0JRtxntoYYp4W1s4Ws9qNsGxeLiIiIIRSuKkjhSqTm+nVzIvd8vh6At8bEMDw60uCKilgscGCZbTZr249nmmCY3aDVVRAzDpqqCYaIiEhVU7iqIIUrkZrtxV93MGvpXrzcXPh+Yi9ahvsZXVJx2Sdh8ze2oJUYd+a8f72iJhhj1QRDRESkiihcVZDClUjNVlBoYfxHa1ix5xiN6nrzw6TLCfByM7qs80vafKYJRvbJM+cb9T7TBMPd27j6REREajiFqwpSuBKp+U5k5TH8rRUcTs1mYKtQ3hvXBbO5GjeQKMiFHaebYCziTBMM/7OaYHRSEwwREREHU7iqIIUrkdphy+E0rpu5ktwCC5MHNWfyoBZGl1Q6qfGw8Qvb3llnN8EIbWsLWR1GqwmGiIiIg5QlGxjUh7i4t99+m0aNGuHp6Un37t1ZvXr1Bcf269cPk8lU4jVs2DD7mPHjx5d4f8iQIVXxVUTEibSrF8Dz17QH4PU/dhO7PdngikopMAr6Pgz3b4RxP9o6Crp6QspW+G0qvNYSvhoHuxeCpdDoakVERGoNw8PVvHnzmDJlCk8++STr168nOjqawYMHk5KSct7x3333HYmJifbXli1bcHFx4YYbbig2bsiQIcXGffHFF1XxdUTEyVzfuT63XNYQgMnz4jhwLMvgisrAbIYmfeG69+DfO2HYa7b9sSz5sO0H+Px6+L92EPsMnNhndLUiIiI1nuHLArt3707Xrl2ZMWMGABaLhaioKO677z4effTRS17/+uuvM23aNBITE/Hx8QFsM1epqal8//335apJywJFape8Agtj3vuLdQdP0jLMj/kTe+Lt7mp0WeWXtOWsJhgnzpxveDl0ugVaX60mGCIiIqXkNMsC8/LyWLduHYMGDbKfM5vNDBo0iFWrVpXqHh988AE33nijPVidtmTJEkJDQ2nZsiX33HMPx48fv+A9cnNzSU9PL/YSkdrD3dXMO2M7EeLnwc7kDB7+ZhNO/ThqeDsY+iL8ewfcMAeaDQJMcHAFzL/Ltmzwfw9Awjpw5u8pIiJSzRgaro4dO0ZhYSFhYWHFzoeFhZGUlHTJ61evXs2WLVu4/fbbi50fMmQIn3zyCbGxsbz00kssXbqUoUOHUlh4/mcPpk+fTkBAgP0VFRVV/i8lIk4pzN+Td8Z2wtVs4qdNiXywYr/RJVWcqwe0vQZu/hb+tQX6Pw6BDSE3HdbNgfcHwDs9YNXbkHXM6GpFREScnqHLAo8cOUK9evVYuXIlPXr0sJ9/+OGHWbp0KX///fdFr7/rrrtYtWoVmzZtuui4ffv20bRpU/744w8GDhxY4v3c3Fxyc3PtP6enpxMVFaVlgSK10McrD/Dkj1txMZv4dEI3ejYNNrokx7JYbDNYGz6zPZdVkGM7b3aDlkMgZhw0HQAuTrwsUkRExIGcZllgcHAwLi4uJCcX79CVnJxMeHj4Ra/Nysriyy+/ZMKECZf8nCZNmhAcHMyePXvO+76Hhwf+/v7FXiJSO43r0ZBrY+pRaLFy39wNHEnNNrokxzKboXEfuPbdoiYY/7Xtj2XJh+3/g7k3wOtFTTCO7zW6WhEREadiaLhyd3enc+fOxMbG2s9ZLBZiY2OLzWSdz9dff01ubi4333zzJT8nISGB48ePExERUeGaRaRmM5lMvHBte9pE+HM8K497PltHTn4NbWfuFQhdJ8Cdi+GelXDZveBVBzISYflr8FYn+OgqiPsC8pyoi6KIiIhBDO8WOG/ePG699VZmz55Nt27deP311/nqq6/YsWMHYWFhjBs3jnr16jF9+vRi1/Xu3Zt69erx5ZdfFjufmZnJ008/zXXXXUd4eDh79+7l4YcfJiMjg82bN+Ph4XHJmtQtUETiT5xi+IwVpJ7K58auUbx4XQejS6oaBXmw61dY/ynsjQWrxXbe3Q/aXQudxkG9zmAyGVuniIhIFSlLNjB8Uf3o0aM5evQo06ZNIykpiY4dO7JgwQJ7k4tDhw5hNhefYNu5cycrVqzg999/L3E/FxcXNm3axMcff0xqaiqRkZFceeWVPPvss6UKViIiAFF1vHnzxhhu/Wg1X66JJzoqkDHdGhhdVuVzdYc2I2yvtMOwca7t+ayTB2D9x7ZXSCuIuQU6jAbfEKMrFhERqTYMn7mqjjRzJSKnvb14D6/8thN3FzPz7rqMmAZBRpdU9SwWOPjnWU0wip5DM7tCiyG22aymA9UEQ0REaqSyZAOFq/NQuBKR06xWK3d/to7ftiYT7u/J/+67nBC/WjwLnpMGW761Ba3D686c94uA6DEQczPUbWpcfSIiIg6mcFVBClcicraMnHxGvv0ne49m0b1xHT67vTtuLob2A6oekrfZQtamL+HUWRu1N+gJnW6xLS1097nw9SIiIk5A4aqCFK5E5Fx7UjIZ+fafZOYWMOHyxjzxjzZGl1R9nG6CseEz2PPHOU0wrrHtnVW/i5pgiIiIU1K4qiCFKxE5nwVbkrj7M9tSuDdu7MiIjvUMrqgaSj8CcaebYOw/cz64pW3JYPSN4BtqXH0iIiJlpHBVQQpXInIhLy/YwTtL9uLpZmb+vb1oHaH/jTgvqxUOroQNn8LW70s2wYi5BZoNUhMMERGp9hSuKkjhSkQupNBiZfxHq1m++xgN6njzv0mXE+DtZnRZ1VtO+llNMNaeOe8bVtQE4xYIbmZcfSIiIhehcFVBClcicjEns/IYPmMFCSez6dcyhA9v7YrZrOeJSiVluy1kbfwSTh07c75BD1vIajMCPHyNq09EROQcClcVpHAlIpey5XAa181cSW6BhfsHNmfKFS2MLsm5FOTBrgVFTTAWntUEwxfaXmPbO6t+VzXBEBERwylcVZDClYiUxnfrE5jy1UYA3h/XhUFtwgyuyEmlJ8LGoiYYJ/adOR/coqgJxhg1wRAREcMoXFWQwpWIlNZTP25lzsoD+Hm48sOkXjQJ0ZK2crNa4dAqWP8pbPse8k/Zzptcippg3AzNr1QTDBERqVIKVxWkcCUipZVXYGHs+3+x5sBJIgM8ubJtOB2jAukYFUjDut6YtKytfHLSYet8W7fBhDVnzvuG2dq5x9wCwc2Nq09ERGoNhasKUrgSkbJIychhxIw/SUzLKXY+0NuN6Pq2oNWxQSAd6wcS5ONuUJVOLGWHLWSd2wQj6jLbbFbba9QEQ0REKo3CVQUpXIlIWaWdymfJrhTi4lOJi09l65F08gosJcY1rOtNx6hAW+hqEEibCH883VwMqNgJFebDrt9sQWv372eaYLj5QLtrIGYcRHVTEwwREXEohasKUrgSkYrKK7CwIyndFrYOpRKXkMq+o1klxrm5mGgd4W9fStgxKpBGdX3U2v1S0hNh4xdFTTD2njlft/mZJhh+ajAiIiIVp3BVQQpXIlIZ0k7lszEhlY1Fs1tx8akcz8orMc7f05XoqEBiogKJLgpcdX09DKjYCVitcOgv22zW1vnnNMEYfFYTDG30LCIi5aNwVUEKVyJSFaxWKwkns+1Ba2N8KpsPp5F7nuWEUXW87M9vxTQIpG1kgJYTnis3A7Z8Z5vNSlh95rxP6JkmGCHaj0xERMpG4aqCFK5ExCj5hRZ2JmXYA1dcfCp7j2Zy7v9Su5pNtIrwsz+/FdMgkCbBvlpOeNrRnWeaYGQdPXM+qvtZTTD8jKtPRESchsJVBSlciUh1kp6Tz+aENOLiU9lwyBa4jmXmlhjn5+FKh6iAome3goiOCiDUz9OAiquRwnxb84v1p5tgFNrOu/nYAlbMzdDgMjXBEBGRC1K4qiCFKxGpzqxWK0fScog7lMrGBFvDjM2H08jOLywxtl6gl212KyqAjlFBtK8XgJd7LV1OmJFkm8na8Ckc33PmfN1mZzXBCDeuPhERqZYUripI4UpEnE1BoYVdyZlFSwlPsjE+jV0pGSWWE7qYTbQIsy0nPN0wo1moLy61aTmh1Qrxf9tms7bOh/yiLo4mF1vzi063qAmGiIjYKVxVkMKViNQEmbkFbEpIZWN8GnHxJ4mLTyU5veRyQl8PV9rXC6BjgzPPb4X515LlhLkZsPV722xW/N9nzvuE2JpgdLwZQlpq2aCTs1qtnDyVz+GT2SScPEWgtztdGgXh5mI2ujQRcQIKVxWkcCUiNVVSWg5x8SfZEH9mOeGpvJLLCSMCPO0bHXeMCqR9vQB8PFwNqLgKHd11VhOMlDPnvYIgtA2EtILQ1rZXSGvwqWtcrVKM1WrlRFYeCSezOZxqC1AJJ7OLXrbjc/+c+3m40qdlCANbhdKvZSh1fNwNql5EqjuFqwpSuBKR2qLQYmV3Sob9+a0Nh1LZlZyB5Zz/z2A2YV9OeHrvrRZhfjVzOWFhPuxeaAtau38HS8H5x/mEQmgrW9Cyh65W4BVYpeXWBlarleNF4el0WDp8sniIOt8zh+cK9fMgMtCL+BOniu0xZzJBpwZBDGgVysDWobQM88Ok2UoRKaJwVUEKVyJSm2XlFrDlcFqx/beOpOWUGOft7kK7egHEFIWt6KhAIgI8a9ZfSvOz4dguSNkBR7dDStEr9eCFr/GLtIWus2e7Qlqq9ftFWK1WjmXmlZhxss1C2Y5z8kvu/3auMH8P6gd5Uz/Iq+jlTb1A23FkoJd9bziLxcrGhFQW7UghdnsK2xLTi92nXqAXA1qFMqB1KD2a1NWeciK1nMJVBSlciYgUl5Kew4aioBUXn8qmhDQyc0vO6IT6ediDVkxUIO3rB+DnWQMbQ+RmwrGdttCVsg2O7rAdpydc+JqABkUzXGfNdoW0BDevqqvbIFarlaOZuSWW6tlmoGzH59s8+2wmE4T5eRYLTvYAFeRFZKAnHq7lC0FHUrNZtCOFRTtS+HPPsWK1eLm5cHnzYAa2CqV/q9Da8zyiiNgpXFWQwpWIyMUVWqzsPZp5ZrPjQ6nsTM6g8Jz1hCYTNAvxte29VdQwo1W4H641tZFATpptA+PTM1ynZ7syky9wgQmCGtlmuc6e7QpuDq4eVVl5hVgsVo5l5hJ/suTzTodTbUv4ShOewv09zwlOZ44jArxwd638PzfZeYWs3HuM2B0pLNqeQlJ68Vnb9vUC7MsH20UGaONukVpA4aqCFK5ERMouO6+QLUfSiDuUSlzR/luHU7NLjPN0M9u6E571/Fa9QK+atZzwXKdOFM1ubStaYlh0fOr4+cebXKBu05JNNOo2NaRFvMViJSUjl8OpJRtFnG4ikXeJ8GQ2QUSAl32Z3rmzT+EBnlUSnsrCarWyLTGdRdtTiN2RwsaE1GLbG4T4eTCgpW354OXNgmt+0xeRWkrhqoIUrkREHONoRq59KWFcvK1pRkZOyeWEwb4edIw6E7g61A8kwKsGLic8V+bRs5YVnjXblZN2/vFmN9usVkirM7NdIa2hTmMwl/+5oEKLlZSMnPM2ikg4eYojqTnkFZYuPNUP8qLeObNPUUXhydlbnx/NyGXJTttzWst3HyXrrA6E7q5mejSpy8DWofRvGUpUHW8DKxURR1K4qiCFKxGRymGxWNl3LMveKCMuPpXtiekUnNueEGga4kPHqKCi0BVEqwg/p//LealYrZCRdFboOmu2Ky/z/Ne4etpC17kt4wMagNlMocVKcnrOmaV6p4NT0UzUkdRs8gsv/tcBF7OJiADPEo0iToeomhCeyiK3oJDV+08Quz2F2B3JxJ8oPkvbMsyPAa1DGdgqlJgGQTWzs6ZILaFwVUEKVyIiVScnv5CtR9KLdSc8dOJUiXEermbaRvrbAleDQDrWDySqTg1fTng2qxXS4kt2Ljy6EwpKLr8EyDF5st9Un6359dhpqccuaxS7LPVJpA5Q/NfNxWwiMtCT+oHFG0Wcnn0K9/esuc/KVZDVansGMbZo+eC6gyeLPX8Y5O1Gv5ahDGgVSp8WIbVjVlakBlG4qiCFKxERYx3PzGVj0XNbcQlpbIxPJS07v8S4uj7uREcFntnwuH4gAd417y+uBYUWkuwzT8X3ejpyMgOXtASaEE8LUzwtzAm0MB2mqekwHqbz79GVbfYh1acpOUHNMYe2xqdBBwIbtMc1IMLWWUIqJPVUHkt3HWXRjhSW7Dxa7M+ui9lE10ZBDGodxoBWoTQJ8TWwUhEpDYWrClK4EhGpXqxWK/uPZZ0JXPGpbEtMP+9StsbBPrbuhEXPb7WO8Ct3i+6qUlBoITEtp0SjiNPd9hLTckp0YjyXm4uJyNNL9QK9iQp0o6X7MRpbDhGasx/f9D2Yj26H43suvDGyV1BRm/hz9unyCa6Eb107FBRaWHfwpG1PrR0p7EkpvrSzcbCPrftgq1C6NKpT7Zp6iIjCVYUpXImIVH+5BYVsK1pOePr5rQPHSy4ndHcx0ybS3x64OkYF0rCud5UuJ8wvtJCYmmN/xunc2aek9EuHJ3cXs23Z3nnalNcP8ibEz6N0z/UU5NkC1tHtxffpOrEPrBdoWuETUrJzYWgrWxiTMjl4PMu+p9Zf+44X+wcCPw9X+rQIYUCrUPq1DKGur/O04xepyRSuKkjhSkTEOZ3MyrPNbp31/NbJUyWXEwZ6u9mWEp41w1XHx73cn5tXYCExLfuC3faS0nO4RHbC3cV8Vqe9kns9hfh6VO6eSvk5cGzXOU00tsPJAxe+xi+iZOfC0Fbg4Vd5ddYgmbkFrNh9lNjtKSzemcKxzDz7eyYTxEQFMrB1GANbh9IyzK/2PF8oUs0oXFWQwpWISM1gtVo5dOIUcfGpbDhkawW/9Uj6efdkaljX2xa0ip7fahPhj6ebbTlhbkGhbebprKV6Z88+JaXncKn/b+ruWhSeAksGp6ggL4IrOzyVV16WrWnGuZ0L0+IvfE1AVNEM11mzXcEtwV3tyS/EYrGyMSHVtnxwewrbEtOLvV8v0IsBrWx7avVoUtf+Z1NEKp/CVQUpXImI1Fx5BRa2J6YXe35r37GsEuPcXEw0CfYlLTuf5IxLhyePovBUvMvemRAV7FNNw1N55aTbQte5+3RlJl3gAhMENTzrWa6i2a66zcHNs0pLdwaJadm25YPbU1ix5xi5Z/2DgJebC72aBTOwta0DYZi/fv1EKpPCVQUpXImI1C5pp/LtywlPP791PCuv2BhPN3OJGaez93oK9nXXsi2AUyfOH7pOHTv/eJMZ6jQ9a1lh0atuM3CpeZ0fyyM7r5BV+44Ru932rFZiWk6x99vV82dAqzAGtgqlfb2AmhXiRaoBhasKUrgSEandrFYrCSez2Z2SQR0fD+oHeVHXR+GpQjKPnmmicfY+XTmp5x9vdrMFrHM7FwY1BhfXKi29OrFarWxPzCB2ezKxO1LYmJBabFY1xM+DAS1tywcvbxaMj0ft/bUScRSFqwpSuBIREakCVitkJJXsXJiyA/Iyzn+NiwcEtyia4TprtiuwIZhrXxvzoxm5LNlpm9FatusoWXmF9vfcXcxc1rQuA1vZlg9G1dEzbyLloXBVQQpXIiIiBrJaIS2hZOfClB1QkH3+a9y8i0JXm+KzXQH1a83GyLkFhazZf5LYHcnEbk/h0IniWxO0CPO1LR9sHUpMVCCuLrUvjIqUh8JVBSlciYiIVEMWC6QetC0ntM92bbe1kC/MPf817n5FM1xndS4Magx+4eDmVbX1VyGr1creo1n25YPrDp4stpdaoLcb/VqEMKB1GH2bhxDgrefbRC5E4aqCFK5EREScSGGBbT8u+7LCotmu47vBUnDh6zwCwDfUFrR8w4r+Gwq+4eAXZvuvb6hts2Qnn/1KPZXH0l1HWbQjhSU7j5KWfWb/Nxezia6NghjYKowBrUNpEuyj5wtFzqJwVUEKVyIiIjVAQR6c2Fs003VW6EqLh4KcS19/motHUfgKs/33QkHMJ8Qpmm0UFFpYfyiV2B3JLNqewu6UzGLvN6rrbV8+2LVRHdxdtXxQajenC1dvv/02r7zyCklJSURHR/PWW2/RrVu3846dM2cOt912W7FzHh4e5OSc+R9Jq9XKk08+yXvvvUdqaiq9evVi5syZNG/evFT1KFyJiIjUYFYr5KRBZoptX66MZMhMPus4yfZeRtKFuxmelwl8gs8KXBcJYtVoQ+VDx0+xaIdt+eBf+46TX3jmr4a+Hq70aRHMgFZh9GsZQrCvh4GVihjDqcLVvHnzGDduHLNmzaJ79+68/vrrfP311+zcuZPQ0NAS4+fMmcMDDzzAzp077edMJhNhYWH2n1966SWmT5/Oxx9/TOPGjXniiSfYvHkz27Ztw9Pz0hvtKVyJiIgIAPk5RcHrdBBLOieUnf45BayFl77fae5+Z4JWiSB21nEVL0nMzC1gxe6jxG5PYfHOFI5lntnvzWSCjlGBDGodxoBWobQK99PyQakVnCpcde/ena5duzJjxgwALBYLUVFR3HfffTz66KMlxs+ZM4fJkyeTmpp63vtZrVYiIyP597//zYMPPghAWloaYWFhzJkzhxtvvPGSNSlciYiISJlYCuHU8XPCV1JRMEs+E8Qyki/c8fB8zG5nLUm8SBDzDXX4pssWi5VNh9NYVNQUY+uR9GLvRwZ4MqB1KANbhdGjaV083Vwc+vki1UVZsoGhC4Pz8vJYt24dU6dOtZ8zm80MGjSIVatWXfC6zMxMGjZsiMVioVOnTrzwwgu0bdsWgP3795OUlMSgQYPs4wMCAujevTurVq06b7jKzc0lN/dMl6H09PQSY0REREQuyOxStPSv5KqbYqxWyM0oClxnh6/zzIhlnwRLPqQn2F4XZQLvuqULYh6+pftKZhMdowLpGBXIlCtbkpiWzeIdR4ndnsyKPcc4kpbDZ38d4rO/DuHpZubyZrblgwNahRIecOmVQiI1kaHh6tixYxQWFhZb0gcQFhbGjh07zntNy5Yt+fDDD+nQoQNpaWm8+uqr9OzZk61bt1K/fn2SkpLs9zj3nqffO9f06dN5+umnHfCNRERERC7CZAJPf9sr+BLPghfkFgWuSwSxrBRbV8RTx2yvlK0Xv6+77wWeBTs7iBUtSTxrY+aIAC9u6t6Am7o3IDuvkFX7jhG73baBcWJaDn9sT+GP7SkAtI30Z2CrUAa2DqN9vQDMZi0flNqh+re0OUePHj3o0aOH/eeePXvSunVrZs+ezbPPPluue06dOpUpU6bYf05PTycqKqrCtYqIiIiUm6sHBEbZXhdjsUD2iaLQdXaDjnNDWTLkZ0FeJpzItHVSvBizW1H4KhnEvHzDGOAbzoABYViHt2B7Sq69KUZcfCpbj6Sz9Ug6by7aQ7CvBwNahTCgVRiXNw/G18Pp/vopUmqG/ukODg7GxcWF5OTkYueTk5MJDw8v1T3c3NyIiYlhz549APbrkpOTiYiIKHbPjh07nvceHh4eeHio+42IiIg4IbPZ1qXQJxhod/GxuRlnOiFeLIidOl60JPGw7XURJqCNVx3a+IUzyTeMnJgQDub6sinNk7+PunMoy4816wL5eW0g+S4+dG9Sxz6rFVWn+nRNFHEEQ8OVu7s7nTt3JjY2lpEjRwK2hhaxsbFMmjSpVPcoLCxk8+bNXHXVVQA0btyY8PBwYmNj7WEqPT2dv//+m3vuuacyvoaIiIiIc/Dws73qNr34uII823LDc5txnC+IWQpsM2fZJyBlG55Ay6LXDSbgrH+/zrJ6cPRgICkHA9m4IJC1XqEEhdanQcMmNGzYGBf/CNtMmXfdYksSRZyF4fOyU6ZM4dZbb6VLly5069aN119/naysLPteVuPGjaNevXpMnz4dgGeeeYbLLruMZs2akZqayiuvvMLBgwe5/fbbAVtb9smTJ/Pcc8/RvHlzeyv2yMhIe4ATERERkYtwdYeA+rbXxVgstsYbmUmXDmJ5mfiYcvExJdOIolVLeUBC0evPM7e1ml0x+RQ1CDndjKPY0sTwM10SXbX6SKoPw8PV6NGjOXr0KNOmTSMpKYmOHTuyYMECe0OKQ4cOYT7rXy5OnjzJHXfcQVJSEkFBQXTu3JmVK1fSpk0b+5iHH36YrKws7rzzTlJTU7n88stZsGBBqfa4EhEREZFSMpvBp67tFdb24mNzM88Ersxksk8cISF+PyeTDpGfnkQdy0lCTKkEm9IxWQog44jtlXiJGryCwL8eRMZAVHfbq24zzXyJIQzf56o60j5XIiIiIlWnoNDC+kOpxO5IZum2I5w8eoRQUyqhppOEmNJo4Z1Fh4AcGntmEGRNxXw6pBXmnf+GXkFQvytEdbOFrchOpW5BL3Iup9pEuDpSuBIRERExzqHjp+zdB//ed4K8Qov9PV8PV3o3D2Zgq1D6N3SlrjUVTuyDhDUQvxoOr4OCnOI3NLlAeDtb0KrfzRa6AhvYWuOLXILCVQUpXImIiIhUD5m5BazYfYxFO5JZtOMoxzJz7e+ZTNAxKpC+LUJoHOxD/SAv6vm5Epq1G/PhNRD/ty1wnW8TZt/wMzNbUd0gIlrPb8l5KVxVkMKViIiISPVjsVjZfDiN2B0pxG5PZuuR9POOc3MxERHgRb1AL+oFedHSK422lp00OrWFuic34n50s+25rrO5uBc9t9XtzAyXX1gVfCup7hSuKkjhSkRERKT6S0rLYdGOFNYeOEHCyWwOp2aTlJ5DoeXif731NOXRxzueyz330ZGdNM3djk/ByZIDAxuemdmK6g6hbcDF8H5wUsUUripI4UpERETEORUUWkhKz+FIag6HU09xuCh0nQ5fh09mk1tgOecqKw1NyXQ27aKzeTedzLtoaU7ATPG/Jhe4epMd0hGXhpfh1aQHpqiutuYZUqMpXFWQwpWIiIhIzWS1WjmelWcPXeeGryOp2aRl5+PHKaLNe4sC1y46mvfgb8oucb8E14Yk+rUjPaQTlvrdCKjfhnp1fAjz88DVRe3gawKFqwpSuBIRERGpvTJy8ovNfCWkZnPkRCbm4zsJS9tEi7ztdDLtook5qcS1J62+rLc0J87anANe7UgN6kBw3SD7819n/9fTzcWAbydlpXBVQQpXIiIiInIhuQWFJKbmkJyUQN6B1XgkrqHuyTiiTm3HneJ7bxVYzWy3NmCdpQXrLc1Zb21BgjUYMBHs6148dAV6US/I237s7+WKSe3iDadwVUEKVyIiIiJSZgV5kLwZy6HV5O5fhcvhNbhnHSkxLMUaxFpLc9ZZmrPB0pwt1sbk4VZinK+H63lnvOoFeVE/0ItgXw/MZoWvyqZwVUEKVyIiIiLiEGkJtr224ldDwmpI3AjntIEvNLlxxLsV211bs6awOUtONWL3KZ9L3trdxUxkoOdZM1/e1AvyIjLQk/qB3kQEeuKm574qTOGqghSuRERERKRS5GfDkQ1nNjiOXw2njpUYZglsSFZIJxIDotnj0YatBfVISMu3N+BITs/hEh3nMZkgzM/zgjNf9YK88HZXa/lLUbiqIIUrEREREakSViuc2FcUtIoCV8o2OKcNPO6+UK9T0b5b3cmP6ExSnmexjof2/xa98kq0nC8pyNvNHroii571qh90ZhYsyNut1j/3pXBVQQpXIiIiImKYnDQ4vO5M4EpYC7npJceFtIL6Xe2Bi+DmtukqwGKxciwrt2TwOiuAZeQUlLznObzdXeyh63QIq3/WDFionycuNfy5L4WrClK4EhEREZFqw1IIR3ecWUYY/zec2FtynFcQ1O8GUUWBq15ncL/ws1vpOUXLDM+e8SpqPX/4ZDbHMnMvWZqr2UR4gGeJ5YZnP//l4ercLecVripI4UpEREREqrWsY5Cw5sxSwsProCCn+BiTC4S3swWt+t0gqhsENrDPbl1KTn4hR84KXUdSzwSvw6nZJKXlUHCpB7+AED+P84SvomWIQV74e5bslFidKFxVkMKViIiIiDiVojbwZ2a3VkN6QslxvuG2kHV6KWFEB3D1KNdHFlqsJKfnFFtumGBffniKw6nZ5ORf+rkvP0/XEssN6wV6E1XHiw71A8tVmyMpXFWQwpWIiIiIOL1StIHHxQMiO54JXPW7gV+YQz7earVyIiuPI6k5HE49dVbwOrMMMfVU/gWvjwzwZOXUgQ6ppSIUripI4UpEREREapxStoEnsGHRzFZR4AptAy6V07I9M7fAtvTwZPElh4dPniLUz5NZt3SulM8tC4WrClK4EhEREZEar5xt4KnfxdY8o5ZQuKoghSsRERERqZXK0gY+qltRo4zibeBrGoWrClK4EhERERGh0trAOxOFqwpSuBIRERERuYCsY2eaZJSmDXxUd9tmx2VoA1+dKFxVkMKViIiIiEgpGdAGviopXFWQwpWIiIiISAUY3AbekRSuKkjhSkRERETEgcrbBj68veFLCRWuKkjhSkRERESkEpWmDbx3XXhor1OFq8rZDUxERERERORCTCao29T26jjGdu7cNvA+IYYHq7JSuBIREREREeN5BkDTAbaXkzIbXYCIiIiIiEhNoHAlIiIiIiLiAApXIiIiIiIiDqBwJSIiIiIi4gAKVyIiIiIiIg6gcCUiIiIiIuIAClciIiIiIiIOoHAlIiIiIiLiAApXIiIiIiIiDqBwJSIiIiIi4gAKVyIiIiIiIg6gcCUiIiIiIuIAClciIiIiIiIOoHAlIiIiIiLiAApXIiIiIiIiDqBwJSIiIiIi4gAKVyIiIiIiIg6gcCUiIiIiIuIArkYXUB1ZrVYA0tPTDa5ERERERESMdDoTnM4IF6NwdR4ZGRkAREVFGVyJiIiIiIhUBxkZGQQEBFx0jMlamghWy1gsFo4cOYKfnx8mk8mwOtLT04mKiiI+Ph5/f3/D6hDH0O9nzaLfz5pFv581i34/axb9ftYszvj7abVaycjIIDIyErP54k9VaebqPMxmM/Xr1ze6DDt/f3+n+cMnl6bfz5pFv581i34/axb9ftYs+v2sWZzt9/NSM1anqaGFiIiIiIiIAyhciYiIiIiIOIDCVTXm4eHBk08+iYeHh9GliAPo97Nm0e9nzaLfz5pFv581i34/a5aa/vuphhYiIiIiIiIOoJkrERERERERB1C4EhERERERcQCFKxEREREREQdQuBIREREREXEAhatqaNmyZQwfPpzIyEhMJhPff/+90SVJBUyfPp2uXbvi5+dHaGgoI0eOZOfOnUaXJeU0c+ZMOnToYN/8sEePHvz6669GlyUO8uKLL2IymZg8ebLRpUg5PPXUU5hMpmKvVq1aGV2WVMDhw4e5+eabqVu3Ll5eXrRv3561a9caXZaUQ6NGjUr836fJZGLixIlGl+ZQClfVUFZWFtHR0bz99ttGlyIOsHTpUiZOnMhff/3FwoULyc/P58orryQrK8vo0qQc6tevz4svvsi6detYu3YtAwYMYMSIEWzdutXo0qSC1qxZw+zZs+nQoYPRpUgFtG3blsTERPtrxYoVRpck5XTy5El69eqFm5sbv/76K9u2beO1114jKCjI6NKkHNasWVPs/zYXLlwIwA033GBwZY7lanQBUtLQoUMZOnSo0WWIgyxYsKDYz3PmzCE0NJR169bRp08fg6qS8ho+fHixn59//nlmzpzJX3/9Rdu2bQ2qSioqMzOTsWPH8t577/Hcc88ZXY5UgKurK+Hh4UaXIQ7w0ksvERUVxUcffWQ/17hxYwMrkooICQkp9vOLL75I06ZN6du3r0EVVQ7NXIlUsbS0NADq1KljcCVSUYWFhXz55ZdkZWXRo0cPo8uRCpg4cSLDhg1j0KBBRpciFbR7924iIyNp0qQJY8eO5dChQ0aXJOX0448/0qVLF2644QZCQ0OJiYnhvffeM7oscYC8vDw+++wz/vnPf2IymYwux6E0cyVShSwWC5MnT6ZXr160a9fO6HKknDZv3kyPHj3IycnB19eX+fPn06ZNG6PLknL68ssvWb9+PWvWrDG6FKmg7t27M2fOHFq2bEliYiJPP/00vXv3ZsuWLfj5+RldnpTRvn37mDlzJlOmTOE///kPa9as4f7778fd3Z1bb73V6PKkAr7//ntSU1MZP3680aU4nMKVSBWaOHEiW7Zs0TMATq5ly5bExcWRlpbGN998w6233srSpUsVsJxQfHw8DzzwAAsXLsTT09PocqSCzl5S36FDB7p3707Dhg356quvmDBhgoGVSXlYLBa6dOnCCy+8AEBMTAxbtmxh1qxZCldO7oMPPmDo0KFERkYaXYrDaVmgSBWZNGkSP/30E4sXL6Z+/fpGlyMV4O7uTrNmzejcuTPTp08nOjqaN954w+iypBzWrVtHSkoKnTp1wtXVFVdXV5YuXcqbb76Jq6srhYWFRpcoFRAYGEiLFi3Ys2eP0aVIOURERJT4R6vWrVtrqaeTO3jwIH/88Qe333670aVUCs1ciVQyq9XKfffdx/z581myZIkexq2BLBYLubm5Rpch5TBw4EA2b95c7Nxtt91Gq1ateOSRR3BxcTGoMnGEzMxM9u7dyy233GJ0KVIOvXr1KrF1ya5du2jYsKFBFYkjfPTRR4SGhjJs2DCjS6kUClfVUGZmZrF/Zdu/fz9xcXHUqVOHBg0aGFiZlMfEiROZO3cuP/zwA35+fiQlJQEQEBCAl5eXwdVJWU2dOpWhQ4fSoEEDMjIymDt3Lkv+v527CYlqDcA4/j9lmE4WpmXSog8KscAgErJcZBFpIBSGJEONtRCpJAohkkL7oGW1asCoaVEUGBguKsGgjSDWInNhbSss7GNTQm3GuwiEwcvlIicnx/8PDsx5z5mZ510+nPO+z5/T29ub7miahry8vCnrHyORCAUFBa6LnIVaW1upra1l1apVjI6O0t7ezvz582loaEh3NE3DqVOn2LZtG1euXKG+vp7BwUE6Ozvp7OxMdzRNUzKZJJFIEIvFyMrKzBqSmbOa5V6+fElVVdXk+enTpwGIxWLcuXMnTak0XfF4HIAdO3akjCcSiYxcyJnpxsbGOHz4MB8/fmTJkiWUlZXR29vL7t270x1NmvM+fPhAQ0MDX79+ZdmyZVRWVjIwMDBlC2jNDuXl5XR3d3P27FkuXrzImjVruH79OtFoNN3RNE19fX28e/eOo0ePpjvKHxNMTExMpDuEJEmSJM12bmghSZIkSSGwXEmSJElSCCxXkiRJkhQCy5UkSZIkhcByJUmSJEkhsFxJkiRJUggsV5IkSZIUAsuVJEmSJIXAciVJUsiCIODRo0fpjiFJmmGWK0lSRmlsbCQIgilHdXV1uqNJkjJcVroDSJIUturqahKJRMpYdnZ2mtJIkuYKn1xJkjJOdnY2K1asSDny8/OB36/sxeNxampqyMnJYe3atTx8+DDl+8PDw+zcuZOcnBwKCgpoamrix48fKffcvn2bjRs3kp2dTXFxMSdOnEi5/uXLF/bv309ubi7r16+np6fnz05akpR2litJ0pxz/vx56urqGBoaIhqNcvDgQUZGRgAYHx9nz5495Ofn8+LFC7q6uujr60spT/F4nOPHj9PU1MTw8DA9PT2sW7cu5T8uXLhAfX09r1+/Zu/evUSjUb59+zaj85QkzaxgYmJiIt0hJEkKS2NjI3fv3mXhwoUp421tbbS1tREEAc3NzcTj8clrW7duZfPmzdy4cYObN29y5swZ3r9/TyQSAeDx48fU1tYyOjpKUVERK1eu5MiRI1y+fPlfMwRBwLlz57h06RLwu7AtWrSIJ0+euPZLkjKYa64kSRmnqqoqpTwBLF26dPJzRUVFyrWKigpevXoFwMjICJs2bZosVgDbt28nmUzy9u1bgiBgdHSUXbt2/WeGsrKyyc+RSITFixczNjY23SlJkmYBy5UkKeNEIpEpr+mFJScn53/dt2DBgpTzIAhIJpN/IpIk6S/hmitJ0pwzMDAw5by0tBSA0tJShoaGGB8fn7ze39/PvHnzKCkpIS8vj9WrV/Ps2bMZzSxJ+vv55EqSlHF+/frFp0+fUsaysrIoLCwEoKuriy1btlBZWcm9e/cYHBzk1q1bAESjUdrb24nFYnR0dPD582daWlo4dOgQRUVFAHR0dNDc3Mzy5cupqanh+/fv9Pf309LSMrMTlST9VSxXkqSM8/TpU4qLi1PGSkpKePPmDfB7J78HDx5w7NgxiouLuX//Phs2bAAgNzeX3t5eTp48SXl5Obm5udTV1XH16tXJ34rFYvz8+ZNr167R2tpKYWEhBw4cmLkJSpL+Su4WKEmaU4IgoLu7m3379qU7iiQpw7jmSpIkSZJCYLmSJEmSpBC45kqSNKf4Nrwk6U/xyZUkSZIkhcByJUmSJEkhsFxJkiRJUggsV5IkSZIUAsuVJEmSJIXAciVJkiRJIbBcSZIkSVIILFeSJEmSFIJ/AD3NJQHu8ZXAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.39087653160095215, 'eval_accuracy': 0.6149466192170818, 'eval_f1': 0.4683242653182536, 'eval_precision': 0.3781593444865186, 'eval_recall': 0.6149466192170818, 'eval_runtime': 4.9316, 'eval_samples_per_second': 284.899, 'eval_steps_per_second': 4.461, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "      output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "      logging_strategy='epoch',  # characterize as epoch\n",
        "      num_train_epochs=7, # have high epoch\n",
        "      #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "      per_device_train_batch_size=64, #reduced batch sie\n",
        "      per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "      save_strategy= 'epoch',\n",
        "      warmup_steps=500,\n",
        "      weight_decay=1e-5,\n",
        "      logging_dir= tensor_logs,  # change to tensor logs\n",
        "      #eval_steps=100,\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      #accumulate gradients over 4 steps\n",
        "      #gradient_accumulation_steps = 4\n",
        "      load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "      metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "      greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Save checkpoint after every epoch\n",
        "#save_checkpoint(model, optimizer, epoch, current_loss, current_val_loss, is_best=False)\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvHjlczRfoIP"
      },
      "outputs": [],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y3hG9frfp73"
      },
      "outputs": [],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxR5iKE9QHH0",
        "outputId": "120352f9-2b10-4304-8c2f-cc6c0a9836a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-8-32d170bac344>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[-0.05156063],\n",
            "       [ 0.02275924],\n",
            "       [ 0.29232895],\n",
            "       ...,\n",
            "       [-0.05083224],\n",
            "       [ 0.04027008],\n",
            "       [ 1.3359376 ]], dtype=float32), array([[[-0.31174132,  1.0459477 ,  0.20530361, ..., -0.23421311,\n",
            "         -0.7189822 ,  0.5841622 ],\n",
            "        [-0.5974792 ,  0.06271473,  0.8740115 , ..., -0.18676034,\n",
            "         -0.5453987 ,  1.0652807 ],\n",
            "        [-0.29048595, -0.40350938,  1.0523149 , ..., -1.1495125 ,\n",
            "          0.18207148,  0.17285325],\n",
            "        ...,\n",
            "        [-0.79533404,  0.6584197 ,  0.7211775 , ..., -1.1442517 ,\n",
            "          0.78271616,  0.17289083],\n",
            "        [-0.77776396,  0.66922444,  0.71544677, ..., -1.1397786 ,\n",
            "          0.7727014 ,  0.167052  ],\n",
            "        [-0.7692934 ,  0.6798537 ,  0.7145402 , ..., -1.1541237 ,\n",
            "          0.76063716,  0.16104855]],\n",
            "\n",
            "       [[-1.4948034 ,  0.09051998,  0.22772537, ...,  0.47113812,\n",
            "         -0.39081255,  0.6625714 ],\n",
            "        [-1.7181098 ,  0.28854176, -0.50335026, ..., -1.3238444 ,\n",
            "         -0.85340494, -0.04318841],\n",
            "        [ 0.15405342, -0.41846514, -0.4234807 , ..., -1.0875015 ,\n",
            "         -1.0560808 ,  0.8428339 ],\n",
            "        ...,\n",
            "        [-1.7208155 ,  1.065572  , -0.48464432, ..., -1.1097012 ,\n",
            "         -0.35594222, -0.05960393],\n",
            "        [-1.7229081 ,  1.0671831 , -0.48504996, ..., -1.1090854 ,\n",
            "         -0.35358813, -0.06130953],\n",
            "        [-1.7245805 ,  1.0672901 , -0.48452315, ..., -1.1120855 ,\n",
            "         -0.35238403, -0.05966199]],\n",
            "\n",
            "       [[ 0.39487574, -0.01174552,  1.7100749 , ..., -1.3291212 ,\n",
            "          0.17987426,  1.1879531 ],\n",
            "        [-0.28599086, -0.36304092, -0.58613545, ..., -1.0405717 ,\n",
            "         -0.6164215 ,  0.57599324],\n",
            "        [-1.9641275 ,  1.1722431 ,  0.51401997, ..., -1.522638  ,\n",
            "         -0.44109207, -0.19061656],\n",
            "        ...,\n",
            "        [-0.9489639 ,  0.20557518,  0.25389814, ..., -0.5561298 ,\n",
            "          0.33181942,  1.1089976 ],\n",
            "        [-0.5327771 , -0.33922172,  1.4046835 , ..., -0.39510286,\n",
            "         -0.908338  ,  1.4593359 ],\n",
            "        [-1.5778854 ,  1.7530329 ,  0.4390716 , ..., -1.334421  ,\n",
            "          0.5049946 ,  0.26525047]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[-1.4550505 ,  0.09478377, -0.23940118, ...,  0.78985196,\n",
            "         -0.2128647 , -0.259927  ],\n",
            "        [-1.0549164 ,  0.9103853 , -1.7294655 , ...,  0.5795567 ,\n",
            "          0.02465158,  0.85546154],\n",
            "        [-0.53891826, -0.9383099 , -1.5526949 , ...,  0.39389408,\n",
            "         -0.04741279, -0.33664155],\n",
            "        ...,\n",
            "        [-1.7603779 ,  1.0418354 , -0.6924527 , ..., -0.0533064 ,\n",
            "          0.4325369 , -0.13607587],\n",
            "        [-1.7615453 ,  1.043473  , -0.6878848 , ..., -0.05037257,\n",
            "          0.43470973, -0.141773  ],\n",
            "        [-1.7604991 ,  1.0436683 , -0.6893321 , ..., -0.04557151,\n",
            "          0.43625572, -0.14349613]],\n",
            "\n",
            "       [[-1.0932245 ,  0.2575086 , -0.20192893, ..., -1.9770606 ,\n",
            "          0.02925356, -0.22733827],\n",
            "        [-0.24747218,  0.39661348,  0.786805  , ..., -1.0638534 ,\n",
            "         -0.49121913,  1.7343158 ],\n",
            "        [-0.94003445,  0.48528615,  0.26449886, ..., -0.90591085,\n",
            "         -0.3867023 , -0.4669497 ],\n",
            "        ...,\n",
            "        [-1.1822186 ,  1.202638  ,  0.19924752, ..., -1.8733943 ,\n",
            "          0.177312  ,  0.10414037],\n",
            "        [-1.1816646 ,  1.1995641 ,  0.19741134, ..., -1.8713535 ,\n",
            "          0.17846031,  0.10403562],\n",
            "        [-1.1715348 ,  1.1982023 ,  0.19541168, ..., -1.8781471 ,\n",
            "          0.18063529,  0.10036774]],\n",
            "\n",
            "       [[-1.2125163 ,  0.47235337,  0.24186942, ..., -0.12333731,\n",
            "         -0.04558584,  0.42408127],\n",
            "        [ 0.13669266, -0.1259636 ,  1.007864  , ...,  0.37473136,\n",
            "         -1.3344656 , -0.55583906],\n",
            "        [-1.5904032 ,  0.37171513, -0.16883597, ...,  0.45159778,\n",
            "         -0.01973872, -0.24153188],\n",
            "        ...,\n",
            "        [-1.3332473 ,  0.45348722, -0.9429719 , ..., -2.027745  ,\n",
            "         -1.2309077 ,  0.30256832],\n",
            "        [-1.9973245 ,  0.68711376, -0.279078  , ..., -0.65617454,\n",
            "          0.23497374,  0.2597206 ],\n",
            "        [-0.74815816, -1.0670149 ,  0.27724022, ..., -0.4863813 ,\n",
            "         -0.95364034,  0.76218426]]], dtype=float32)), label_ids=array([0., 0., 0., ..., 0., 0., 2.], dtype=float32), metrics={'test_loss': 0.2587758004665375, 'test_accuracy': 0.6145195729537366, 'test_f1': 0.467797742274957, 'test_precision': 0.37763430554324284, 'test_recall': 0.6145195729537366, 'test_runtime': 24.2954, 'test_samples_per_second': 289.15, 'test_steps_per_second': 4.528})\n",
            "Test Results: {'eval_loss': 0.2587758004665375, 'eval_accuracy': 0.6145195729537366, 'eval_f1': 0.467797742274957, 'eval_precision': 0.37763430554324284, 'eval_recall': 0.6145195729537366, 'eval_runtime': 25.2544, 'eval_samples_per_second': 278.17, 'eval_steps_per_second': 4.356, 'epoch': 7.0}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76      4317\n",
            "           1       0.00      0.00      0.00       207\n",
            "           2       0.00      0.00      0.00       221\n",
            "           3       0.00      0.00      0.00      2136\n",
            "           4       0.00      0.00      0.00       144\n",
            "\n",
            "    accuracy                           0.61      7025\n",
            "   macro avg       0.12      0.20      0.15      7025\n",
            "weighted avg       0.38      0.61      0.47      7025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['0', '1', '2', '3', '4']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffqg7AwNCu8_",
        "outputId": "ea33ef1e-4a6f-4007-ce0e-fff1da4bf5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision   Recall  F1 Score\n",
            "0   0.61452   0.377634  0.61452  0.467798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCFTWfcD1Tfb",
        "outputId": "53ba46fa-1159-4a98-f042-3f2b44051764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels: [0, 0, 0, 2, 3, 3, 0, 0, 3, 3, 3, 0, 0, 3, 2, 0, 3, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 4, 3, 0, 3, 0, 0, 2, 3, 3, 0, 0, 3, 4, 3, 3, 0, 0, 0, 3, 2, 3, 0, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3, 0, 2, 3, 0, 3, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 3, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 4, 0, 0, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 3, 2, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 1, 0, 3, 0, 0, 0, 2, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 2, 3, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 4, 0, 0, 3, 0, 3, 0, 2, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 3, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 4, 0, 0, 0, 3, 0, 4, 3, 0, 3, 3, 0, 3, 0, 1, 0, 4, 0, 0, 3, 3, 0, 2, 3, 0, 3, 3, 2, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 1, 1, 0, 3, 0, 0, 0, 3, 3, 4, 0, 0, 0, 4, 0, 0, 3, 0, 0, 3, 3, 1, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 2, 4, 3, 3, 3, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 1, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 2, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 3, 3, 0, 4, 0, 0, 0, 0, 0, 2, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 1, 2, 3, 2, 2, 2, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 4, 2, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 4, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 4, 3, 0, 3, 0, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 2, 0, 0, 4, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 1, 2, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 4, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 1, 1, 3, 2, 0, 3, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 3, 3, 4, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 3, 0, 3, 4, 4, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 2, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 4, 3, 0, 3, 3, 0, 3, 3, 3, 3, 1, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 4, 4, 4, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 0, 3, 3, 3, 0, 3, 3, 2, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 1, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 4, 3, 3, 0, 0, 0, 0, 3, 0, 3, 1, 1, 1, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 1, 1, 2, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 1, 3, 0, 3, 0, 3, 0, 3, 3, 3, 0, 1, 3, 0, 0, 0, 3, 0, 0, 3, 0, 4, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 3, 3, 4, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 1, 1, 0, 0, 0, 0, 3, 3, 3, 0, 3, 4, 3, 3, 3, 3, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 3, 3, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1, 0, 3, 0, 0, 4, 1, 3, 3, 2, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 3, 0, 0, 2, 0, 3, 3, 0, 3, 0, 0, 4, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 4, 3, 4, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 3, 0, 4, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 3, 3, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 3, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 1, 3, 4, 2, 3, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 2, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 1, 0, 3, 0, 2, 3, 4, 0, 0, 0, 3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 2, 3, 0, 0, 3, 3, 1, 3, 3, 3, 0, 3, 3, 0, 1, 0, 0, 0, 1, 4, 2, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 2, 0, 0, 3, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0, 3, 2, 3, 0, 0, 0, 0, 0, 3, 0, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 1, 3, 4, 3, 0, 4, 1, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 1, 0, 0, 0, 2, 0, 3, 3, 3, 2, 0, 0, 0, 0, 1, 1, 3, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 1, 1, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 1, 0, 0, 0, 4, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 0, 2, 0, 0, 0, 0, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 1, 2, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 4, 3, 4, 0, 0, 0, 0, 0, 3, 3, 2, 0, 0, 0, 0, 0, 3, 3, 0, 1, 3, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 1, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0, 2, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 0, 4, 3, 4, 3, 3, 0, 0, 2, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 0, 0, 1, 3, 3, 0, 3, 0, 3, 4, 0, 3, 0, 0, 1, 0, 4, 0, 2, 0, 3, 3, 3, 0, 0, 3, 0, 0, 2, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 1, 3, 2, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 2, 0, 3, 0, 0, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3, 3, 0, 0, 1, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 1, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 3, 4, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 1, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 1, 0, 0, 0, 3, 3, 4, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 2, 4, 3, 3, 0, 0, 0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 0, 2, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 2, 3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 4, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 4, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 4, 0, 3, 3, 0, 0, 1, 0, 1, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 2, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 1, 2, 3, 0, 0, 3, 3, 3, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 2, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 4, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 4, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 1, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 1, 3, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3, 4, 0, 0, 0, 4, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 4, 3, 0, 0, 3, 0, 3, 0, 2, 3, 0, 4, 0, 4, 3, 0, 0, 1, 0, 0, 0, 0, 3, 4, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 0, 1, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 3, 3, 1, 2, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 4, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 4, 1, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 2, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 2, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0, 3, 1, 1, 3, 0, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 4, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3, 0, 0, 3, 0, 3, 1, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 0, 2, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 1, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0, 4, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 2, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 2, 0, 0, 0, 3, 3, 3, 0, 3, 2, 0, 0, 0, 0, 0, 3, 3, 4, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3, 2, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 4, 4, 1, 0, 0, 4, 4, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 3, 1, 0, 3, 3, 0, 3, 1, 0, 3, 3, 3, 0, 0, 3, 2, 0, 1, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 3, 2, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 1, 0, 3, 3, 0, 3, 3, 4, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 0, 3, 3, 3, 2, 3, 3, 3, 3, 0, 3, 2, 3, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3, 3, 4, 3, 0, 0, 1, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 2, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 0, 4, 0, 1, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 1, 0, 3, 0, 3, 3, 1, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 2, 3, 0, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0, 3, 3, 0, 4, 0, 3, 0, 3, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 4, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 3, 3, 0, 3, 0, 2, 0, 3, 0, 1, 0, 0, 3, 3, 3, 3, 3, 1, 0, 3, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 3, 0, 1, 4, 0, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 0, 4, 1, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 3, 3, 2, 2, 1, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 1, 3, 3, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 2, 3, 3, 0, 3, 2, 0, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 2, 2, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 2, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 2, 0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 3, 2, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0, 2, 0, 3, 0, 0, 2, 3, 0, 0, 2, 0, 0, 1, 1, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 1, 0, 0, 0, 0, 2, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 2, 2, 2, 1, 1, 1, 1, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 4, 2, 1, 3, 0, 0, 0, 0, 0, 0, 3, 3, 2, 3, 0, 3, 0, 0, 2, 3, 3, 3, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3, 2, 0, 3, 3, 0, 0, 0, 0, 4, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 4, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 3, 3, 2, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 2, 3, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 1, 3, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 2, 1, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 3, 0, 3, 3, 0, 3, 0, 0, 2, 0, 0, 1, 3, 0, 3, 3, 2, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 4, 2, 0, 0, 3, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 1, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 0, 0, 1, 4, 3, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 2, 3, 0, 3, 3, 0, 3, 4, 0, 0, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 4, 0, 3, 0, 2, 3, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 3, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 2, 0, 0, 2, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 1, 0, 3, 0, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 3, 1, 3, 3, 2, 0, 0, 0, 0, 0, 3, 0, 0, 4, 0, 0, 3, 3, 3, 4, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 1, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 3, 3, 0, 0, 0, 3, 4, 4, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 2, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 1, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 2, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 4, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 1, 2, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 4, 0, 3, 0, 0, 0, 4, 0, 3, 0, 2, 0, 2, 3, 0, 2, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 4, 0, 3, 0, 0, 3, 0, 1, 3, 0, 3, 0, 4, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 3, 0, 2, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 1, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 4, 0, 0, 0, 0, 3, 0, 0, 1, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 0, 3, 3, 3, 1, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 3, 1, 3, 0, 3, 0, 2, 3, 4, 0, 0, 1, 0, 2, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 1, 3, 4, 3, 0, 0, 3, 0, 3, 0, 0, 0, 1, 0, 0, 3, 0, 3, 0, 2, 3, 3, 0, 4, 3, 0, 1, 0, 3, 0, 0, 0, 3, 0, 0, 3, 3, 0, 1, 3, 0, 0, 3, 0, 0, 4, 3, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 0, 0, 3, 2, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 1, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 1, 3, 0, 0, 1, 1, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 4, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 3, 3, 0, 3, 0, 0, 2, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 3, 2, 0, 0, 3, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 0, 4, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 2, 4, 0, 3, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 4, 0, 0, 3, 3, 3, 0, 3, 2, 3, 0, 0, 3, 0, 0, 0, 3, 2, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 1, 3, 3, 0, 0, 3, 0, 3, 0, 3, 1, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 4, 0, 3, 2, 0, 0, 3, 3, 3, 0, 2, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 4, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 1, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 1, 1, 0, 0, 3, 3, 3, 1, 3, 3, 0, 0, 3, 0, 0, 0, 3, 3, 1, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 4, 3, 0, 3, 0, 0, 3, 3, 2, 3, 2, 0, 3, 3, 0, 3, 3, 3, 3, 0, 4, 3, 0, 0, 4, 3, 3, 3, 0, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 4, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2]\n",
            "Predicted Labels: [0 0 0 ... 0 0 0]\n",
            "Unique Predicted Labels: [0]\n",
            "Test Dataset Labels: [0 1 2 3 4]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"predicted_labels = results.predictions[0].argmax(axis=1)\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "true_labels = np.array(test_dataset.labels).flatten()\"\"\"\n",
        "\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "print(\"Unique Predicted Labels:\", np.unique(predicted_labels))\n",
        "print(\"Test Dataset Labels:\", np.unique(test_dataset.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nbm1CKoj0UKX",
        "outputId": "3f6bc60e-11ef-4503-b0a4-33ed2a02534c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-676cbab762d7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate AUROC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUROC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         return _multiclass_roc_auc_score(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \"\"\"\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         raise ValueError(\n\u001b[1;32m    640\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#predicted_probs = torch.nn.functional.softmax(torch.tensor(predicted_labels), dim=-1).numpy()\n",
        "\n",
        "# Calculate AUROC\n",
        "auroc = roc_auc_score(true_labels, predicted_labels, multi_class='ovr')\n",
        "print(\"AUROC:\", auroc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyPwipgLOPflvyZMys0wlHG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}