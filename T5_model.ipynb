{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBandemer/capstone-mayo/blob/t5/T5_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import T5ForSequenceClassification, T5Tokenizer, TrainingArguments, Trainer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorboard.backend.event_processing import event_accumulator"
      ],
      "metadata": {
        "id": "-DSs6x7k5P13"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PoaQyof32svo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and train-test split\n",
        "# load the preprocessed dataset from a CSV file\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "# extract text data and specific SDoH categories from the dataset\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\n",
        "# prepare directories for storing train-test split data for each SDoH category\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Iterate through each SDOH data category to split and save as separate CSV files\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    )\n",
        "\n",
        "    # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grqOIcHt24wl"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def save_metrics_to_csv(json_filepath, csv_filename):\n",
        "    with open(json_filepath) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "        log_history = data['log_history']\n",
        "        df = pd.DataFrame(log_history)\n",
        "\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "def plot_metric_from_tensor(log_dir, output_dir, steps_per_epoch):\n",
        "\n",
        "    # Calculate steps_per_epoch based on training data and training arguments\n",
        "    # steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    graph1_data = event_acc.Scalars(\"eval/loss\")\n",
        "    graph2_data = event_acc.Scalars(\"train/loss\")\n",
        "\n",
        "    # convert steps to epochs\n",
        "    epochs1 = [event.step / steps_per_epoch for event in graph1_data]\n",
        "    values1 = [event.value for event in graph1_data]\n",
        "\n",
        "    epochs2 = [event.step / steps_per_epoch for event in graph2_data]\n",
        "    values2 = [event.value for event in graph2_data]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(epochs1, values1, label=\"Validation Loss\")\n",
        "    plt.plot(epochs2, values2, label=\"Train Loss\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Overlap\")\n",
        "    # plt.show()\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the graph to the specified folder\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.show()\n",
        "\n",
        "# evaluation metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions[0].argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def get_latest_checkpoint(folder_path):\n",
        "    # Get a list of all files and directories in the specified folder\n",
        "    files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "    # Filter only directories (assumed to be checkpoints)\n",
        "    checkpoint_dirs = [d for d in files_and_dirs if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "    if not checkpoint_dirs:\n",
        "        print(\"No checkpoint directories found.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the checkpoint numbers from the directory names\n",
        "    checkpoint_numbers = [int(d.split('-')[1]) for d in checkpoint_dirs]\n",
        "\n",
        "    # Identify the directory with the highest checkpoint number\n",
        "    latest_checkpoint = os.path.join(folder_path, f\"checkpoint-{max(checkpoint_numbers)}\")\n",
        "\n",
        "    return latest_checkpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/checkpoint_epoch_{epoch}.pth'\n",
        "best_model_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/checkpoints/best_model.pth'\n",
        "\n",
        "\n",
        "# Saving the checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, loss, val_loss, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'val_loss': val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    if is_best:\n",
        "        torch.save(model.state_dict(), best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kgr3zQq_u2lB"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "csqlu1lfu2n-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c83607-6ac1-45cf-ffd4-9fa068a69915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForSequenceClassification(\n",
              "  (transformer): T5Model(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): T5ClassificationHead(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Define label_columns here\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['behavior_alcohol']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9CVvlmjwzPb"
      },
      "outputs": [],
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gz_TbUC_3p0y"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data)\n",
        "max_seq_length = 100\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sPuxaTGu2qf"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list()\n",
        "\"\"\"sdoh_data = {\n",
        "    \"sdoh_community_present\": dataset[\"sdoh_community_present\"].to_list(),\n",
        "    \"sdoh_community_absent\": dataset[\"sdoh_community_absent\"].to_list(),\n",
        "    \"sdoh_education\": dataset[\"sdoh_education\"].to_list(),\n",
        "    \"sdoh_economics\": dataset[\"sdoh_economics\"].to_list(),\n",
        "    \"sdoh_environment\": dataset[\"sdoh_environment\"].to_list(),\n",
        "    \"behavior_alcohol\": dataset[\"behavior_alcohol\"].to_list(),\n",
        "    \"behavior_tobacco\": dataset[\"behavior_tobacco\"].to_list(),\n",
        "    \"behavior_drug\": dataset[\"behavior_drug\"].to_list()\n",
        "}\n",
        "\"\"\"\n",
        "base_path = 'test_train_split/behavior_drug'\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size = .8, stratify=sdoh_data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0, test_size = .01)\n",
        "for category, data in sdoh_data.items():\n",
        "    base_path = f\"test_train_split/{category}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Split data for the current category\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        text_data, data, random_state=0, train_size=0.8, stratify=data\n",
        "    ) #maybe try a different test size (0.7/0.3)\n",
        "\n",
        "        # Save all splits as CSV files\n",
        "    pd.DataFrame({\"text\": X_train}).to_csv(f\"{base_path}/X_train.csv\", index=False)\n",
        "    pd.DataFrame({\"text\": X_val}).to_csv(f\"{base_path}/X_val.csv\", index=False)\n",
        "    pd.DataFrame({category: y_train}).to_csv(f\"{base_path}/y_train.csv\", index=False)\n",
        "    pd.DataFrame({category: y_val}).to_csv(f\"{base_path}/y_val.csv\", index=False)\n",
        "\n",
        "max_seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWo_hibZu2tJ"
      },
      "outputs": [],
      "source": [
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JkZier8Iu2vr"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: change label to float for sdoh_economics, sdoh_environment\n",
        "\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Retrieve tokenized data for the given index\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            # Add the label for the given index to the item dictionary\n",
        "            item['labels'] = torch.tensor(float(self.labels[idx]))\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Aewf93yu2yL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataLoader(train_encodings, y_train)\n",
        "val_dataset = DataLoader(val_encodings,y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K13qpoJCu26R"
      },
      "outputs": [],
      "source": [
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/tensor_logs/{timestamp_fortrain}' # create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'/content/drive/MyDrive/Colab Notebooks/Capstone/logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i8-ZZN5mu286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a50abe55-7a0e-453f-fd94-b73b369c4c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [616/616 07:00, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.775900</td>\n",
              "      <td>1.284825</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.145100</td>\n",
              "      <td>1.479923</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.939900</td>\n",
              "      <td>1.673701</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.782400</td>\n",
              "      <td>0.854065</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.671500</td>\n",
              "      <td>0.673932</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.581000</td>\n",
              "      <td>0.721593</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.406400</td>\n",
              "      <td>0.529921</td>\n",
              "      <td>0.236299</td>\n",
              "      <td>0.090330</td>\n",
              "      <td>0.055837</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "There were missing keys in the checkpoint model loaded: ['transformer.encoder.embed_tokens.weight', 'transformer.decoder.embed_tokens.weight'].\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.5299213528633118, 'eval_accuracy': 0.23629893238434163, 'eval_f1': 0.09032958612734764, 'eval_precision': 0.055837185445979653, 'eval_recall': 0.23629893238434163, 'eval_runtime': 4.633, 'eval_samples_per_second': 303.258, 'eval_steps_per_second': 4.749, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "] # change this\n",
        "#label_columns = ['sdoh_community_present']\n",
        "num_labels = len(label_columns)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", num_labels=num_labels)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "configuration = T5ForSequenceClassification.config_class.from_pretrained(\"t5-small\", num_labels= num_labels)\n",
        "configuration.pad_token_id = tokenizer.pad_token_id\n",
        "model = T5ForSequenceClassification(configuration)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\")\n",
        "text_data = dataset[\"text\"].to_list()\n",
        "sdoh_data = dataset[\"behavior_alcohol\"].to_list() # change this\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(text_data, sdoh_data, random_state=0, train_size=0.8,\n",
        "                                                  stratify=sdoh_data) #make it test = 0.3\n",
        "max_seq_length = 100  # actually 50 but increase to accomadate outliers\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "model_size_MB = num_trainable_params * 4 / (1024 ** 2)\n",
        "effective_batch = 8 / (50*4*model_size_MB) #gpu/seqlength * 4 * model size\n",
        "\n",
        "# define training arguments and start training with the Trainer\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "# custom Dataset class for loading training and validation data\n",
        "class DataLoader(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Converting to tensor , maybe use just 'labels'\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx].clone().detach()  # Already a tensor, just clone and detach\n",
        "            return item\n",
        "        except Exception as e:\n",
        "            print(f\"index error: {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # detach from tensor device\n",
        "\n",
        "# Initialize the DataLoader for training and validation sets with the tokenized encodings\n",
        "train_dataset: DataLoader = DataLoader(\n",
        "    train_encodings,  # These should be the output from the tokenizer\n",
        "    y_train  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "val_dataset = DataLoader(\n",
        "    val_encodings,  # These should be the output from the tokenizer\n",
        "    y_val  # These should be labels, as a list or tensor\n",
        ")\n",
        "\n",
        "timestamp_fortrain = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "tensor_logs = f'./logs/tensor_logs/{timestamp_fortrain}' #create seperate logs for tensor/epoch\n",
        "os.makedirs(tensor_logs, exist_ok=True)\n",
        "epoch_logs = f'./logs/epoch_logs/{timestamp_fortrain}'\n",
        "os.makedirs(epoch_logs, exist_ok=True)\n",
        "\"\"\"\n",
        "# training args - need to adjust\n",
        "training_args = TrainingArguments(\n",
        "      output_dir= epoch_logs,  # change to epoch log directory, convert to a text\n",
        "      logging_strategy='epoch',  # characterize as epoch\n",
        "      num_train_epochs=7, # have high epoch\n",
        "      #per_device_train_batch_size=64,  # cpu constraint,  64 approp\n",
        "      per_device_train_batch_size=64, #reduced batch sie\n",
        "      per_device_eval_batch_size=64,  # gradient accum if batch size of two, 64 approp\n",
        "      save_strategy= 'epoch',\n",
        "      warmup_steps=500,\n",
        "      weight_decay=1e-5,\n",
        "      logging_dir= tensor_logs,  # change to tensor logs\n",
        "      #eval_steps=100,\n",
        "      evaluation_strategy=\"epoch\",\n",
        "      #accumulate gradients over 4 steps\n",
        "      #gradient_accumulation_steps = 4\n",
        "      load_best_model_at_end=True,  # This will load the best model at the end of training\n",
        "      metric_for_best_model=\"eval_loss\",  # Use eval_loss to determine the best model\n",
        "      greater_is_better=False,  # Set to False because a lower loss is better\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()\n",
        "\n",
        "# evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Save checkpoint after every epoch\n",
        "#save_checkpoint(model, optimizer, epoch, current_loss, current_val_loss, is_best=False)\n",
        "\n",
        "#readable results\n",
        "steps_per_epoch = len(train_dataset) // training_args.per_device_train_batch_size\n",
        "latest_checkpoint = get_latest_checkpoint(epoch_logs) # latest checkpoint update to csv\n",
        "json_path = os.path.join(latest_checkpoint, 'trainer_state.json')\n",
        "save_metrics_to_csv(json_path, 'eval_metric.csv') #update metrics\n",
        "plot_metric_from_tensor(tensor_logs, 'graphs', steps_per_epoch)\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]"
      ],
      "metadata": {
        "id": "qvHjlczRfoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "2y3hG9frfp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUdxBtaG5BV6"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "trainer.train()\n",
        "\n",
        "# Extract loss values\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "val_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract evaluation loss values from the log history\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# evaluation loss for all epochs\n",
        "for epoch, loss in enumerate(eval_losses):\n",
        "    print(f\"Epoch {epoch + 1}: Evaluation Loss = {loss}\")\n",
        "\n",
        "# epoch with the minimum evaluation loss\n",
        "best_epoch = eval_losses.index(min(eval_losses)) + 1\n",
        "print(f'Best epoch: {best_epoch}')\n",
        "\n",
        "\"\"\"test_result = trainer.evaluate(val_dataset)\n",
        "# Report precision, recall, and F1 score\n",
        "y_true = val_dataset['labels']\n",
        "y_pred = trainer.predict(val_dataset).label_ids\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaNyYGquaOlP"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "for epoch, loss in enumerate(train_loss):\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic9VsIfu3BF"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN\n",
        "# Saving & Loading the model<br>\n",
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "evaluation_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "283glZPjeRK3"
      },
      "outputs": [],
      "source": [
        "# Evaluation on Test Data\n",
        "\n",
        "# function to evaluate the trained model on test data\n",
        "def evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512):\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
        "    model = T5ForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Load the test data\n",
        "    test_dataset = pd.read_csv(test_data_path)\n",
        "    texts = test_dataset[\"text\"].tolist()\n",
        "\n",
        "    # collect true labels and predictions for each label\n",
        "    true_labels = {label: test_dataset[label].tolist() for label in label_columns}\n",
        "\n",
        "    # Tokenize the test data\n",
        "    test_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "\n",
        "    # Custom Dataset for test data\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            #return {key: val[idx] for key, val in self.encodings.items()}\n",
        "              return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # prepare DataLoader for test data\n",
        "    test_dataset = TestDataset(test_encodings)\n",
        "    test_loader = DataLoader(test_dataset, val_dataset)\n",
        "\n",
        "    # Prepare to collect predictions\n",
        "    predictions = {label: [] for label in label_columns}\n",
        "    results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        sigmoid_logits = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid function for binary classification on logits\n",
        "        threshold = 0.5\n",
        "        binary_predictions = (sigmoid_logits > threshold).astype(int)  # Apply threshold to get binary predictions\n",
        "        # Collect binary_predictions for the labels\n",
        "        for i, label in enumerate(label_columns):\n",
        "            predictions[label].extend(binary_predictions[:, i])\n",
        "\n",
        "    # calculate and print the metrics for each label\n",
        "    for label in label_columns:\n",
        "        accuracy = accuracy_score(true_labels[label], predictions[label])\n",
        "        precision = precision_score(true_labels[label], predictions[label], average='weighted')\n",
        "        recall = recall_score(true_labels[label], predictions[label], average='weighted')\n",
        "        f1 = f1_score(true_labels[label], predictions[label], average='weighted')\n",
        "        report = classification_report(true_labels[label], predictions[label], zero_division=0)\n",
        "\n",
        "          # Append the results for the current label to the list\n",
        "        results.append({\n",
        "          'Label': label,\n",
        "          'Accuracy': accuracy,\n",
        "          'Precision': precision,\n",
        "          'Recall': recall,\n",
        "          'F1 Score': f1\n",
        "        })\n",
        "\n",
        "        # Print the results for the current label\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(f\"Metrics for {label}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        # Convert the list of results to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv('/content/model_evaluation_results.csv', index=False)\n",
        "        print(\"Evaluation results saved to /content/model_evaluation_results.csv\")\n",
        "        print(\"Test evaluation completed for all labels.\")\n",
        "\n",
        "# Paths to the model, tokenizer, and test data\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/Capstone/PREPROCESSED-NOTES.csv\"\n",
        "\n",
        "# List of label columns in your test data for evaluation\n",
        "\"\"\"label_columns = [\n",
        "    'sdoh_community_present', 'sdoh_community_absent', 'sdoh_education',\n",
        "    'sdoh_economics', 'sdoh_environment', 'behavior_alcohol',\n",
        "    'behavior_tobacco', 'behavior_drug'\n",
        "]\"\"\"\n",
        "label_columns = ['sdoh_community_present']\n",
        "\n",
        "# Call the function to evaluate on test data\n",
        "evaluate_on_test_data(model_path, test_data_path, tokenizer_path, label_columns, max_seq_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_encodings = tokenizer(text_data, truncation=True, padding='max_length', max_length=max_seq_length, return_tensors='pt')\n",
        "test_dataset = DataLoader(test_encodings, sdoh_data)\n",
        "\n",
        "\"\"\"tokenizer = T5Tokenizer.from_pretrained(/content/logs/epoch_logs)\n",
        "model = T5ForSequenceClassification.from_pretrained(tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\"\"\"\n",
        "\n",
        "best_checkpoint_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Capstone/t5\")\n",
        "\n",
        "model = T5ForSequenceClassification.from_pretrained(best_checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "#test_metrics = compute_metrics(test_results)\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "print(\"Prediction:\", results)\n",
        "\n",
        "predicted_labels = results.predictions[0].argmax(-1)\n",
        "true_labels = test_dataset.labels\n",
        "# true_labels = test_dataset[label_columns].tolist() #  labels from the DataLoader\n",
        "target_names_binary = ['0', '1', '2', '3', '4']\n",
        "\n",
        "print(\"Test Results:\", test_results)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=target_names_binary))"
      ],
      "metadata": {
        "id": "yxR5iKE9QHH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e480e681-bcdd-4e1d-955b-71fddd2409e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-9-d7e363410469>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: PredictionOutput(predictions=(array([[ 0.1827819 ],\n",
            "       [ 1.3221704 ],\n",
            "       [ 3.080827  ],\n",
            "       ...,\n",
            "       [-0.04516848],\n",
            "       [ 1.326191  ],\n",
            "       [ 0.9090392 ]], dtype=float32), array([[[-4.32080954e-01,  2.49196529e+00, -4.87178832e-01, ...,\n",
            "         -8.19038033e-01, -9.33901846e-01, -9.20616925e-01],\n",
            "        [-7.65223086e-01,  1.01387358e+00, -5.07223606e-01, ...,\n",
            "         -2.77237058e-01, -6.13972008e-01, -1.29092956e+00],\n",
            "        [ 8.75780106e-01,  1.54866731e+00,  4.48801935e-01, ...,\n",
            "         -6.57460749e-01, -3.67442518e-01, -6.51225746e-01],\n",
            "        ...,\n",
            "        [ 2.81931390e-03,  1.29879546e+00, -8.94482434e-01, ...,\n",
            "          3.53449166e-01, -7.28254616e-01, -5.79916477e-01],\n",
            "        [ 2.93007446e-03,  1.29990494e+00, -8.94252360e-01, ...,\n",
            "          3.51084381e-01, -7.26339102e-01, -5.80450356e-01],\n",
            "        [ 7.26539129e-03,  1.29893708e+00, -8.95615935e-01, ...,\n",
            "          3.46366733e-01, -7.28210270e-01, -5.79465508e-01]],\n",
            "\n",
            "       [[ 1.67508304e-01,  2.11883354e+00, -6.72383547e-01, ...,\n",
            "         -1.67773676e+00,  1.05166160e-01,  2.69975007e-01],\n",
            "        [-2.12308615e-01,  2.36108375e+00, -3.88864338e-01, ...,\n",
            "         -7.46575058e-01, -1.33637857e+00, -8.86245191e-01],\n",
            "        [ 2.15831590e+00,  1.37804449e+00,  4.82027501e-01, ...,\n",
            "         -1.13764167e+00, -3.44811678e-01, -3.70825231e-01],\n",
            "        ...,\n",
            "        [ 2.40167648e-01,  1.72427785e+00, -1.02560616e+00, ...,\n",
            "          1.28830299e-01, -7.14247823e-01,  1.23300448e-01],\n",
            "        [ 2.43003666e-01,  1.72393572e+00, -1.02318859e+00, ...,\n",
            "          1.31128639e-01, -7.15176702e-01,  1.21303394e-01],\n",
            "        [ 2.42095292e-01,  1.72177970e+00, -1.02289045e+00, ...,\n",
            "          1.35403007e-01, -7.17640042e-01,  1.23057954e-01]],\n",
            "\n",
            "       [[ 7.21664190e-01, -5.98965704e-01,  4.72920418e-01, ...,\n",
            "          1.40941072e+00,  8.12490582e-01, -1.19571137e+00],\n",
            "        [ 3.63416791e-01,  1.55555204e-01, -9.24198925e-01, ...,\n",
            "          1.00286245e+00, -2.68494487e-02, -1.18398046e+00],\n",
            "        [ 7.71221459e-01, -6.39092147e-01, -1.23156473e-01, ...,\n",
            "          8.07015896e-01, -1.26174167e-01, -1.43419743e+00],\n",
            "        ...,\n",
            "        [ 2.63868499e+00, -9.20487404e-01,  8.52435112e-01, ...,\n",
            "          1.13140130e+00, -2.23351464e-01, -2.37125203e-01],\n",
            "        [-2.56429911e-01, -8.70003700e-01,  6.29851699e-01, ...,\n",
            "          9.19805348e-01,  2.54434347e-01, -2.07504940e+00],\n",
            "        [-4.29944813e-01, -6.86404765e-01, -2.81619221e-01, ...,\n",
            "          2.12673640e+00,  1.14299762e+00, -9.40484226e-01]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 6.10271275e-01,  2.91460371e+00,  2.91456819e-01, ...,\n",
            "         -5.12205303e-01, -1.88897288e+00, -5.02038300e-01],\n",
            "        [-7.56985992e-02,  1.96209502e+00, -5.35168469e-01, ...,\n",
            "          7.27760017e-01, -1.20527148e+00, -7.62905896e-01],\n",
            "        [ 6.27286851e-01,  2.69700694e+00, -7.20207214e-01, ...,\n",
            "         -2.66226172e-01, -1.28709519e+00, -3.96507114e-01],\n",
            "        ...,\n",
            "        [ 1.99904025e-01,  1.91214299e+00, -6.58776164e-01, ...,\n",
            "          9.10761297e-01, -1.03007090e+00, -3.17193151e-01],\n",
            "        [ 2.02552378e-01,  1.90816081e+00, -6.60024226e-01, ...,\n",
            "          9.11534607e-01, -1.03138947e+00, -3.14620554e-01],\n",
            "        [ 2.03099757e-01,  1.91026723e+00, -6.61046147e-01, ...,\n",
            "          9.11064267e-01, -1.03262961e+00, -3.15671563e-01]],\n",
            "\n",
            "       [[ 8.51330638e-01,  1.01432967e+00,  6.39352500e-01, ...,\n",
            "         -1.24531734e+00, -1.26023281e+00, -2.99189359e-01],\n",
            "        [-4.12941515e-01,  6.04767799e-01, -1.29116821e+00, ...,\n",
            "         -2.92600989e-01, -1.48681164e+00, -1.98652613e+00],\n",
            "        [ 2.30399966e-01,  1.86771667e+00, -3.82739604e-01, ...,\n",
            "         -4.20728654e-01, -2.02526689e+00, -1.37594044e+00],\n",
            "        ...,\n",
            "        [-7.69299194e-02,  1.14606118e+00, -9.38667655e-01, ...,\n",
            "          7.05047101e-02, -1.37389874e+00, -2.46076331e-01],\n",
            "        [-7.44712204e-02,  1.14590633e+00, -9.39199448e-01, ...,\n",
            "          6.89259842e-02, -1.37468708e+00, -2.49403611e-01],\n",
            "        [-7.78184459e-02,  1.14711857e+00, -9.36959743e-01, ...,\n",
            "          6.98823631e-02, -1.37158954e+00, -2.43663281e-01]],\n",
            "\n",
            "       [[-1.66300222e-01, -1.10018127e-01,  2.68902928e-02, ...,\n",
            "          6.29825830e-01, -2.14696193e+00, -2.03046656e+00],\n",
            "        [ 7.72316039e-01, -2.53899813e-01, -4.91079122e-01, ...,\n",
            "          2.49591187e-01, -2.51070082e-01,  3.09537500e-01],\n",
            "        [-1.70156583e-01,  7.28011787e-01, -1.64052173e-02, ...,\n",
            "         -1.04430938e+00,  4.69575763e-01, -7.15657711e-01],\n",
            "        ...,\n",
            "        [-1.03139386e-01,  6.96389079e-01,  1.05277109e+00, ...,\n",
            "         -1.87748834e-01, -1.70705366e+00, -2.12706733e+00],\n",
            "        [-1.44202673e+00,  1.23162997e+00, -6.99033797e-01, ...,\n",
            "         -7.72327259e-02, -4.54256624e-01, -1.16602230e+00],\n",
            "        [-9.22502875e-01,  2.79058397e-01,  4.42981064e-01, ...,\n",
            "         -1.34729773e-01, -3.69384766e-01, -1.77576399e+00]]],\n",
            "      dtype=float32)), label_ids=array([0., 0., 3., ..., 0., 1., 4.], dtype=float32), metrics={'test_loss': 0.3416479229927063, 'test_accuracy': 0.23587188612099644, 'test_f1': 0.0900344886667798, 'test_precision': 0.05563554666227631, 'test_recall': 0.23587188612099644, 'test_runtime': 22.9268, 'test_samples_per_second': 306.41, 'test_steps_per_second': 4.798})\n",
            "Test Results: {'eval_loss': 0.3416479229927063, 'eval_accuracy': 0.23587188612099644, 'eval_f1': 0.0900344886667798, 'eval_precision': 0.05563554666227631, 'eval_recall': 0.23587188612099644, 'eval_runtime': 23.5198, 'eval_samples_per_second': 298.684, 'eval_steps_per_second': 4.677, 'epoch': 7.0}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      1.00      0.38      1657\n",
            "           1       0.00      0.00      0.00      2077\n",
            "           2       0.00      0.00      0.00       515\n",
            "           3       0.00      0.00      0.00      2444\n",
            "           4       0.00      0.00      0.00       332\n",
            "\n",
            "    accuracy                           0.24      7025\n",
            "   macro avg       0.05      0.20      0.08      7025\n",
            "weighted avg       0.06      0.24      0.09      7025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'Precision': [precision],\n",
        "    'Recall': [recall],\n",
        "    'F1 Score': [f1],\n",
        "})\n",
        "print(\"Metrics Table:\\n\", metrics_df)"
      ],
      "metadata": {
        "id": "ffqg7AwNCu8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008bc47d-9603-4a49-f185-8210620cefd8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Table:\n",
            "    Accuracy  Precision    Recall  F1 Score\n",
            "0  0.235872   0.055636  0.235872  0.090034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"predicted_labels = results.predictions[0].argmax(axis=1)\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "\n",
        "true_labels = np.array(test_dataset.labels).flatten()\n",
        "true_labels = np.array(test_dataset.labels).flatten()\"\"\"\n",
        "\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "print(\"Unique Predicted Labels:\", np.unique(predicted_labels))\n",
        "print(\"Test Dataset Labels:\", np.unique(test_dataset.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCFTWfcD1Tfb",
        "outputId": "ca858a78-4eda-414c-c38c-0a6a2fc42d56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels: [0, 0, 3, 3, 3, 3, 1, 3, 3, 0, 2, 1, 3, 1, 2, 0, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 0, 3, 4, 1, 0, 3, 1, 3, 3, 3, 3, 1, 2, 1, 4, 3, 3, 1, 3, 0, 3, 1, 1, 3, 0, 3, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 0, 3, 3, 0, 1, 0, 2, 0, 0, 1, 1, 0, 3, 1, 1, 0, 3, 0, 0, 0, 0, 0, 4, 1, 1, 3, 3, 3, 1, 0, 1, 0, 0, 1, 3, 0, 2, 0, 2, 2, 3, 0, 1, 3, 0, 3, 1, 0, 3, 1, 0, 1, 3, 3, 3, 0, 1, 3, 1, 3, 1, 2, 3, 3, 1, 3, 0, 0, 1, 2, 1, 0, 1, 3, 0, 1, 3, 1, 2, 3, 4, 3, 3, 4, 0, 3, 1, 0, 3, 3, 4, 3, 3, 3, 3, 0, 3, 1, 1, 3, 3, 0, 3, 1, 0, 3, 3, 0, 4, 3, 3, 0, 0, 3, 3, 3, 3, 0, 1, 0, 3, 1, 0, 3, 2, 0, 1, 3, 1, 0, 3, 0, 1, 3, 0, 3, 3, 1, 3, 0, 3, 3, 1, 0, 1, 1, 0, 0, 3, 0, 1, 3, 3, 3, 0, 3, 3, 3, 0, 2, 1, 1, 0, 3, 4, 0, 0, 3, 2, 4, 3, 3, 1, 1, 0, 3, 4, 1, 0, 0, 2, 4, 3, 2, 4, 3, 1, 1, 0, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 0, 1, 0, 1, 1, 1, 2, 3, 3, 3, 0, 1, 4, 0, 3, 0, 3, 0, 1, 4, 0, 1, 0, 3, 3, 3, 0, 0, 3, 3, 1, 1, 1, 0, 3, 1, 0, 0, 0, 0, 1, 3, 0, 3, 2, 2, 3, 1, 0, 3, 0, 1, 3, 4, 4, 1, 0, 3, 3, 1, 1, 3, 1, 3, 3, 0, 0, 3, 0, 3, 3, 1, 1, 3, 3, 0, 0, 0, 0, 0, 1, 3, 1, 3, 1, 3, 0, 1, 1, 1, 0, 1, 3, 3, 4, 3, 1, 0, 3, 0, 3, 0, 3, 0, 2, 2, 1, 3, 3, 1, 1, 3, 1, 1, 1, 0, 3, 0, 1, 1, 3, 3, 0, 1, 1, 1, 1, 1, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 3, 4, 1, 3, 1, 1, 1, 0, 1, 2, 0, 0, 3, 1, 1, 1, 0, 3, 4, 1, 0, 3, 1, 1, 3, 3, 3, 3, 1, 3, 2, 3, 0, 3, 3, 3, 0, 4, 1, 0, 4, 3, 3, 3, 1, 3, 0, 0, 1, 3, 1, 3, 1, 0, 0, 2, 1, 0, 1, 0, 1, 0, 1, 1, 3, 3, 3, 0, 3, 1, 3, 1, 1, 2, 2, 3, 1, 3, 1, 0, 3, 3, 3, 4, 0, 3, 3, 0, 4, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 0, 2, 2, 3, 3, 3, 4, 2, 3, 3, 3, 3, 3, 2, 0, 3, 3, 4, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 3, 0, 1, 3, 3, 1, 3, 3, 3, 3, 0, 1, 0, 1, 1, 2, 2, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 0, 3, 1, 1, 3, 1, 0, 0, 3, 3, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 4, 0, 1, 1, 2, 1, 0, 0, 3, 3, 1, 3, 1, 1, 1, 3, 3, 2, 3, 2, 1, 1, 1, 0, 3, 3, 1, 3, 3, 1, 1, 3, 0, 1, 1, 1, 1, 1, 3, 1, 1, 0, 3, 0, 0, 1, 3, 2, 1, 1, 3, 0, 3, 1, 0, 2, 2, 1, 1, 3, 3, 3, 1, 1, 3, 3, 1, 0, 3, 4, 3, 3, 1, 3, 0, 3, 0, 0, 3, 3, 2, 1, 3, 3, 3, 4, 3, 4, 1, 3, 3, 3, 1, 3, 0, 1, 1, 0, 3, 2, 0, 3, 1, 1, 0, 3, 4, 1, 1, 0, 3, 1, 3, 1, 1, 1, 1, 3, 3, 0, 0, 3, 1, 0, 3, 3, 0, 0, 1, 3, 3, 3, 0, 1, 1, 4, 1, 1, 3, 3, 0, 1, 3, 3, 1, 1, 1, 0, 1, 1, 3, 3, 2, 0, 3, 3, 3, 2, 3, 1, 3, 3, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 2, 3, 3, 3, 3, 1, 4, 3, 4, 0, 3, 2, 3, 1, 1, 1, 1, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 1, 1, 1, 4, 0, 3, 4, 3, 3, 3, 3, 1, 0, 3, 3, 4, 2, 3, 3, 3, 1, 1, 3, 1, 3, 3, 4, 3, 4, 4, 3, 4, 3, 1, 0, 3, 1, 1, 0, 1, 2, 2, 0, 3, 2, 1, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 1, 3, 3, 1, 3, 0, 3, 3, 4, 3, 3, 3, 1, 0, 4, 1, 0, 1, 1, 3, 3, 3, 0, 3, 3, 1, 3, 3, 0, 0, 3, 2, 1, 1, 0, 3, 1, 2, 3, 3, 0, 1, 0, 3, 0, 1, 3, 0, 0, 1, 1, 3, 3, 1, 1, 3, 0, 3, 4, 3, 1, 3, 3, 3, 3, 4, 4, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 3, 3, 0, 3, 3, 3, 2, 0, 3, 3, 1, 1, 0, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 1, 1, 0, 0, 1, 1, 0, 3, 1, 0, 1, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 0, 1, 3, 0, 0, 3, 4, 1, 1, 1, 3, 1, 1, 0, 3, 3, 1, 0, 0, 4, 1, 3, 2, 0, 4, 1, 1, 0, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 0, 4, 3, 1, 3, 3, 1, 3, 3, 3, 3, 1, 0, 0, 1, 0, 1, 4, 0, 0, 1, 1, 1, 2, 0, 3, 3, 0, 0, 0, 1, 3, 1, 0, 1, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 1, 0, 1, 3, 1, 2, 1, 2, 3, 3, 0, 3, 3, 1, 0, 3, 3, 1, 3, 0, 1, 0, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 0, 0, 1, 3, 3, 3, 3, 3, 1, 3, 2, 1, 3, 0, 1, 0, 3, 3, 4, 0, 0, 1, 0, 3, 3, 1, 1, 3, 3, 0, 1, 3, 3, 1, 0, 3, 1, 4, 3, 3, 3, 1, 3, 3, 1, 1, 1, 1, 4, 3, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 3, 3, 0, 3, 3, 1, 3, 3, 3, 2, 3, 3, 1, 0, 1, 3, 0, 3, 0, 0, 0, 0, 4, 4, 2, 2, 2, 2, 0, 4, 3, 1, 1, 3, 3, 0, 3, 1, 2, 3, 3, 0, 3, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 1, 3, 3, 1, 1, 3, 3, 0, 1, 0, 0, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0, 1, 0, 1, 3, 0, 1, 3, 3, 3, 1, 3, 1, 1, 0, 3, 0, 1, 1, 3, 3, 3, 3, 1, 1, 1, 3, 1, 3, 3, 1, 3, 0, 0, 3, 1, 3, 1, 3, 3, 2, 1, 2, 2, 1, 3, 3, 0, 0, 0, 1, 1, 1, 3, 3, 2, 2, 2, 3, 3, 3, 0, 1, 2, 3, 1, 0, 1, 3, 3, 1, 2, 2, 1, 1, 3, 3, 4, 0, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 2, 2, 3, 3, 3, 3, 1, 0, 3, 3, 1, 0, 1, 0, 0, 3, 3, 0, 0, 1, 3, 3, 3, 1, 3, 1, 1, 3, 1, 1, 1, 0, 3, 3, 2, 3, 3, 3, 3, 0, 4, 1, 1, 3, 1, 3, 3, 3, 3, 3, 1, 3, 0, 3, 0, 3, 3, 3, 0, 1, 1, 2, 0, 4, 3, 0, 3, 1, 1, 1, 0, 3, 3, 3, 1, 3, 0, 3, 1, 3, 0, 0, 0, 1, 1, 0, 0, 1, 2, 2, 3, 0, 3, 1, 1, 3, 3, 3, 3, 1, 3, 0, 0, 1, 1, 3, 1, 1, 1, 0, 4, 3, 1, 1, 3, 3, 1, 3, 2, 1, 3, 1, 3, 4, 1, 3, 1, 0, 0, 3, 1, 4, 3, 1, 1, 0, 3, 0, 1, 3, 3, 1, 1, 0, 3, 0, 0, 3, 3, 0, 3, 1, 0, 0, 1, 1, 0, 2, 1, 0, 3, 3, 0, 3, 0, 0, 1, 2, 0, 1, 0, 1, 1, 1, 3, 1, 3, 4, 1, 3, 1, 1, 0, 2, 0, 0, 1, 1, 1, 3, 3, 0, 3, 3, 0, 3, 0, 4, 1, 0, 3, 3, 1, 0, 3, 3, 1, 1, 0, 3, 3, 1, 4, 0, 3, 1, 0, 2, 3, 1, 4, 0, 0, 1, 1, 1, 3, 2, 0, 1, 3, 0, 0, 0, 1, 4, 3, 1, 1, 3, 3, 3, 3, 3, 0, 0, 1, 1, 0, 1, 1, 1, 3, 0, 1, 3, 3, 2, 2, 0, 3, 3, 0, 3, 1, 0, 0, 1, 3, 3, 3, 0, 0, 3, 0, 3, 3, 2, 0, 3, 0, 3, 1, 2, 0, 2, 3, 1, 0, 1, 0, 4, 3, 0, 1, 1, 1, 0, 0, 3, 1, 0, 3, 3, 0, 2, 0, 1, 0, 3, 0, 3, 1, 3, 3, 0, 1, 1, 1, 3, 1, 3, 0, 3, 3, 4, 1, 3, 4, 3, 1, 1, 1, 3, 3, 3, 1, 2, 2, 0, 0, 3, 1, 0, 4, 1, 3, 3, 3, 3, 3, 1, 3, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1, 3, 3, 0, 3, 1, 0, 1, 4, 4, 0, 3, 3, 0, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 4, 3, 3, 3, 3, 1, 4, 0, 0, 0, 0, 2, 3, 3, 4, 1, 1, 4, 1, 1, 3, 4, 0, 3, 0, 2, 2, 3, 0, 1, 1, 0, 0, 4, 1, 3, 1, 0, 1, 1, 3, 1, 0, 3, 3, 1, 1, 3, 1, 4, 3, 1, 0, 4, 3, 3, 0, 1, 1, 1, 3, 3, 0, 3, 3, 1, 1, 3, 1, 0, 0, 1, 3, 0, 1, 3, 1, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 2, 0, 0, 2, 3, 2, 0, 3, 4, 4, 3, 2, 2, 1, 1, 1, 0, 3, 3, 1, 0, 0, 0, 3, 0, 0, 3, 3, 4, 3, 2, 3, 0, 0, 0, 0, 0, 3, 0, 1, 3, 3, 3, 3, 3, 0, 3, 1, 1, 1, 3, 2, 1, 0, 3, 0, 0, 3, 1, 3, 3, 3, 0, 0, 0, 3, 0, 1, 3, 2, 1, 1, 0, 1, 1, 3, 2, 1, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 1, 3, 0, 3, 3, 3, 3, 0, 2, 2, 3, 2, 2, 3, 3, 1, 1, 0, 1, 0, 1, 3, 3, 0, 3, 3, 2, 3, 1, 0, 0, 4, 2, 2, 1, 0, 0, 4, 0, 0, 0, 3, 1, 2, 3, 3, 3, 3, 0, 4, 3, 3, 0, 1, 2, 0, 0, 0, 1, 1, 3, 2, 4, 4, 3, 3, 3, 3, 0, 3, 1, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 1, 1, 3, 2, 3, 2, 3, 3, 4, 0, 4, 0, 0, 1, 3, 0, 0, 0, 1, 3, 1, 4, 0, 0, 3, 0, 4, 3, 0, 3, 1, 1, 1, 3, 1, 3, 3, 4, 4, 0, 3, 3, 3, 1, 3, 3, 0, 1, 0, 3, 0, 0, 3, 3, 0, 2, 1, 3, 0, 0, 1, 3, 3, 1, 1, 0, 3, 0, 3, 1, 0, 3, 3, 3, 1, 2, 4, 3, 0, 0, 3, 3, 1, 3, 0, 0, 0, 3, 2, 1, 3, 3, 0, 0, 1, 2, 3, 0, 2, 1, 1, 3, 4, 0, 0, 3, 3, 2, 1, 4, 0, 3, 0, 3, 3, 3, 3, 0, 1, 3, 0, 1, 0, 4, 4, 3, 3, 3, 2, 2, 1, 1, 0, 1, 3, 1, 1, 4, 2, 2, 3, 3, 3, 0, 0, 0, 1, 3, 3, 3, 1, 0, 4, 0, 3, 0, 1, 4, 3, 0, 2, 3, 2, 2, 0, 1, 3, 3, 4, 1, 0, 0, 0, 3, 4, 0, 2, 3, 3, 2, 1, 0, 2, 3, 2, 4, 1, 0, 0, 1, 3, 0, 1, 3, 3, 2, 2, 4, 2, 3, 2, 3, 0, 1, 0, 4, 1, 0, 1, 0, 0, 0, 0, 2, 3, 1, 3, 3, 4, 4, 2, 3, 0, 3, 4, 0, 3, 3, 1, 3, 0, 3, 2, 2, 2, 3, 1, 1, 3, 1, 3, 0, 0, 0, 1, 3, 3, 1, 3, 0, 1, 0, 0, 0, 1, 0, 1, 3, 2, 3, 3, 3, 0, 2, 3, 0, 3, 1, 4, 0, 1, 3, 2, 1, 1, 3, 0, 1, 1, 4, 1, 1, 1, 0, 0, 2, 1, 0, 4, 0, 3, 1, 0, 1, 3, 1, 2, 3, 1, 3, 3, 1, 1, 1, 3, 4, 1, 0, 0, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 1, 3, 2, 3, 3, 0, 1, 2, 1, 0, 1, 1, 2, 3, 0, 0, 0, 0, 1, 3, 0, 1, 0, 1, 0, 1, 3, 0, 0, 1, 1, 0, 3, 1, 3, 1, 3, 1, 3, 3, 0, 0, 2, 1, 2, 2, 0, 3, 3, 3, 3, 3, 0, 3, 2, 0, 0, 3, 1, 1, 0, 3, 3, 1, 2, 3, 1, 3, 0, 1, 3, 3, 1, 0, 0, 1, 1, 1, 2, 0, 0, 0, 3, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, 3, 0, 3, 2, 0, 0, 3, 0, 3, 0, 3, 0, 1, 1, 3, 0, 0, 2, 0, 1, 4, 0, 1, 3, 1, 0, 3, 0, 3, 1, 0, 0, 0, 3, 1, 3, 3, 2, 3, 0, 1, 0, 1, 3, 4, 1, 0, 4, 4, 3, 3, 1, 1, 0, 1, 3, 3, 3, 1, 3, 0, 2, 1, 3, 3, 0, 1, 0, 3, 0, 4, 0, 2, 1, 1, 0, 1, 0, 3, 1, 3, 0, 1, 3, 3, 3, 4, 1, 3, 3, 3, 3, 3, 0, 1, 3, 1, 0, 0, 3, 2, 1, 1, 3, 1, 3, 3, 1, 0, 0, 0, 1, 3, 1, 3, 3, 3, 1, 2, 1, 1, 1, 4, 2, 0, 3, 3, 1, 1, 3, 1, 2, 0, 2, 3, 3, 3, 0, 2, 2, 2, 0, 3, 1, 0, 1, 0, 3, 3, 1, 0, 1, 1, 1, 4, 0, 2, 0, 0, 1, 1, 3, 1, 0, 3, 0, 0, 0, 3, 3, 0, 1, 0, 0, 3, 0, 0, 3, 0, 1, 1, 0, 0, 3, 1, 0, 0, 0, 3, 3, 1, 3, 0, 1, 3, 1, 1, 1, 0, 2, 1, 1, 1, 3, 1, 1, 0, 1, 1, 3, 3, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 3, 0, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 0, 1, 1, 1, 3, 3, 0, 2, 3, 0, 4, 3, 1, 0, 3, 1, 0, 0, 3, 0, 3, 0, 1, 3, 0, 3, 3, 3, 0, 4, 0, 3, 1, 0, 3, 1, 1, 0, 3, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 1, 3, 0, 1, 1, 3, 1, 1, 0, 0, 0, 0, 0, 3, 1, 3, 2, 0, 0, 0, 3, 1, 1, 3, 3, 3, 0, 1, 1, 0, 0, 2, 0, 3, 3, 4, 1, 3, 0, 0, 0, 2, 2, 0, 3, 1, 0, 3, 2, 3, 0, 3, 0, 3, 0, 1, 0, 3, 0, 1, 3, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 3, 0, 3, 0, 3, 1, 1, 1, 3, 1, 0, 1, 4, 4, 0, 0, 0, 0, 0, 3, 0, 3, 1, 1, 2, 0, 0, 3, 3, 0, 3, 3, 0, 1, 3, 3, 0, 0, 1, 3, 3, 3, 3, 1, 0, 1, 1, 3, 3, 3, 3, 0, 0, 2, 2, 0, 3, 4, 3, 0, 3, 0, 0, 0, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2, 2, 1, 3, 1, 2, 3, 1, 1, 0, 1, 1, 1, 2, 0, 0, 3, 2, 0, 0, 0, 3, 3, 1, 0, 2, 4, 0, 4, 3, 1, 4, 1, 2, 1, 0, 1, 1, 4, 1, 0, 2, 1, 3, 0, 1, 1, 1, 1, 0, 3, 3, 0, 3, 1, 0, 3, 0, 3, 3, 0, 3, 0, 0, 1, 0, 0, 3, 1, 3, 3, 1, 2, 1, 0, 2, 3, 0, 1, 1, 3, 1, 1, 1, 0, 3, 4, 3, 4, 0, 1, 3, 2, 0, 1, 0, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 2, 2, 3, 1, 2, 3, 1, 4, 1, 1, 0, 1, 2, 1, 0, 3, 0, 0, 0, 1, 1, 1, 3, 4, 0, 2, 4, 3, 3, 1, 1, 0, 1, 1, 1, 1, 1, 3, 0, 2, 2, 3, 3, 3, 3, 4, 1, 3, 1, 4, 0, 3, 1, 1, 0, 3, 1, 1, 0, 1, 1, 4, 2, 2, 3, 3, 3, 0, 3, 2, 3, 3, 1, 1, 1, 0, 0, 3, 0, 2, 4, 1, 3, 0, 2, 3, 3, 3, 0, 1, 1, 0, 1, 3, 3, 0, 1, 1, 1, 1, 4, 3, 2, 1, 0, 3, 0, 1, 1, 1, 1, 3, 0, 0, 0, 0, 3, 3, 1, 0, 0, 3, 3, 3, 3, 3, 3, 1, 4, 1, 4, 1, 1, 2, 1, 0, 1, 3, 3, 0, 1, 1, 3, 3, 3, 0, 1, 2, 0, 1, 0, 1, 0, 4, 3, 0, 4, 0, 3, 1, 3, 0, 3, 1, 3, 0, 3, 0, 1, 1, 0, 1, 0, 1, 1, 3, 1, 0, 0, 3, 4, 1, 1, 2, 1, 0, 0, 0, 1, 3, 1, 1, 0, 1, 3, 1, 3, 0, 1, 0, 3, 3, 0, 0, 0, 1, 1, 0, 3, 1, 3, 0, 1, 1, 1, 3, 0, 2, 3, 4, 3, 2, 3, 0, 0, 3, 3, 2, 3, 1, 4, 0, 3, 0, 3, 0, 0, 4, 3, 0, 0, 3, 3, 3, 3, 1, 0, 3, 1, 3, 3, 0, 0, 3, 1, 3, 1, 3, 1, 1, 0, 0, 0, 0, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 4, 0, 3, 3, 3, 1, 2, 2, 3, 3, 3, 0, 1, 1, 1, 1, 3, 0, 3, 4, 3, 1, 1, 3, 2, 2, 2, 2, 1, 3, 1, 3, 3, 1, 3, 3, 0, 4, 0, 3, 0, 1, 3, 3, 1, 0, 3, 1, 3, 1, 3, 3, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 4, 4, 3, 3, 2, 3, 3, 0, 0, 4, 1, 0, 2, 1, 1, 1, 3, 3, 3, 0, 4, 3, 4, 1, 3, 3, 1, 1, 1, 1, 1, 0, 3, 3, 1, 0, 3, 1, 3, 3, 1, 3, 3, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 0, 1, 3, 2, 1, 2, 0, 3, 1, 2, 3, 1, 3, 0, 1, 1, 0, 3, 0, 1, 1, 3, 3, 0, 0, 1, 0, 1, 1, 2, 1, 3, 1, 2, 1, 0, 0, 1, 0, 1, 3, 3, 1, 3, 1, 3, 0, 3, 3, 3, 1, 3, 1, 3, 3, 2, 2, 1, 3, 1, 2, 3, 3, 0, 0, 3, 0, 0, 3, 1, 0, 3, 0, 1, 3, 1, 3, 1, 2, 4, 1, 2, 1, 1, 1, 0, 3, 1, 1, 3, 1, 0, 3, 0, 0, 1, 0, 1, 0, 3, 2, 1, 0, 3, 3, 1, 1, 3, 4, 1, 3, 3, 3, 0, 0, 1, 0, 1, 1, 3, 1, 0, 0, 3, 3, 1, 3, 1, 3, 0, 1, 3, 1, 0, 0, 3, 1, 3, 1, 3, 3, 1, 1, 1, 3, 4, 4, 1, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 3, 3, 1, 0, 3, 3, 3, 1, 0, 0, 1, 1, 2, 3, 0, 3, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 3, 3, 0, 3, 3, 0, 3, 1, 0, 3, 0, 1, 2, 3, 0, 1, 3, 0, 3, 0, 3, 1, 3, 3, 3, 3, 4, 3, 3, 1, 1, 2, 0, 0, 1, 1, 3, 3, 2, 1, 1, 1, 3, 0, 1, 1, 3, 0, 3, 0, 1, 0, 3, 2, 3, 3, 1, 1, 3, 1, 3, 3, 0, 4, 1, 0, 0, 0, 3, 2, 2, 1, 3, 0, 1, 3, 1, 2, 4, 1, 0, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 4, 0, 0, 2, 3, 3, 3, 1, 3, 3, 0, 3, 1, 1, 3, 4, 3, 3, 3, 1, 0, 3, 3, 0, 3, 0, 0, 3, 0, 1, 1, 0, 0, 4, 2, 3, 0, 3, 4, 0, 3, 2, 3, 1, 3, 4, 0, 1, 4, 3, 3, 0, 3, 1, 0, 1, 3, 3, 3, 1, 1, 1, 1, 3, 0, 3, 3, 3, 0, 1, 3, 1, 4, 1, 0, 1, 0, 1, 1, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 3, 0, 3, 2, 3, 3, 1, 3, 3, 0, 3, 1, 0, 1, 3, 1, 0, 3, 0, 3, 3, 3, 1, 1, 3, 1, 3, 0, 0, 0, 1, 1, 0, 1, 1, 1, 3, 3, 3, 0, 3, 1, 3, 1, 3, 1, 0, 1, 0, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3, 0, 0, 0, 0, 3, 4, 1, 3, 4, 3, 0, 3, 3, 3, 2, 3, 1, 0, 0, 0, 1, 3, 3, 3, 1, 0, 1, 0, 0, 0, 1, 0, 3, 1, 4, 1, 2, 3, 1, 3, 1, 1, 0, 3, 1, 1, 3, 1, 2, 3, 2, 3, 3, 4, 2, 1, 1, 1, 0, 0, 0, 0, 3, 4, 3, 2, 1, 3, 0, 0, 0, 3, 3, 0, 1, 3, 3, 3, 4, 1, 3, 3, 1, 3, 3, 3, 0, 1, 1, 1, 1, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 3, 0, 2, 4, 2, 3, 1, 1, 0, 1, 1, 0, 1, 0, 3, 0, 0, 3, 0, 1, 0, 2, 3, 3, 1, 0, 1, 0, 3, 1, 1, 1, 1, 0, 2, 2, 1, 2, 3, 1, 3, 1, 3, 0, 1, 1, 3, 3, 1, 0, 0, 1, 1, 0, 0, 1, 2, 4, 0, 3, 3, 3, 4, 3, 1, 0, 3, 1, 3, 3, 0, 0, 1, 1, 3, 3, 1, 3, 3, 1, 3, 1, 0, 3, 4, 3, 3, 3, 2, 3, 4, 3, 0, 0, 3, 3, 2, 3, 1, 0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 3, 1, 1, 0, 1, 0, 0, 0, 2, 2, 0, 0, 3, 1, 1, 0, 0, 0, 3, 1, 1, 1, 1, 1, 0, 1, 3, 1, 0, 0, 1, 2, 3, 1, 0, 1, 0, 0, 0, 1, 0, 3, 4, 2, 0, 0, 2, 3, 3, 0, 4, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3, 1, 0, 1, 4, 0, 3, 4, 1, 1, 3, 1, 1, 3, 0, 4, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 1, 1, 3, 0, 0, 1, 2, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 2, 0, 1, 4, 1, 0, 1, 3, 3, 3, 1, 3, 0, 1, 1, 0, 3, 1, 3, 3, 3, 0, 4, 3, 3, 2, 0, 4, 4, 2, 1, 1, 1, 1, 0, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 2, 1, 3, 0, 0, 3, 0, 0, 3, 1, 1, 0, 1, 1, 2, 2, 3, 1, 2, 1, 1, 1, 4, 4, 3, 0, 0, 3, 3, 3, 3, 1, 3, 0, 0, 4, 2, 1, 3, 0, 2, 0, 1, 1, 3, 3, 3, 3, 3, 1, 0, 1, 1, 0, 2, 1, 3, 4, 0, 1, 1, 2, 2, 1, 2, 0, 1, 1, 3, 3, 1, 1, 1, 0, 3, 2, 2, 2, 3, 0, 3, 3, 3, 2, 3, 1, 3, 3, 0, 3, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 3, 3, 0, 3, 1, 0, 3, 1, 0, 3, 1, 1, 3, 0, 1, 4, 1, 3, 1, 3, 3, 3, 1, 1, 3, 1, 0, 0, 3, 0, 1, 1, 3, 3, 3, 3, 2, 0, 3, 0, 3, 4, 0, 3, 3, 1, 1, 0, 3, 3, 3, 3, 0, 1, 3, 1, 0, 0, 0, 3, 1, 1, 0, 1, 0, 1, 3, 1, 4, 1, 3, 3, 0, 3, 0, 0, 1, 2, 0, 3, 1, 3, 3, 0, 3, 2, 3, 3, 1, 1, 1, 3, 2, 3, 0, 0, 1, 0, 3, 3, 1, 1, 3, 3, 3, 3, 0, 3, 1, 3, 3, 3, 4, 0, 0, 1, 1, 1, 0, 4, 1, 1, 1, 1, 1, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 0, 1, 1, 4, 1, 1, 1, 3, 1, 1, 0, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 0, 0, 3, 0, 3, 1, 1, 2, 1, 2, 0, 4, 3, 1, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 1, 3, 1, 1, 4, 4, 4, 3, 1, 3, 1, 3, 0, 3, 1, 3, 4, 1, 3, 0, 3, 0, 3, 1, 3, 3, 3, 1, 2, 3, 0, 1, 0, 1, 1, 1, 0, 0, 3, 1, 1, 3, 3, 3, 1, 0, 1, 0, 3, 1, 3, 3, 1, 0, 3, 1, 0, 1, 1, 0, 1, 3, 2, 1, 3, 3, 3, 3, 1, 3, 0, 1, 0, 1, 1, 1, 1, 4, 3, 1, 3, 0, 1, 0, 0, 0, 2, 0, 1, 3, 1, 3, 3, 1, 3, 1, 1, 3, 2, 2, 2, 2, 2, 2, 1, 1, 0, 3, 1, 1, 1, 3, 0, 2, 1, 1, 1, 2, 3, 1, 1, 2, 0, 2, 0, 3, 3, 1, 1, 1, 3, 1, 3, 3, 3, 1, 0, 2, 2, 3, 2, 3, 0, 0, 3, 0, 1, 3, 0, 3, 3, 3, 0, 0, 2, 2, 4, 0, 0, 1, 1, 3, 0, 2, 1, 3, 3, 3, 1, 3, 0, 3, 0, 3, 4, 1, 0, 0, 3, 0, 0, 0, 1, 3, 3, 3, 3, 3, 0, 0, 0, 3, 2, 0, 3, 3, 0, 1, 3, 0, 3, 3, 1, 0, 3, 3, 1, 0, 1, 1, 3, 3, 3, 0, 3, 1, 1, 2, 0, 1, 0, 3, 1, 1, 3, 1, 0, 1, 0, 0, 0, 1, 1, 3, 1, 3, 0, 1, 1, 0, 0, 1, 4, 1, 1, 3, 4, 1, 1, 3, 1, 0, 3, 3, 1, 0, 3, 3, 0, 1, 1, 3, 3, 3, 4, 1, 3, 0, 1, 0, 3, 3, 3, 3, 3, 3, 3, 0, 1, 0, 3, 3, 3, 3, 1, 2, 0, 0, 2, 0, 0, 3, 1, 1, 0, 3, 3, 2, 0, 3, 1, 1, 3, 0, 3, 1, 1, 0, 0, 1, 3, 1, 0, 3, 3, 0, 3, 4, 1, 0, 3, 3, 3, 3, 0, 3, 1, 1, 1, 0, 1, 0, 0, 0, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 0, 0, 3, 0, 1, 3, 3, 1, 1, 3, 3, 0, 0, 1, 3, 0, 1, 0, 3, 3, 1, 1, 0, 0, 1, 3, 3, 2, 1, 1, 0, 3, 3, 3, 4, 0, 1, 0, 1, 0, 0, 0, 3, 3, 4, 1, 0, 3, 3, 3, 2, 3, 1, 1, 2, 3, 1, 3, 3, 3, 4, 4, 4, 4, 0, 1, 3, 0, 0, 3, 1, 3, 1, 0, 2, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 1, 0, 0, 1, 2, 1, 1, 1, 2, 3, 3, 3, 1, 0, 1, 1, 1, 3, 1, 1, 3, 3, 3, 0, 1, 1, 0, 3, 0, 3, 0, 1, 1, 1, 3, 3, 1, 0, 0, 2, 0, 0, 3, 3, 3, 0, 3, 3, 0, 1, 1, 3, 1, 1, 1, 1, 1, 3, 4, 0, 0, 3, 1, 3, 3, 1, 3, 1, 0, 3, 3, 0, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 3, 2, 3, 1, 4, 1, 3, 2, 1, 3, 0, 0, 3, 1, 0, 3, 0, 1, 3, 0, 4, 3, 1, 1, 3, 2, 0, 2, 3, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 2, 1, 1, 3, 2, 0, 2, 0, 1, 2, 3, 1, 0, 3, 4, 3, 0, 0, 0, 0, 1, 3, 0, 4, 0, 3, 0, 1, 1, 1, 3, 0, 1, 1, 1, 0, 3, 1, 0, 0, 3, 4, 2, 0, 0, 3, 3, 3, 1, 1, 1, 1, 2, 1, 0, 3, 3, 2, 2, 1, 3, 2, 4, 1, 1, 1, 2, 4, 1, 1, 2, 0, 2, 3, 1, 0, 4, 2, 3, 1, 0, 3, 0, 1, 1, 3, 3, 1, 1, 1, 3, 3, 3, 1, 0, 4, 4, 0, 3, 1, 3, 3, 3, 1, 1, 1, 3, 2, 4, 3, 0, 1, 1, 1, 0, 0, 0, 3, 0, 1, 3, 3, 1, 0, 3, 2, 3, 1, 2, 3, 3, 3, 4, 2, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 0, 1, 0, 1, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 3, 0, 0, 3, 0, 0, 1, 2, 1, 1, 0, 1, 1, 0, 2, 3, 2, 2, 3, 1, 3, 3, 0, 1, 3, 3, 1, 3, 3, 1, 1, 0, 0, 1, 3, 3, 3, 4, 3, 3, 3, 1, 3, 0, 0, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 4, 3, 2, 3, 2, 3, 1, 1, 1, 1, 1, 0, 0, 1, 2, 3, 1, 0, 1, 1, 0, 0, 1, 2, 0, 2, 1, 3, 1, 0, 1, 3, 3, 1, 4, 0, 0, 0, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 1, 3, 0, 3, 0, 1, 0, 1, 3, 1, 1, 1, 3, 0, 4, 4, 3, 3, 1, 0, 0, 3, 1, 0, 2, 1, 3, 2, 2, 0, 3, 0, 0, 3, 1, 3, 3, 1, 1, 3, 1, 4, 2, 3, 0, 0, 1, 3, 3, 3, 3, 1, 3, 3, 1, 1, 1, 0, 1, 4, 3, 3, 0, 3, 3, 3, 3, 3, 1, 1, 2, 1, 2, 3, 3, 3, 0, 3, 1, 1, 0, 0, 3, 0, 3, 1, 3, 3, 1, 3, 0, 3, 0, 2, 3, 0, 1, 3, 4, 2, 3, 3, 1, 0, 2, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 2, 2, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 0, 3, 1, 3, 0, 3, 3, 0, 1, 3, 1, 0, 3, 0, 3, 3, 0, 1, 3, 0, 3, 1, 3, 1, 1, 4, 0, 0, 2, 1, 0, 1, 3, 1, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 2, 3, 0, 3, 1, 3, 0, 0, 3, 1, 1, 2, 3, 0, 3, 3, 1, 1, 1, 3, 3, 3, 1, 0, 0, 0, 3, 3, 3, 0, 3, 2, 3, 3, 1, 0, 3, 1, 3, 1, 2, 1, 2, 0, 3, 3, 0, 3, 3, 0, 1, 3, 3, 3, 0, 4, 1, 1, 2, 4, 3, 1, 1, 1, 3, 2, 3, 3, 1, 0, 0, 0, 4, 0, 4, 0, 2, 3, 1, 1, 0, 0, 1, 2, 3, 2, 1, 0, 3, 3, 0, 1, 1, 4, 0, 1, 3, 1, 1, 3, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 4, 0, 0, 1, 0, 0, 3, 1, 1, 3, 0, 1, 1, 1, 0, 1, 1, 3, 1, 3, 4, 0, 1, 1, 0, 0, 4, 0, 1, 1, 3, 2, 3, 3, 3, 3, 0, 3, 3, 0, 2, 0, 1, 1, 3, 2, 3, 3, 1, 3, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 3, 2, 2, 1, 0, 0, 1, 3, 3, 1, 3, 1, 3, 1, 2, 4, 1, 2, 4, 3, 1, 1, 0, 1, 3, 3, 3, 4, 1, 1, 0, 4, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 3, 3, 4, 3, 0, 0, 0, 3, 1, 3, 3, 1, 3, 3, 1, 0, 1, 0, 3, 1, 2, 1, 3, 2, 1, 1, 3, 1, 3, 3, 0, 0, 1, 3, 1, 1, 0, 3, 1, 1, 1, 1, 0, 3, 2, 1, 0, 3, 1, 1, 3, 4, 0, 3, 3, 0, 4, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 2, 1, 3, 2, 0, 2, 3, 2, 0, 1, 3, 3, 1, 1, 2, 3, 1, 3, 3, 3, 3, 4, 1, 0, 0, 4, 0, 3, 3, 3, 1, 3, 0, 0, 3, 2, 3, 3, 3, 3, 4, 3, 0, 1, 3, 0, 3, 2, 1, 3, 1, 3, 1, 0, 0, 3, 1, 3, 3, 0, 3, 1, 1, 4, 0, 1, 0, 3, 1, 1, 1, 0, 0, 1, 3, 1, 3, 0, 3, 2, 3, 2, 0, 1, 3, 1, 0, 3, 1, 1, 4, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 3, 1, 1, 3, 2, 1, 3, 3, 3, 1, 1, 1, 0, 3, 3, 1, 4, 3, 3, 3, 4, 3, 3, 0, 2, 3, 0, 1, 3, 3, 2, 4, 1, 3, 0, 0, 3, 2, 1, 2, 1, 1, 0, 3, 3, 0, 0, 1, 0, 1, 1, 2, 0, 4, 0, 3, 0, 1, 2, 3, 3, 1, 3, 1, 3, 3, 1, 3, 1, 3, 0, 4, 3, 3, 3, 1, 1, 3, 0, 0, 3, 1, 4, 0, 3, 0, 3, 3, 2, 0, 3, 1, 0, 1, 3, 0, 2, 3, 1, 3, 1, 3, 4, 1, 1, 4, 3, 3, 1, 3, 1, 3, 3, 0, 3, 4, 3, 1, 3, 3, 2, 3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 1, 3, 1, 3, 1, 0, 3, 2, 2, 3, 3, 0, 1, 3, 4, 1, 1, 2, 3, 3, 3, 0, 1, 1, 0, 0, 4, 3, 3, 2, 1, 1, 1, 3, 0, 3, 1, 2, 3, 1, 1, 1, 2, 3, 3, 0, 3, 1, 3, 3, 1, 3, 4, 0, 1, 3, 3, 3, 3, 1, 3, 0, 3, 1, 4, 3, 0, 1, 1, 1, 2, 1, 3, 2, 2, 3, 3, 1, 0, 3, 1, 1, 0, 0, 1, 3, 1, 1, 1, 3, 3, 1, 1, 0, 3, 4, 1, 1, 3, 0, 0, 3, 1, 4, 1, 3, 1, 3, 3, 0, 0, 3, 2, 1, 1, 3, 3, 3, 0, 3, 3, 3, 3, 2, 1, 0, 3, 1, 0, 1, 1, 0, 1, 1, 3, 2, 3, 3, 1, 1, 3, 1, 0, 3, 3, 0, 1, 1, 3, 1, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 0, 1, 3, 3, 0, 3, 1, 1, 3, 1, 3, 0, 0, 0, 3, 1, 0, 2, 3, 0, 0, 3, 1, 0, 1, 1, 3, 3, 0, 1, 3, 1, 1, 3, 3, 3, 4, 3, 0, 1, 3, 0, 3, 0, 3, 1, 0, 0, 0, 3, 2, 0, 2, 3, 3, 0, 3, 1, 1, 2, 0, 3, 3, 1, 0, 3, 1, 1, 0, 1, 1, 3, 0, 4, 3, 1, 0, 3, 0, 2, 2, 3, 0, 3, 1, 1, 3, 1, 1, 1, 0, 4, 3, 2, 0, 1, 4, 3, 3, 3, 0, 1, 0, 3, 0, 3, 3, 1, 0, 3, 1, 0, 1, 0, 0, 1, 3, 2, 1, 3, 3, 0, 1, 0, 3, 4, 3, 3, 1, 3, 0, 0, 3, 4, 4, 4, 3, 0, 2, 2, 3, 0, 2, 4, 1, 1, 0, 2, 1, 1, 3, 3, 1, 1, 3, 1, 3, 3, 0, 3, 3, 3, 3, 3, 0, 1, 1, 4, 1, 4, 1, 1, 1, 1, 0, 1, 4, 1, 0, 1, 3, 3, 0, 3, 0, 3, 1, 3, 3, 2, 3, 3, 0, 1, 2, 0, 0, 3, 0, 0, 0, 1, 0, 3, 0, 0, 1, 1, 3, 1, 3, 1, 3, 3, 3, 1, 0, 1, 0, 3, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 0, 3, 0, 2, 3, 4, 1, 4, 0, 1, 2, 2, 1, 1, 3, 0, 1, 4, 1, 3, 3, 1, 0, 3, 0, 3, 1, 3, 4, 4, 3, 3, 1, 3, 1, 1, 3, 3, 1, 0, 3, 4, 2, 1, 1, 1, 1, 1, 1, 1, 3, 0, 0, 3, 0, 0, 3, 2, 1, 0, 1, 1, 0, 0, 3, 1, 1, 3, 1, 3, 2, 1, 1, 2, 0, 1, 0, 3, 3, 1, 1, 3, 1, 1, 0, 4, 3, 0, 1, 0, 1, 0, 1, 1, 0, 3, 4, 3, 1, 0, 1, 2, 1, 0, 0, 3, 1, 0, 2, 2, 0, 1, 3, 2, 3, 3, 0, 1, 3, 0, 2, 0, 1, 0, 0, 1, 3, 3, 3, 1, 3, 4, 2, 3, 0, 4, 4, 1, 1, 4, 3, 0, 3, 3, 1, 3, 0, 2, 1, 1, 3, 0, 3, 1, 0, 1, 4, 0, 1, 3, 3, 0, 3, 0, 0, 1, 3, 1, 1, 3, 1, 1, 0, 1, 1, 0, 0, 3, 1, 3, 0, 2, 0, 4, 2, 3, 3, 0, 1, 3, 3, 3, 3, 1, 0, 0, 4, 1, 2, 0, 0, 1, 3, 1, 2, 1, 3, 3, 1, 0, 3, 0, 3, 1, 4, 3, 0, 3, 3, 4, 2, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 3, 3, 4, 3, 0, 3, 3, 2, 4, 3, 1, 0, 3, 3, 0, 1, 3, 0, 1, 1, 3, 0, 1, 4, 3, 1, 4, 1, 1, 0, 3, 1, 0, 3, 3, 3, 3, 3, 0, 3, 1, 0, 3, 3, 3, 3, 1, 1, 0, 3, 3, 0, 3, 3, 1, 1, 3, 1, 4, 3, 3, 1, 0, 1, 0, 3, 1, 3, 1, 4, 1, 0, 1, 2, 1, 1, 0, 0, 0, 0, 3, 0, 3, 1, 3, 0, 4, 3, 4, 1, 0, 1, 3, 0, 0, 0, 0, 1, 3, 3, 1, 0, 0, 0, 1, 3, 1, 3, 0, 4, 3, 1, 3, 1, 3, 3, 3, 2, 0, 1, 3, 1, 0, 3, 3, 3, 1, 3, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 3, 1, 1, 1, 3, 0, 3, 0, 3, 2, 3, 3, 0, 2, 3, 0, 1, 1, 3, 2, 1, 0, 3, 0, 3, 1, 1, 3, 0, 1, 3, 3, 1, 3, 0, 3, 1, 1, 0, 2, 1, 0, 3, 0, 3, 1, 1, 3, 2, 3, 1, 3, 3, 3, 1, 1, 3, 1, 3, 3, 2, 3, 3, 1, 1, 3, 0, 3, 3, 4, 0, 3, 0, 3, 1, 1, 3, 3, 3, 2, 2, 3, 0, 1, 3, 3, 0, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 3, 1, 0, 2, 0, 3, 1, 3, 1, 1, 3, 4, 4, 0, 0, 0, 3, 4, 0, 3, 4, 3, 4, 1, 3, 0, 0, 0, 3, 3, 1, 2, 1, 3, 3, 3, 3, 1, 1, 2, 0, 0, 3, 3, 2, 0, 1, 3, 1, 1, 3, 1, 3, 0, 3, 3, 1, 1, 3, 3, 1, 4, 2, 3, 1, 1, 4, 3, 1, 2, 1, 3, 4, 1, 3, 1, 3, 3, 3, 2, 1, 4, 3, 1, 0, 1, 2, 3, 1, 0, 0, 1, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 0, 1, 1, 1, 3, 0, 3, 0, 0, 3, 0, 1, 4, 0, 1, 3, 3, 1, 0, 1, 1, 2, 3, 1, 3, 0, 0, 3, 0, 3, 0, 1, 4]\n",
            "Predicted Labels: [0 0 0 ... 0 0 0]\n",
            "Unique Predicted Labels: [0]\n",
            "Test Dataset Labels: [0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#predicted_probs = torch.nn.functional.softmax(torch.tensor(predicted_labels), dim=-1).numpy()\n",
        "\n",
        "# Calculate AUROC\n",
        "auroc = roc_auc_score(true_labels, predicted_labels, multi_class='ovr')\n",
        "print(\"AUROC:\", auroc)"
      ],
      "metadata": {
        "id": "nbm1CKoj0UKX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "74891a4f-ed96-4eb5-9883-92b6adecfa2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-676cbab762d7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate AUROC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUROC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         return _multiclass_roc_auc_score(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \"\"\"\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         raise ValueError(\n\u001b[1;32m    640\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "12LfmsNjtM7jz3zkYzTbF2SMs3meeF4Wl",
      "authorship_tag": "ABX9TyPZbgVGJc2LAGgLsTPpgo1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}