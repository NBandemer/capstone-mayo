{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/678\n",
      "2/678\n",
      "3/678\n",
      "4/678\n",
      "5/678\n",
      "6/678\n",
      "7/678\n",
      "8/678\n",
      "9/678\n",
      "10/678\n",
      "11/678\n",
      "12/678\n",
      "13/678\n",
      "14/678\n",
      "15/678\n",
      "16/678\n",
      "17/678\n",
      "18/678\n",
      "19/678\n",
      "20/678\n",
      "21/678\n",
      "22/678\n",
      "23/678\n",
      "24/678\n",
      "25/678\n",
      "26/678\n",
      "27/678\n",
      "28/678\n",
      "29/678\n",
      "30/678\n",
      "31/678\n",
      "32/678\n",
      "33/678\n",
      "34/678\n",
      "35/678\n",
      "36/678\n",
      "37/678\n",
      "38/678\n",
      "39/678\n",
      "40/678\n",
      "41/678\n",
      "42/678\n",
      "43/678\n",
      "44/678\n",
      "45/678\n",
      "46/678\n",
      "47/678\n",
      "48/678\n",
      "49/678\n",
      "50/678\n",
      "51/678\n",
      "52/678\n",
      "53/678\n",
      "54/678\n",
      "55/678\n",
      "56/678\n",
      "57/678\n",
      "58/678\n",
      "59/678\n",
      "60/678\n",
      "61/678\n",
      "62/678\n",
      "63/678\n",
      "64/678\n",
      "65/678\n",
      "66/678\n",
      "67/678\n",
      "68/678\n",
      "69/678\n",
      "70/678\n",
      "71/678\n",
      "72/678\n",
      "73/678\n",
      "74/678\n",
      "75/678\n",
      "76/678\n",
      "77/678\n",
      "78/678\n",
      "79/678\n",
      "80/678\n",
      "81/678\n",
      "82/678\n",
      "83/678\n",
      "84/678\n",
      "85/678\n",
      "86/678\n",
      "87/678\n",
      "88/678\n",
      "89/678\n",
      "90/678\n",
      "91/678\n",
      "92/678\n",
      "93/678\n",
      "94/678\n",
      "95/678\n",
      "96/678\n",
      "97/678\n",
      "98/678\n",
      "99/678\n",
      "100/678\n",
      "101/678\n",
      "102/678\n",
      "103/678\n",
      "104/678\n",
      "105/678\n",
      "106/678\n",
      "107/678\n",
      "108/678\n",
      "109/678\n",
      "110/678\n",
      "111/678\n",
      "112/678\n",
      "113/678\n",
      "114/678\n",
      "115/678\n",
      "116/678\n",
      "117/678\n",
      "118/678\n",
      "119/678\n",
      "120/678\n",
      "121/678\n",
      "122/678\n",
      "123/678\n",
      "124/678\n",
      "125/678\n",
      "126/678\n",
      "127/678\n",
      "128/678\n",
      "129/678\n",
      "130/678\n",
      "131/678\n",
      "132/678\n",
      "133/678\n",
      "134/678\n",
      "135/678\n",
      "136/678\n",
      "137/678\n",
      "138/678\n",
      "139/678\n",
      "140/678\n",
      "141/678\n",
      "142/678\n",
      "143/678\n",
      "144/678\n",
      "145/678\n",
      "146/678\n",
      "147/678\n",
      "148/678\n",
      "149/678\n",
      "150/678\n",
      "151/678\n",
      "152/678\n",
      "153/678\n",
      "154/678\n",
      "155/678\n",
      "156/678\n",
      "157/678\n",
      "158/678\n",
      "159/678\n",
      "160/678\n",
      "161/678\n",
      "162/678\n",
      "163/678\n",
      "164/678\n",
      "165/678\n",
      "166/678\n",
      "167/678\n",
      "168/678\n",
      "169/678\n",
      "170/678\n",
      "171/678\n",
      "172/678\n",
      "173/678\n",
      "174/678\n",
      "175/678\n",
      "176/678\n",
      "177/678\n",
      "178/678\n",
      "179/678\n",
      "180/678\n",
      "181/678\n",
      "182/678\n",
      "183/678\n",
      "184/678\n",
      "185/678\n",
      "186/678\n",
      "187/678\n",
      "188/678\n",
      "189/678\n",
      "190/678\n",
      "191/678\n",
      "192/678\n",
      "193/678\n",
      "194/678\n",
      "195/678\n",
      "196/678\n",
      "197/678\n",
      "198/678\n",
      "199/678\n",
      "200/678\n",
      "201/678\n",
      "202/678\n",
      "203/678\n",
      "204/678\n",
      "205/678\n",
      "206/678\n",
      "207/678\n",
      "208/678\n",
      "209/678\n",
      "210/678\n",
      "211/678\n",
      "212/678\n",
      "213/678\n",
      "214/678\n",
      "215/678\n",
      "216/678\n",
      "217/678\n",
      "218/678\n",
      "219/678\n",
      "220/678\n",
      "221/678\n",
      "222/678\n",
      "223/678\n",
      "224/678\n",
      "225/678\n",
      "226/678\n",
      "227/678\n",
      "228/678\n",
      "229/678\n",
      "230/678\n",
      "231/678\n",
      "232/678\n",
      "233/678\n",
      "234/678\n",
      "235/678\n",
      "236/678\n",
      "237/678\n",
      "238/678\n",
      "239/678\n",
      "240/678\n",
      "241/678\n",
      "242/678\n",
      "243/678\n",
      "244/678\n",
      "245/678\n",
      "246/678\n",
      "247/678\n",
      "248/678\n",
      "249/678\n",
      "250/678\n",
      "251/678\n",
      "252/678\n",
      "253/678\n",
      "254/678\n",
      "255/678\n",
      "256/678\n",
      "257/678\n",
      "258/678\n",
      "259/678\n",
      "260/678\n",
      "261/678\n",
      "262/678\n",
      "263/678\n",
      "264/678\n",
      "265/678\n",
      "266/678\n",
      "267/678\n",
      "268/678\n",
      "269/678\n",
      "270/678\n",
      "271/678\n",
      "272/678\n",
      "273/678\n",
      "274/678\n",
      "275/678\n",
      "276/678\n",
      "277/678\n",
      "278/678\n",
      "279/678\n",
      "280/678\n",
      "281/678\n",
      "282/678\n",
      "283/678\n",
      "284/678\n",
      "285/678\n",
      "286/678\n",
      "287/678\n",
      "288/678\n",
      "289/678\n",
      "290/678\n",
      "291/678\n",
      "292/678\n",
      "293/678\n",
      "294/678\n",
      "295/678\n",
      "296/678\n",
      "297/678\n",
      "298/678\n",
      "299/678\n",
      "300/678\n",
      "301/678\n",
      "302/678\n",
      "303/678\n",
      "304/678\n",
      "305/678\n",
      "306/678\n",
      "307/678\n",
      "308/678\n",
      "309/678\n",
      "310/678\n",
      "311/678\n",
      "312/678\n",
      "313/678\n",
      "314/678\n",
      "315/678\n",
      "316/678\n",
      "317/678\n",
      "318/678\n",
      "319/678\n",
      "320/678\n",
      "321/678\n",
      "322/678\n",
      "323/678\n",
      "324/678\n",
      "325/678\n",
      "326/678\n",
      "327/678\n",
      "328/678\n",
      "329/678\n",
      "330/678\n",
      "331/678\n",
      "332/678\n",
      "333/678\n",
      "334/678\n",
      "335/678\n",
      "336/678\n",
      "337/678\n",
      "338/678\n",
      "339/678\n",
      "340/678\n",
      "341/678\n",
      "342/678\n",
      "343/678\n",
      "344/678\n",
      "345/678\n",
      "346/678\n",
      "347/678\n",
      "348/678\n",
      "349/678\n",
      "350/678\n",
      "351/678\n",
      "352/678\n",
      "353/678\n",
      "354/678\n",
      "355/678\n",
      "356/678\n",
      "357/678\n",
      "358/678\n",
      "359/678\n",
      "360/678\n",
      "361/678\n",
      "362/678\n",
      "363/678\n",
      "364/678\n",
      "365/678\n",
      "366/678\n",
      "367/678\n",
      "368/678\n",
      "369/678\n",
      "370/678\n",
      "371/678\n",
      "372/678\n",
      "373/678\n",
      "374/678\n",
      "375/678\n",
      "376/678\n",
      "377/678\n",
      "378/678\n",
      "379/678\n",
      "380/678\n",
      "381/678\n",
      "382/678\n",
      "383/678\n",
      "384/678\n",
      "385/678\n",
      "386/678\n",
      "387/678\n",
      "388/678\n",
      "389/678\n",
      "390/678\n",
      "391/678\n",
      "392/678\n",
      "393/678\n",
      "394/678\n",
      "395/678\n",
      "396/678\n",
      "397/678\n",
      "398/678\n",
      "399/678\n",
      "400/678\n",
      "401/678\n",
      "402/678\n",
      "403/678\n",
      "404/678\n",
      "405/678\n",
      "406/678\n",
      "407/678\n",
      "408/678\n",
      "409/678\n",
      "410/678\n",
      "411/678\n",
      "412/678\n",
      "413/678\n",
      "414/678\n",
      "415/678\n",
      "416/678\n",
      "417/678\n",
      "418/678\n",
      "419/678\n",
      "420/678\n",
      "421/678\n",
      "422/678\n",
      "423/678\n",
      "424/678\n",
      "425/678\n",
      "426/678\n",
      "427/678\n",
      "428/678\n",
      "429/678\n",
      "430/678\n",
      "431/678\n",
      "432/678\n",
      "433/678\n",
      "434/678\n",
      "435/678\n",
      "436/678\n",
      "437/678\n",
      "438/678\n",
      "439/678\n",
      "440/678\n",
      "441/678\n",
      "442/678\n",
      "443/678\n",
      "444/678\n",
      "445/678\n",
      "446/678\n",
      "447/678\n",
      "448/678\n",
      "449/678\n",
      "450/678\n",
      "451/678\n",
      "452/678\n",
      "453/678\n",
      "454/678\n",
      "455/678\n",
      "456/678\n",
      "457/678\n",
      "458/678\n",
      "459/678\n",
      "460/678\n",
      "461/678\n",
      "462/678\n",
      "463/678\n",
      "464/678\n",
      "465/678\n",
      "466/678\n",
      "467/678\n",
      "468/678\n",
      "469/678\n",
      "470/678\n",
      "471/678\n",
      "472/678\n",
      "473/678\n",
      "474/678\n",
      "475/678\n",
      "476/678\n",
      "477/678\n",
      "478/678\n",
      "479/678\n",
      "480/678\n",
      "481/678\n",
      "482/678\n",
      "483/678\n",
      "484/678\n",
      "485/678\n",
      "486/678\n",
      "487/678\n",
      "488/678\n",
      "489/678\n",
      "490/678\n",
      "491/678\n",
      "492/678\n",
      "493/678\n",
      "494/678\n",
      "495/678\n",
      "496/678\n",
      "497/678\n",
      "498/678\n",
      "499/678\n",
      "500/678\n",
      "501/678\n",
      "502/678\n",
      "503/678\n",
      "504/678\n",
      "505/678\n",
      "506/678\n",
      "507/678\n",
      "508/678\n",
      "509/678\n",
      "510/678\n",
      "511/678\n",
      "512/678\n",
      "513/678\n",
      "514/678\n",
      "515/678\n",
      "516/678\n",
      "517/678\n",
      "518/678\n",
      "519/678\n",
      "520/678\n",
      "521/678\n",
      "522/678\n",
      "523/678\n",
      "524/678\n",
      "525/678\n",
      "526/678\n",
      "527/678\n",
      "528/678\n",
      "529/678\n",
      "530/678\n",
      "531/678\n",
      "532/678\n",
      "533/678\n",
      "534/678\n",
      "535/678\n",
      "536/678\n",
      "537/678\n",
      "538/678\n",
      "539/678\n",
      "540/678\n",
      "541/678\n",
      "542/678\n",
      "543/678\n",
      "544/678\n",
      "545/678\n",
      "546/678\n",
      "547/678\n",
      "548/678\n",
      "549/678\n",
      "550/678\n",
      "551/678\n",
      "552/678\n",
      "553/678\n",
      "554/678\n",
      "555/678\n",
      "556/678\n",
      "557/678\n",
      "558/678\n",
      "559/678\n",
      "560/678\n",
      "561/678\n",
      "562/678\n",
      "563/678\n",
      "564/678\n",
      "565/678\n",
      "566/678\n",
      "567/678\n",
      "568/678\n",
      "569/678\n",
      "570/678\n",
      "571/678\n",
      "572/678\n",
      "573/678\n",
      "574/678\n",
      "575/678\n",
      "576/678\n",
      "577/678\n",
      "578/678\n",
      "579/678\n",
      "580/678\n",
      "581/678\n",
      "582/678\n",
      "583/678\n",
      "584/678\n",
      "585/678\n",
      "586/678\n",
      "587/678\n",
      "588/678\n",
      "589/678\n",
      "590/678\n",
      "591/678\n",
      "592/678\n",
      "593/678\n",
      "594/678\n",
      "595/678\n",
      "596/678\n",
      "597/678\n",
      "598/678\n",
      "599/678\n",
      "600/678\n",
      "601/678\n",
      "602/678\n",
      "603/678\n",
      "604/678\n",
      "605/678\n",
      "606/678\n",
      "607/678\n",
      "608/678\n",
      "609/678\n",
      "610/678\n",
      "611/678\n",
      "612/678\n",
      "613/678\n",
      "614/678\n",
      "615/678\n",
      "616/678\n",
      "617/678\n",
      "618/678\n",
      "619/678\n",
      "620/678\n",
      "621/678\n",
      "622/678\n",
      "623/678\n",
      "624/678\n",
      "625/678\n",
      "626/678\n",
      "627/678\n",
      "628/678\n",
      "629/678\n",
      "630/678\n",
      "631/678\n",
      "632/678\n",
      "633/678\n",
      "634/678\n",
      "635/678\n",
      "636/678\n",
      "637/678\n",
      "638/678\n",
      "639/678\n",
      "640/678\n",
      "641/678\n",
      "642/678\n",
      "643/678\n",
      "644/678\n",
      "645/678\n",
      "646/678\n",
      "647/678\n",
      "648/678\n",
      "649/678\n",
      "650/678\n",
      "651/678\n",
      "652/678\n",
      "653/678\n",
      "654/678\n",
      "655/678\n",
      "656/678\n",
      "657/678\n",
      "658/678\n",
      "659/678\n",
      "660/678\n",
      "661/678\n",
      "662/678\n",
      "663/678\n",
      "664/678\n",
      "665/678\n",
      "666/678\n",
      "667/678\n",
      "668/678\n",
      "669/678\n",
      "670/678\n",
      "671/678\n",
      "672/678\n",
      "673/678\n",
      "674/678\n",
      "675/678\n",
      "676/678\n",
      "677/678\n",
      "678/678\n",
      "1/457\n",
      "2/457\n",
      "3/457\n",
      "4/457\n",
      "5/457\n",
      "6/457\n",
      "7/457\n",
      "8/457\n",
      "9/457\n",
      "10/457\n",
      "11/457\n",
      "12/457\n",
      "13/457\n",
      "14/457\n",
      "15/457\n",
      "16/457\n",
      "17/457\n",
      "18/457\n",
      "19/457\n",
      "20/457\n",
      "21/457\n",
      "22/457\n",
      "23/457\n",
      "24/457\n",
      "25/457\n",
      "26/457\n",
      "27/457\n",
      "28/457\n",
      "29/457\n",
      "30/457\n",
      "31/457\n",
      "32/457\n",
      "33/457\n",
      "34/457\n",
      "35/457\n",
      "36/457\n",
      "37/457\n",
      "38/457\n",
      "39/457\n",
      "40/457\n",
      "41/457\n",
      "42/457\n",
      "43/457\n",
      "44/457\n",
      "45/457\n",
      "46/457\n",
      "47/457\n",
      "48/457\n",
      "49/457\n",
      "50/457\n",
      "51/457\n",
      "52/457\n",
      "53/457\n",
      "54/457\n",
      "55/457\n",
      "56/457\n",
      "57/457\n",
      "58/457\n",
      "59/457\n",
      "60/457\n",
      "61/457\n",
      "62/457\n",
      "63/457\n",
      "64/457\n",
      "65/457\n",
      "66/457\n",
      "67/457\n",
      "68/457\n",
      "69/457\n",
      "70/457\n",
      "71/457\n",
      "72/457\n",
      "73/457\n",
      "74/457\n",
      "75/457\n",
      "76/457\n",
      "77/457\n",
      "78/457\n",
      "79/457\n",
      "80/457\n",
      "81/457\n",
      "82/457\n",
      "83/457\n",
      "84/457\n",
      "85/457\n",
      "86/457\n",
      "87/457\n",
      "88/457\n",
      "89/457\n",
      "90/457\n",
      "91/457\n",
      "92/457\n",
      "93/457\n",
      "94/457\n",
      "95/457\n",
      "96/457\n",
      "97/457\n",
      "98/457\n",
      "99/457\n",
      "100/457\n",
      "101/457\n",
      "102/457\n",
      "103/457\n",
      "104/457\n",
      "105/457\n",
      "106/457\n",
      "107/457\n",
      "108/457\n",
      "109/457\n",
      "110/457\n",
      "111/457\n",
      "112/457\n",
      "113/457\n",
      "114/457\n",
      "115/457\n",
      "116/457\n",
      "117/457\n",
      "118/457\n",
      "119/457\n",
      "120/457\n",
      "121/457\n",
      "122/457\n",
      "123/457\n",
      "124/457\n",
      "125/457\n",
      "126/457\n",
      "127/457\n",
      "128/457\n",
      "129/457\n",
      "130/457\n",
      "131/457\n",
      "132/457\n",
      "133/457\n",
      "134/457\n",
      "135/457\n",
      "136/457\n",
      "137/457\n",
      "138/457\n",
      "139/457\n",
      "140/457\n",
      "141/457\n",
      "142/457\n",
      "143/457\n",
      "144/457\n",
      "145/457\n",
      "146/457\n",
      "147/457\n",
      "148/457\n",
      "149/457\n",
      "150/457\n",
      "151/457\n",
      "152/457\n",
      "153/457\n",
      "154/457\n",
      "155/457\n",
      "156/457\n",
      "157/457\n",
      "158/457\n",
      "159/457\n",
      "160/457\n",
      "161/457\n",
      "162/457\n",
      "163/457\n",
      "164/457\n",
      "165/457\n",
      "166/457\n",
      "167/457\n",
      "168/457\n",
      "169/457\n",
      "170/457\n",
      "171/457\n",
      "172/457\n",
      "173/457\n",
      "174/457\n",
      "175/457\n",
      "176/457\n",
      "177/457\n",
      "178/457\n",
      "179/457\n",
      "180/457\n",
      "181/457\n",
      "182/457\n",
      "183/457\n",
      "184/457\n",
      "185/457\n",
      "186/457\n",
      "187/457\n",
      "188/457\n",
      "189/457\n",
      "190/457\n",
      "191/457\n",
      "192/457\n",
      "193/457\n",
      "194/457\n",
      "195/457\n",
      "196/457\n",
      "197/457\n",
      "198/457\n",
      "199/457\n",
      "200/457\n",
      "201/457\n",
      "202/457\n",
      "203/457\n",
      "204/457\n",
      "205/457\n",
      "206/457\n",
      "207/457\n",
      "208/457\n",
      "209/457\n",
      "210/457\n",
      "211/457\n",
      "212/457\n",
      "213/457\n",
      "214/457\n",
      "215/457\n",
      "216/457\n",
      "217/457\n",
      "218/457\n",
      "219/457\n",
      "220/457\n",
      "221/457\n",
      "222/457\n",
      "223/457\n",
      "224/457\n",
      "225/457\n",
      "226/457\n",
      "227/457\n",
      "228/457\n",
      "229/457\n",
      "230/457\n",
      "231/457\n",
      "232/457\n",
      "233/457\n",
      "234/457\n",
      "235/457\n",
      "236/457\n",
      "237/457\n",
      "238/457\n",
      "239/457\n",
      "240/457\n",
      "241/457\n",
      "242/457\n",
      "243/457\n",
      "244/457\n",
      "245/457\n",
      "246/457\n",
      "247/457\n",
      "248/457\n",
      "249/457\n",
      "250/457\n",
      "251/457\n",
      "252/457\n",
      "253/457\n",
      "254/457\n",
      "255/457\n",
      "256/457\n",
      "257/457\n",
      "258/457\n",
      "259/457\n",
      "260/457\n",
      "261/457\n",
      "262/457\n",
      "263/457\n",
      "264/457\n",
      "265/457\n",
      "266/457\n",
      "267/457\n",
      "268/457\n",
      "269/457\n",
      "270/457\n",
      "271/457\n",
      "272/457\n",
      "273/457\n",
      "274/457\n",
      "275/457\n",
      "276/457\n",
      "277/457\n",
      "278/457\n",
      "279/457\n",
      "280/457\n",
      "281/457\n",
      "282/457\n",
      "283/457\n",
      "284/457\n",
      "285/457\n",
      "286/457\n",
      "287/457\n",
      "288/457\n",
      "289/457\n",
      "290/457\n",
      "291/457\n",
      "292/457\n",
      "293/457\n",
      "294/457\n",
      "295/457\n",
      "296/457\n",
      "297/457\n",
      "298/457\n",
      "299/457\n",
      "300/457\n",
      "301/457\n",
      "302/457\n",
      "303/457\n",
      "304/457\n",
      "305/457\n",
      "306/457\n",
      "307/457\n",
      "308/457\n",
      "309/457\n",
      "310/457\n",
      "311/457\n",
      "312/457\n",
      "313/457\n",
      "314/457\n",
      "315/457\n",
      "316/457\n",
      "317/457\n",
      "318/457\n",
      "319/457\n",
      "320/457\n",
      "321/457\n",
      "322/457\n",
      "323/457\n",
      "324/457\n",
      "325/457\n",
      "326/457\n",
      "327/457\n",
      "328/457\n",
      "329/457\n",
      "330/457\n",
      "331/457\n",
      "332/457\n",
      "333/457\n",
      "334/457\n",
      "335/457\n",
      "336/457\n",
      "337/457\n",
      "338/457\n",
      "339/457\n",
      "340/457\n",
      "341/457\n",
      "342/457\n",
      "343/457\n",
      "344/457\n",
      "345/457\n",
      "346/457\n",
      "347/457\n",
      "348/457\n",
      "349/457\n",
      "350/457\n",
      "351/457\n",
      "352/457\n",
      "353/457\n",
      "354/457\n",
      "355/457\n",
      "356/457\n",
      "357/457\n",
      "358/457\n",
      "359/457\n",
      "360/457\n",
      "361/457\n",
      "362/457\n",
      "363/457\n",
      "364/457\n",
      "365/457\n",
      "366/457\n",
      "367/457\n",
      "368/457\n",
      "369/457\n",
      "370/457\n",
      "371/457\n",
      "372/457\n",
      "373/457\n",
      "374/457\n",
      "375/457\n",
      "376/457\n",
      "377/457\n",
      "378/457\n",
      "379/457\n",
      "380/457\n",
      "381/457\n",
      "382/457\n",
      "383/457\n",
      "384/457\n",
      "385/457\n",
      "386/457\n",
      "387/457\n",
      "388/457\n",
      "389/457\n",
      "390/457\n",
      "391/457\n",
      "392/457\n",
      "393/457\n",
      "394/457\n",
      "395/457\n",
      "396/457\n",
      "397/457\n",
      "398/457\n",
      "399/457\n",
      "400/457\n",
      "401/457\n",
      "402/457\n",
      "403/457\n",
      "404/457\n",
      "405/457\n",
      "406/457\n",
      "407/457\n",
      "408/457\n",
      "409/457\n",
      "410/457\n",
      "411/457\n",
      "412/457\n",
      "413/457\n",
      "414/457\n",
      "415/457\n",
      "416/457\n",
      "417/457\n",
      "418/457\n",
      "419/457\n",
      "420/457\n",
      "421/457\n",
      "422/457\n",
      "423/457\n",
      "424/457\n",
      "425/457\n",
      "426/457\n",
      "427/457\n",
      "428/457\n",
      "429/457\n",
      "430/457\n",
      "431/457\n",
      "432/457\n",
      "433/457\n",
      "434/457\n",
      "435/457\n",
      "436/457\n",
      "437/457\n",
      "438/457\n",
      "439/457\n",
      "440/457\n",
      "441/457\n",
      "442/457\n",
      "443/457\n",
      "444/457\n",
      "445/457\n",
      "446/457\n",
      "447/457\n",
      "448/457\n",
      "449/457\n",
      "450/457\n",
      "451/457\n",
      "452/457\n",
      "453/457\n",
      "454/457\n",
      "455/457\n",
      "456/457\n",
      "457/457\n",
      "1/284\n",
      "2/284\n",
      "3/284\n",
      "4/284\n",
      "5/284\n",
      "6/284\n",
      "7/284\n",
      "8/284\n",
      "9/284\n",
      "10/284\n",
      "11/284\n",
      "12/284\n",
      "13/284\n",
      "14/284\n",
      "15/284\n",
      "16/284\n",
      "17/284\n",
      "18/284\n",
      "19/284\n",
      "20/284\n",
      "21/284\n",
      "22/284\n",
      "23/284\n",
      "24/284\n",
      "25/284\n",
      "26/284\n",
      "27/284\n",
      "28/284\n",
      "29/284\n",
      "30/284\n",
      "31/284\n",
      "32/284\n",
      "33/284\n",
      "34/284\n",
      "35/284\n",
      "36/284\n",
      "37/284\n",
      "38/284\n",
      "39/284\n",
      "40/284\n",
      "41/284\n",
      "42/284\n",
      "43/284\n",
      "44/284\n",
      "45/284\n",
      "46/284\n",
      "47/284\n",
      "48/284\n",
      "49/284\n",
      "50/284\n",
      "51/284\n",
      "52/284\n",
      "53/284\n",
      "54/284\n",
      "55/284\n",
      "56/284\n",
      "57/284\n",
      "58/284\n",
      "59/284\n",
      "60/284\n",
      "61/284\n",
      "62/284\n",
      "63/284\n",
      "64/284\n",
      "65/284\n",
      "66/284\n",
      "67/284\n",
      "68/284\n",
      "69/284\n",
      "70/284\n",
      "71/284\n",
      "72/284\n",
      "73/284\n",
      "74/284\n",
      "75/284\n",
      "76/284\n",
      "77/284\n",
      "78/284\n",
      "79/284\n",
      "80/284\n",
      "81/284\n",
      "82/284\n",
      "83/284\n",
      "84/284\n",
      "85/284\n",
      "86/284\n",
      "87/284\n",
      "88/284\n",
      "89/284\n",
      "90/284\n",
      "91/284\n",
      "92/284\n",
      "93/284\n",
      "94/284\n",
      "95/284\n",
      "96/284\n",
      "97/284\n",
      "98/284\n",
      "99/284\n",
      "100/284\n",
      "101/284\n",
      "102/284\n",
      "103/284\n",
      "104/284\n",
      "105/284\n",
      "106/284\n",
      "107/284\n",
      "108/284\n",
      "109/284\n",
      "110/284\n",
      "111/284\n",
      "112/284\n",
      "113/284\n",
      "114/284\n",
      "115/284\n",
      "116/284\n",
      "117/284\n",
      "118/284\n",
      "119/284\n",
      "120/284\n",
      "121/284\n",
      "122/284\n",
      "123/284\n",
      "124/284\n",
      "125/284\n",
      "126/284\n",
      "127/284\n",
      "128/284\n",
      "129/284\n",
      "130/284\n",
      "131/284\n",
      "132/284\n",
      "133/284\n",
      "134/284\n",
      "135/284\n",
      "136/284\n",
      "137/284\n",
      "138/284\n",
      "139/284\n",
      "140/284\n",
      "141/284\n",
      "142/284\n",
      "143/284\n",
      "144/284\n",
      "145/284\n",
      "146/284\n",
      "147/284\n",
      "148/284\n",
      "149/284\n",
      "150/284\n",
      "151/284\n",
      "152/284\n",
      "153/284\n",
      "154/284\n",
      "155/284\n",
      "156/284\n",
      "157/284\n",
      "158/284\n",
      "159/284\n",
      "160/284\n",
      "161/284\n",
      "162/284\n",
      "163/284\n",
      "164/284\n",
      "165/284\n",
      "166/284\n",
      "167/284\n",
      "168/284\n",
      "169/284\n",
      "170/284\n",
      "171/284\n",
      "172/284\n",
      "173/284\n",
      "174/284\n",
      "175/284\n",
      "176/284\n",
      "177/284\n",
      "178/284\n",
      "179/284\n",
      "180/284\n",
      "181/284\n",
      "182/284\n",
      "183/284\n",
      "184/284\n",
      "185/284\n",
      "186/284\n",
      "187/284\n",
      "188/284\n",
      "189/284\n",
      "190/284\n",
      "191/284\n",
      "192/284\n",
      "193/284\n",
      "194/284\n",
      "195/284\n",
      "196/284\n",
      "197/284\n",
      "198/284\n",
      "199/284\n",
      "200/284\n",
      "201/284\n",
      "202/284\n",
      "203/284\n",
      "204/284\n",
      "205/284\n",
      "206/284\n",
      "207/284\n",
      "208/284\n",
      "209/284\n",
      "210/284\n",
      "211/284\n",
      "212/284\n",
      "213/284\n",
      "214/284\n",
      "215/284\n",
      "216/284\n",
      "217/284\n",
      "218/284\n",
      "219/284\n",
      "220/284\n",
      "221/284\n",
      "222/284\n",
      "223/284\n",
      "224/284\n",
      "225/284\n",
      "226/284\n",
      "227/284\n",
      "228/284\n",
      "229/284\n",
      "230/284\n",
      "231/284\n",
      "232/284\n",
      "233/284\n",
      "234/284\n",
      "235/284\n",
      "236/284\n",
      "237/284\n",
      "238/284\n",
      "239/284\n",
      "240/284\n",
      "241/284\n",
      "242/284\n",
      "243/284\n",
      "244/284\n",
      "245/284\n",
      "246/284\n",
      "247/284\n",
      "248/284\n",
      "249/284\n",
      "250/284\n",
      "251/284\n",
      "252/284\n",
      "253/284\n",
      "254/284\n",
      "255/284\n",
      "256/284\n",
      "257/284\n",
      "258/284\n",
      "259/284\n",
      "260/284\n",
      "261/284\n",
      "262/284\n",
      "263/284\n",
      "264/284\n",
      "265/284\n",
      "266/284\n",
      "267/284\n",
      "268/284\n",
      "269/284\n",
      "270/284\n",
      "271/284\n",
      "272/284\n",
      "273/284\n",
      "274/284\n",
      "275/284\n",
      "276/284\n",
      "277/284\n",
      "278/284\n",
      "279/284\n",
      "280/284\n",
      "281/284\n",
      "282/284\n",
      "283/284\n",
      "284/284\n",
      "1/627\n",
      "2/627\n",
      "3/627\n",
      "4/627\n",
      "5/627\n",
      "6/627\n",
      "7/627\n",
      "8/627\n",
      "9/627\n",
      "10/627\n",
      "11/627\n",
      "12/627\n",
      "13/627\n",
      "14/627\n",
      "15/627\n",
      "16/627\n",
      "17/627\n",
      "18/627\n",
      "19/627\n",
      "20/627\n",
      "21/627\n",
      "22/627\n",
      "23/627\n",
      "24/627\n",
      "25/627\n",
      "26/627\n",
      "27/627\n",
      "28/627\n",
      "29/627\n",
      "30/627\n",
      "31/627\n",
      "32/627\n",
      "33/627\n",
      "34/627\n",
      "35/627\n",
      "36/627\n",
      "37/627\n",
      "38/627\n",
      "39/627\n",
      "40/627\n",
      "41/627\n",
      "42/627\n",
      "43/627\n",
      "44/627\n",
      "45/627\n",
      "46/627\n",
      "47/627\n",
      "48/627\n",
      "49/627\n",
      "50/627\n",
      "51/627\n",
      "52/627\n",
      "53/627\n",
      "54/627\n",
      "55/627\n",
      "56/627\n",
      "57/627\n",
      "58/627\n",
      "59/627\n",
      "60/627\n",
      "61/627\n",
      "62/627\n",
      "63/627\n",
      "64/627\n",
      "65/627\n",
      "66/627\n",
      "67/627\n",
      "68/627\n",
      "69/627\n",
      "70/627\n",
      "71/627\n",
      "72/627\n",
      "73/627\n",
      "74/627\n",
      "75/627\n",
      "76/627\n",
      "77/627\n",
      "78/627\n",
      "79/627\n",
      "80/627\n",
      "81/627\n",
      "82/627\n",
      "83/627\n",
      "84/627\n",
      "85/627\n",
      "86/627\n",
      "87/627\n",
      "88/627\n",
      "89/627\n",
      "90/627\n",
      "91/627\n",
      "92/627\n",
      "93/627\n",
      "94/627\n",
      "95/627\n",
      "96/627\n",
      "97/627\n",
      "98/627\n",
      "99/627\n",
      "100/627\n",
      "101/627\n",
      "102/627\n",
      "103/627\n",
      "104/627\n",
      "105/627\n",
      "106/627\n",
      "107/627\n",
      "108/627\n",
      "109/627\n",
      "110/627\n",
      "111/627\n",
      "112/627\n",
      "113/627\n",
      "114/627\n",
      "115/627\n",
      "116/627\n",
      "117/627\n",
      "118/627\n",
      "119/627\n",
      "120/627\n",
      "121/627\n",
      "122/627\n",
      "123/627\n",
      "124/627\n",
      "125/627\n",
      "126/627\n",
      "127/627\n",
      "128/627\n",
      "129/627\n",
      "130/627\n",
      "131/627\n",
      "132/627\n",
      "133/627\n",
      "134/627\n",
      "135/627\n",
      "136/627\n",
      "137/627\n",
      "138/627\n",
      "139/627\n",
      "140/627\n",
      "141/627\n",
      "142/627\n",
      "143/627\n",
      "144/627\n",
      "145/627\n",
      "146/627\n",
      "147/627\n",
      "148/627\n",
      "149/627\n",
      "150/627\n",
      "151/627\n",
      "152/627\n",
      "153/627\n",
      "154/627\n",
      "155/627\n",
      "156/627\n",
      "157/627\n",
      "158/627\n",
      "159/627\n",
      "160/627\n",
      "161/627\n",
      "162/627\n",
      "163/627\n",
      "164/627\n",
      "165/627\n",
      "166/627\n",
      "167/627\n",
      "168/627\n",
      "169/627\n",
      "170/627\n",
      "171/627\n",
      "172/627\n",
      "173/627\n",
      "174/627\n",
      "175/627\n",
      "176/627\n",
      "177/627\n",
      "178/627\n",
      "179/627\n",
      "180/627\n",
      "181/627\n",
      "182/627\n",
      "183/627\n",
      "184/627\n",
      "185/627\n",
      "186/627\n",
      "187/627\n",
      "188/627\n",
      "189/627\n",
      "190/627\n",
      "191/627\n",
      "192/627\n",
      "193/627\n",
      "194/627\n",
      "195/627\n",
      "196/627\n",
      "197/627\n",
      "198/627\n",
      "199/627\n",
      "200/627\n",
      "201/627\n",
      "202/627\n",
      "203/627\n",
      "204/627\n",
      "205/627\n",
      "206/627\n",
      "207/627\n",
      "208/627\n",
      "209/627\n",
      "210/627\n",
      "211/627\n",
      "212/627\n",
      "213/627\n",
      "214/627\n",
      "215/627\n",
      "216/627\n",
      "217/627\n",
      "218/627\n",
      "219/627\n",
      "220/627\n",
      "221/627\n",
      "222/627\n",
      "223/627\n",
      "224/627\n",
      "225/627\n",
      "226/627\n",
      "227/627\n",
      "228/627\n",
      "229/627\n",
      "230/627\n",
      "231/627\n",
      "232/627\n",
      "233/627\n",
      "234/627\n",
      "235/627\n",
      "236/627\n",
      "237/627\n",
      "238/627\n",
      "239/627\n",
      "240/627\n",
      "241/627\n",
      "242/627\n",
      "243/627\n",
      "244/627\n",
      "245/627\n",
      "246/627\n",
      "247/627\n",
      "248/627\n",
      "249/627\n",
      "250/627\n",
      "251/627\n",
      "252/627\n",
      "253/627\n",
      "254/627\n",
      "255/627\n",
      "256/627\n",
      "257/627\n",
      "258/627\n",
      "259/627\n",
      "260/627\n",
      "261/627\n",
      "262/627\n",
      "263/627\n",
      "264/627\n",
      "265/627\n",
      "266/627\n",
      "267/627\n",
      "268/627\n",
      "269/627\n",
      "270/627\n",
      "271/627\n",
      "272/627\n",
      "273/627\n",
      "274/627\n",
      "275/627\n",
      "276/627\n",
      "277/627\n",
      "278/627\n",
      "279/627\n",
      "280/627\n",
      "281/627\n",
      "282/627\n",
      "283/627\n",
      "284/627\n",
      "285/627\n",
      "286/627\n",
      "287/627\n",
      "288/627\n",
      "289/627\n",
      "290/627\n",
      "291/627\n",
      "292/627\n",
      "293/627\n",
      "294/627\n",
      "295/627\n",
      "296/627\n",
      "297/627\n",
      "298/627\n",
      "299/627\n",
      "300/627\n",
      "301/627\n",
      "302/627\n",
      "303/627\n",
      "304/627\n",
      "305/627\n",
      "306/627\n",
      "307/627\n",
      "308/627\n",
      "309/627\n",
      "310/627\n",
      "311/627\n",
      "312/627\n",
      "313/627\n",
      "314/627\n",
      "315/627\n",
      "316/627\n",
      "317/627\n",
      "318/627\n",
      "319/627\n",
      "320/627\n",
      "321/627\n",
      "322/627\n",
      "323/627\n",
      "324/627\n",
      "325/627\n",
      "326/627\n",
      "327/627\n",
      "328/627\n",
      "329/627\n",
      "330/627\n",
      "331/627\n",
      "332/627\n",
      "333/627\n",
      "334/627\n",
      "335/627\n",
      "336/627\n",
      "337/627\n",
      "338/627\n",
      "339/627\n",
      "340/627\n",
      "341/627\n",
      "342/627\n",
      "343/627\n",
      "344/627\n",
      "345/627\n",
      "346/627\n",
      "347/627\n",
      "348/627\n",
      "349/627\n",
      "350/627\n",
      "351/627\n",
      "352/627\n",
      "353/627\n",
      "354/627\n",
      "355/627\n",
      "356/627\n",
      "357/627\n",
      "358/627\n",
      "359/627\n",
      "360/627\n",
      "361/627\n",
      "362/627\n",
      "363/627\n",
      "364/627\n",
      "365/627\n",
      "366/627\n",
      "367/627\n",
      "368/627\n",
      "369/627\n",
      "370/627\n",
      "371/627\n",
      "372/627\n",
      "373/627\n",
      "374/627\n",
      "375/627\n",
      "376/627\n",
      "377/627\n",
      "378/627\n",
      "379/627\n",
      "380/627\n",
      "381/627\n",
      "382/627\n",
      "383/627\n",
      "384/627\n",
      "385/627\n",
      "386/627\n",
      "387/627\n",
      "388/627\n",
      "389/627\n",
      "390/627\n",
      "391/627\n",
      "392/627\n",
      "393/627\n",
      "394/627\n",
      "395/627\n",
      "396/627\n",
      "397/627\n",
      "398/627\n",
      "399/627\n",
      "400/627\n",
      "401/627\n",
      "402/627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m imbalanced_data \u001b[38;5;241m=\u001b[39m train_data[train_data[sdoh_name]\u001b[38;5;241m.\u001b[39misin(imbalanced_class_indices)]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Create synthetic data (default 2 synthetic rows) for each row belong to the imbalanced classes\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m synthesized_data \u001b[38;5;241m=\u001b[39m \u001b[43msynthesize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimbalanced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msdoh_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# test_data = pd.read_csv(f\"{data_path}/test.csv\")\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Save the resulting synthetic + original data\u001b[39;00m\n\u001b[0;32m     61\u001b[0m synthesized_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train_synthesized.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36msynthesize_data\u001b[1;34m(original_data, sdoh_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m synth_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# for _ in range(num_synths):\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m synth_text \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrase_and_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m new_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: synth_text, sdoh_name: class_val}\n\u001b[0;32m     28\u001b[0m synth_texts\u001b[38;5;241m.\u001b[39mappend(new_row)\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\src\\paraphrasing\\paraphrase.py:47\u001b[0m, in \u001b[0;36mparaphrase_and_combine\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     44\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [sentence\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mif\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Paraphrase each sentence and combine them\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m paraphrased_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(paraphrase(sentence)) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Combine the paraphrased parts into one row\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(paraphrased_sentences)\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\src\\paraphrasing\\paraphrase.py:47\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [sentence\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mif\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Paraphrase each sentence and combine them\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m paraphrased_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mparaphrase\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Combine the paraphrased parts into one row\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(paraphrased_sentences)\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\src\\paraphrasing\\paraphrase.py:30\u001b[0m, in \u001b[0;36mparaphrase\u001b[1;34m(question, num_beams, num_beam_groups, num_return_sequences, repetition_penalty, diversity_penalty, no_repeat_ngram_size, temperature, max_length)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparaphrase\u001b[39m(\n\u001b[0;32m     13\u001b[0m     question,\n\u001b[0;32m     14\u001b[0m     num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m\n\u001b[0;32m     22\u001b[0m ):\n\u001b[0;32m     23\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m     27\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m     )\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beam_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beam_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiversity_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiversity_penalty\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     res \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\generation\\utils.py:1700\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1694\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1695\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1696\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1698\u001b[0m     )\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_beam_search(\n\u001b[0;32m   1701\u001b[0m         input_ids,\n\u001b[0;32m   1702\u001b[0m         beam_scorer,\n\u001b[0;32m   1703\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1704\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1705\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1706\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1707\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1708\u001b[0m         output_logits\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_logits,\n\u001b[0;32m   1709\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1710\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1711\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1712\u001b[0m     )\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONSTRAINED_BEAM_SEARCH:\n\u001b[0;32m   1715\u001b[0m     final_constraints \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\generation\\utils.py:3770\u001b[0m, in \u001b[0;36mGenerationMixin.group_beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3768\u001b[0m \u001b[38;5;66;03m# do one decoder step on all beams of all sentences in batch\u001b[39;00m\n\u001b[0;32m   3769\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m-> 3770\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   3771\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   3772\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3773\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   3774\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   3775\u001b[0m )\n\u001b[0;32m   3777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3778\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1748\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1745\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[1;32m-> 1748\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1115\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1101\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[0;32m   1102\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         output_attentions,\n\u001b[0;32m   1113\u001b[0m     )\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:695\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    705\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:602\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    600\u001b[0m ):\n\u001b[0;32m    601\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 602\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    612\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\xxnan\\Code\\capstone-mayo\\.venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:573\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    571\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m layer_head_mask\n\u001b[1;32m--> 573\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m unshape(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    574\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo(attn_output)\n\u001b[0;32m    576\u001b[0m present_key_value_state \u001b[38;5;241m=\u001b[39m (key_states, value_states) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m use_cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "from paraphrase import paraphrase_and_combine\n",
    "\n",
    "def synthesize_data(original_data, sdoh_name):\n",
    "    \"\"\"\n",
    "    This function paraphrases the data to increase the size of the dataset\n",
    "    \"\"\"\n",
    "    df_synth = original_data.copy()\n",
    "    count = 1\n",
    "    total = len(original_data)\n",
    "\n",
    "    for _, row in original_data.iterrows():\n",
    "        text = str(row['text'])\n",
    "        class_val = row[sdoh_name]\n",
    "\n",
    "        # generic_prompt = \"Paraphrase the following medical discharge summary while preserving any information relevant to the patient's social determinants of health, such as education, economics, environment, and substance use (alcohol, tobacco, and drug use). The note should keep a similar format and style as the original, but can swap words and phrases around and use synonyms. \\n\\n\"\n",
    "        \n",
    "        synth_texts = []\n",
    "\n",
    "        # for _ in range(num_synths):\n",
    "        \n",
    "        synth_text = paraphrase_and_combine(text)\n",
    "\n",
    "        new_row = {'text': synth_text, sdoh_name: class_val}\n",
    "        synth_texts.append(new_row)\n",
    "\n",
    "        new_df = pd.DataFrame(synth_texts)\n",
    "        df_synth = pd.concat([df_synth, new_df], ignore_index=True)\n",
    "        print(f\"{count}/{total}\")\n",
    "        count += 1\n",
    "\n",
    "    return df_synth\n",
    "\n",
    "\n",
    "imbalanced_sdoh_classes = {\n",
    "    'behavior_alcohol': [2,4],\n",
    "    'behavior_drug': [1,2,4],\n",
    "    'behavior_tobacco': [4],\n",
    "    'sdoh_community_absent': [1],\n",
    "    'sdoh_economics': [1],\n",
    "    'sdoh_education': [1],\n",
    "    'sdoh_environment': [2],\n",
    "}\n",
    "\n",
    "for sdoh_name, imbalanced_class_indices in imbalanced_sdoh_classes.items():\n",
    "    # Load the data\n",
    "    data_path = f\"../../data/test_train_split/{sdoh_name}\"\n",
    "    train_data = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "\n",
    "    # Select the data that belongs to the imbalanced classes\n",
    "    imbalanced_data = train_data[train_data[sdoh_name].isin(imbalanced_class_indices)]\n",
    "\n",
    "    # Create synthetic data (default 2 synthetic rows) for each row belong to the imbalanced classes\n",
    "    synthesized_data = synthesize_data(imbalanced_data, sdoh_name)\n",
    "    # test_data = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # Save the resulting synthetic + original data\n",
    "    synthesized_data.to_csv(f\"{data_path}/train_synthesized.csv\", index=False)\n",
    "    # test_data_balanced.to_csv(f\"{data_path}/test_synthesized.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
